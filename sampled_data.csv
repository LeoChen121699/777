Id,Title,Body,Tags
28523054,Android Studio No LogCat,"<p>Android Studio is just killing me. I'm migrating over from Eclipse and am unable to produce LogCat output. I just created a simple hello world app complete with a single line of <code>System.out.println(""hello world"");</code> Regardless of whether I run this on an emulator or on a USB device, I get no LogCat output. </p>

<p>I reinstalled Android Studio, and then I got the correct output for a few executions. Now I'm back to no output. I tried restarting the computer, but this didn't correct anything. </p>

<p>Obviously, I can't reinstall the program every time LogCat output stops being produced, and I can't program without the ability to see console output. I'm beyond frustrated.</p>

<p>Here are a couple of clues:</p>

<ol>
<li>Occasionally, I will get this error:<img src=""https://i.stack.imgur.com/ckUJG.png"" alt=""enter image description here""></li>
<li>I am unable to run <code>adb</code> from the command line. Since I installed my SDK along with Android Studio, I have no idea where the <code>adb</code> application exists, so I don't know how to add it to my PATH variable. Even so, I don't think that this has anything to do with why LogCat output isn't produced by Android Studio.</li>
</ol>

<p>I have tried restarting the LogCat by clicking on the <img src=""https://i.stack.imgur.com/RWEYA.png"" alt=""enter image description here"">icon, but this does nothing.</p>

<p>I realize that there are <em>many</em> other posts on this same type of issue, but the solutions suggested there are not resolving my issue. I am grateful for any help.</p>
",<android><android-studio>
4435773,"Android Proguard, removing all Log statements and merging packages","<ol>
<li><p>I have about 5 packages in my project, is it possible to merge all the packages into one large package, I want to do this to make hacking more difficult.</p></li>
<li><p>How do I remove all references to Log.e Log.d etc. in my source code using proguard. (I have the eclipse ADT with proguard integrated already).</p></li>
</ol>

<p>Update: Looks like part 2 can be done like this</p>

<pre><code>-assumenosideeffects class android.util.Log {
    public static *** d(...);
    public static *** v(...);
}
</code></pre>
",<android><proguard>
58458851,Lowercase field name in Logstash for Elasticsearch index,"<p>I have a logstash command that I'm piping a file to that will write to Elasticsearch.  I want to use one field to select the index I will write to (<code>appName</code>).  However the data in this field is not all lowercase so I need to do that when selecting the index but I don't want the data in the document itself to be modified.</p>

<p>I have an attempt below where I first copy the original field (<code>appName</code>) to a new one (<code>appNameIndex</code>), lowercase the new field, remove it from the upload and then use it pick the index.</p>

<pre><code>input {
      stdin { type =&gt; stdin }
}
filter {
  csv {
     separator =&gt; "" ""
     columns =&gt; [""appName"", ""field1"", ""field2"", ...]
     convert =&gt; {
         ...
  }
}

filter {
  mutate {
    copy =&gt; [""appName"", ""appNameIndex""]
  }
}

filter {
  mutate {
    lowercase =&gt; [""appNameIndex""]
  }
}

filter {
  mutate {
    remove_field =&gt; [
      ""appNameIndex"", // if I remove this it works
       ...
    ]
  }
}

output {
   amazon_es {
     hosts =&gt;
         [""my-es-cluster.us-east-1.es.amazonaws.com""]
     index =&gt; ""%{appNameIndex}""
     region =&gt; ""us-east-1""
  }
}
</code></pre>

<p>However I am getting errors that say</p>

<pre><code>Invalid index name [%{appIndexName}]
</code></pre>

<p>Clearly it's not grabbing my mutation.  Is it because the remove section takes it out entirely?  I was hoping that just removed it from the document upload.  Am I going about this incorrectly?</p>

<p><strong>UPDATE</strong> I tried taking out the remove index name part and it does in fact work, so that helps identify the source of the error.  Now the question becomes how do I get around it.  With that part of the config removed I essentially have two fields with the same data, one lowercased and one not</p>
",<elasticsearch><logstash>
12089323,Thread count increases with running logger.info in greenlet,"<p>With the following code if I uncomment <code>log_it</code>, <code>threading.active_count</code> reaches 11. 
Since It means each logger creates <code>_DummyThread daemons.Now</code> <br></p>

<p>Q1.Is their any way to achieve the same without creating extra threads?<br></p>

<p>Q2.Why logger needs to create another thread.Why can't it execute in same way, like <code>fun</code> function? </p>

<pre><code>from gevent import monkey
monkey.patch_all()

import threading
import gc
import gevent
import logging

def print_stats():
    while True:
        gc.collect()
        print threading.active_count() 
        gevent.sleep(2)

jobs = [gevent.spawn(print_stats)]
logger = logging.getLogger(__name__)
ch = logging.StreamHandler()
ch.setLevel(logging.DEBUG)
logger.setLevel(logging.INFO)
form = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
ch.setFormatter(form)
logger.addHandler(ch)

def log_it():
    string = 'abcdefghijklmnopqrstuvwxyz'
    logger.info(string)

def fun():
    print ""hello world""

def block_for_some_time():
    log_it()
    fun()
    gevent.sleep(5)
    print 'exiting thread'

for i in range(10):
    jobs.append(gevent.spawn(block_for_some_time))

gevent.joinall(jobs)
</code></pre>
",<python><logging><gevent>
24169060,Character encoding issue between logstash and logstash-forwarder,"<p>I have the following setup -</p>

<pre><code>[logstash-forwarder nodes] -&gt; [Amazon's elastic load balancer] -&gt; [logstash nodes]
</code></pre>

<p>I start logstash-forwarder with the following config file -</p>

<pre><code>{
  ""network"": {
    ""servers"": [""&lt;Load_balancer_DNS_name&gt;:443""],
    ""ssl key"": ""/etc/pki/private/logstash-forwarder.key"",
    ""ssl ca"": ""/etc/pki/tls/certs/logstash-forwarder.crt"",
    ""timeout"": 15
  },

  ""files"": [
    {
      ""paths"": [ ""-"" ],
      ""fields"": { ""type"": ""stdin"" }
    }
  ]
}
</code></pre>

<p>And I start logstash with following settings -</p>

<pre><code>input {
  tcp {
    port =&gt; ""7286""
    codec =&gt; plain {
      charset =&gt; ""UTF-8""
    }
  }
}

output {
  stdout { }
  elasticsearch {
    host =&gt; ""&lt;cluster_node_ip&gt;""
    protocol =&gt; ""http""
  }
}
</code></pre>

<p>Now I feed some input at the command line from logstash-forwarder just to see if it is reachable perfectly at logstash. So when I type ""Hello World"" or just any other plain text on the logstash-forwarder side, I receive the following on logstash node, instead of the original text -</p>

<pre><code>Received an event that has a different character encoding than you configured. {:text=&gt;""1W\\u0000\\u0000\\u0000\\u00011C\\u0000\\u0000\\u0000ox^2ta```\\u0004bV fI\\xCB\\xCCI\\u0005\\xF1uA\\x9C\\x8C\\xFC\\xE2\\u0012 -\\x90Y\\xA0kh\\xA0kha\\xAAkdh\\xACkb\\u0006\\u0014c\\xCBOK+N\\u0005\\xC92\\u001A\\x80\\x94\\xE6d\\xE6\\x81\\xF4\\t\\xBBy\\xFA9\\xFAć\\xB8\\u0006\\x87\\xC4{{:9\\xFA9\\xDAۃ\\xA4K*\\v@Ҭ\\xC5%)\\x99y\\u0000\\u0000\\u0000\\u0000\\xFF\\xFF\\u0001\\u0000\\u0000\\xFF\\xFF\\u001A\\x93\\u0015\\xA2"", :expected_charset=&gt;""UTF-8"", :level=&gt;:warn}
</code></pre>
",<amazon-web-services><character-encoding><logstash>
22271518,SLFJ4 bridge for the Maven logger,"<p>I'm writing a Maven 3.x plugin and want to log with SLF4J &amp; Logback.</p>

<p>I found some SLF4J bindings for the Maven Logger:</p>

<ul>
<li><a href=""http://www.jcabi.com/jcabi-maven-slf4j/index.html"" rel=""nofollow"">http://www.jcabi.com/jcabi-maven-slf4j/index.html</a></li>
<li><a href=""https://bitbucket.org/peachjean/slf4j-mojo"" rel=""nofollow"">https://bitbucket.org/peachjean/slf4j-mojo</a></li>
</ul>

<p>However, these seem to be SLF4J bindings but I believe what I need is a bridge for the Maven Logger i.e. to bridge/route all Maven log statements to SLF4J and use LogBack binding with logback.xml config.</p>
",<maven-3><slf4j><logback>
28536910,Using different pattern for a specific logger in logback,"<p>I am using logback with slf4j and I need to change the pattern for a specific logger but keep the appenders same. </p>

<p>Here's my configuration:<code>logback.xml</code></p>

<pre><code>&lt;configuration&gt;
&lt;appender name=""STDOUT"" class=""ch.qos.logback.core.ConsoleAppender""&gt;
    &lt;!-- encoders are assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --&gt;
    &lt;encoder&gt;
        &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %class{36}:%L - %msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
&lt;/appender&gt;
&lt;appender name=""FILE"" class=""ch.qos.logback.core.FileAppender""&gt;
    &lt;file&gt;${logFile}&lt;/file&gt;
    &lt;append&gt;false&lt;/append&gt;
    &lt;!-- encoders are assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --&gt;
    &lt;encoder&gt;
        &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %class{36}:%L - %msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
&lt;/appender&gt;
&lt;!-- We want error logging from this logger to go to an extra appender It still inherits CONSOLE STDOUT from the root logger --&gt;
&lt;logger name=""${log.name:-com.mycompany}"" level=""${log.level:-INFO}""&gt;
    &lt;appender-ref ref=""STDOUT"" /&gt;
    &lt;appender-ref ref=""FILE"" /&gt;
&lt;/logger&gt;
&lt;logger name=""completion-logger"" level=""${log.level:-INFO}""&gt;
    &lt;appender-ref ref=""STDOUT"" /&gt;
    &lt;appender-ref ref=""FILE"" /&gt;
&lt;/logger&gt;
&lt;/configuration&gt;
</code></pre>

<p>I would like to use a different pattern for 'completion-logger'. Is this possible?</p>
",<java><logging><slf4j><logback>
58723595,Accessing logs of a node js code running as a server,"<p>There is a node js code running on a linux server as a process. 
I have the process id of the process using</p>

<pre><code> ps -aef | grep node
</code></pre>

<p>which gives</p>

<pre><code>amit 20897     1  0 Sep26 ?        03:07:06 node energyMonitor/newBroker.js 
</code></pre>

<p>I want to access the stdout,stderr of this process, to view the what <code>console.log()</code> statements are priniting. I tried with </p>

<pre><code>tail -f /proc/20897/fd/1  
</code></pre>

<p>but of no use, can someone help me with this?</p>

<p>Thanks</p>
",<node.js><linux><process><stdout><stderr>
57575709,I need to console log my anser and not just return it,"<p>I need to console log my anser and not just return it</p>

<p>I have tried this however in my console it does not LOG it but returns (3) [""JavaScript"", ""CSS"", ""HTML""] 
I need it to return<br>
* HTML,CSS,JAVASCRIPT</p>

<pre><code>
function logReverse(input) {
    let arr = input.reverse();
    console.log(arr) 

}
//test
logReverse(['HTML', 'CSS', 'JavaScript'])
</code></pre>

<p>Please  help out</p>
",<javascript>
47895695,Log4j configuration with different logger level for the same class or package,"<p>Nowadays I am using AXIS client to conect with some Webservices. I have configured the logger level at log4j properties like this:</p>

<p>org.apache.axis.client=INFO</p>

<p>However, I would need to config diferent logger level for this client depending from what class or method use the AXIS client.</p>

<p>Is there any possibility to configure log4j with this purpose?</p>
",<java><logging><log4j><axis>
66245411,How to automatically log time taken for all commands run by user in bash,"<p>I know that for logging time taken for executing a command/script in Linux we can put &quot;time &lt;command/script&gt;&quot;.</p>
<p>However, I am looking for any method on how I can log all the commands entered by user in a bash shell and the time taken for each command without even entering time in front of each command by the user.</p>
<p>Basically in our organization, we have a need to monitor all the commands entered by users and fetch the time taken for certain commands on each machine. Is this even possible?</p>
",<linux><bash><shell><time><syslog>
26153772,Tons of 404 errors in Apache httpd log for static files with wrong Path,"<p>We have an Apache in front of a Tomcat, with the Tomcat serving both static and dynamic content. The Tomcat has gotten terribly slow since the number of users on the system increased, and we are trying to pinpoint the cause. We have other servers with double the number of open sessions in Tomcat with no problem.</p>

<p>In the Apache httpd log I am seeing thousands of 404 errors for static files with paths that don't exist in our application. The files exist and the path almost looks right, but it contains duplications and parts of other file paths in the system.</p>

<p>Example: we have this file in our system:</p>

<pre><code>/assets/img/menu-toggler.png
</code></pre>

<p>In the httpd log I can see this:</p>

<pre><code>[02/Oct/2014:12:22:16 +1000] ""GET /assets/assets/css/assets/plugins/jqvmap/assets/assets/img/menu-toggler.png HTTP/1.1"" 404 11947 ""-"" ""Mozilla/4.0 (compatible;)""
[02/Oct/2014:12:22:16 +1000] ""GET /assets/assets/plugins/gritter/assets/plugins/fullcalendar/assets/assets/img/menu-toggler.png HTTP/1.1"" 404 11947 ""-"" ""Mozilla/4.0 (compatible;)""
</code></pre>

<p>We have the folders <code>assets</code>, <code>plugins</code>, <code>jquery-validation</code>, etc in the system, but certainly not nested like that. </p>

<p>We also have correct GET requests for that file</p>

<pre><code>[02/Oct/2014:12:37:23 +1000] ""GET /assets/img/menu-toggler.png HTTP/1.1"" 200 948 ""-"" ""Mozilla/4.0 (compatible;)""
</code></pre>

<p>I believe that all these 404 errors are causing Tomcat to be slow. Question is: what could cause such weird GET requests with paths in the system that don't exist?</p>
",<java><apache><tomcat><http-status-code-404>
12629228,Does Prolog have a condition and restart system like Common Lisp?,"<p>Common Lisp allows exception handling through <a href=""http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html"">conditions and restarts</a>.  In rough terms, when a function throws an exception, the ""catcher"" can decide how/whether the ""thrower"" should proceed.  Does Prolog offer a similar system?  If not, could one be built on top of existing predicates for walking and examining the call stack?</p>
",<prolog><iso-prolog>
11654967,How can I make Apache httpcomponents use log4j?,"<p>My log4j.properties file looks like this:</p>

<pre><code># Root logger option
log4j.rootLogger=DEBUG, file

# Direct log messages to a log file
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=/home/user/logs/myapp.log
log4j.appender.file.MaxFileSize=10MB
log4j.appender.file.MaxBackupIndex=1
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%5p [%c] %m%n

log4j.logger.org.apache.http=DEBUG
</code></pre>

<p>The file myapp.log is created, and my http requests are executing, but the log file remains empty and I have no idea why. </p>

<p>edit: in the class that is using HttpClient, I was able to log messages there. So it makes me think the log4j.logger.org.apache.http line is wrong even though that's what the documentation on <a href=""http://hc.apache.org/"" rel=""nofollow"">http://hc.apache.org/</a> tells you to do.</p>
",<groovy><log4j><apache-httpcomponents>
58112516,Data Transfer from gcp cloud storage to bigquery - log says success but no data in bigquery table,"<p>We are using Google cloud data transfer option from cloud storage to bigquery - transfer job runs every day at certain time and transfers a csv file from storage to bigquery.
Transfer log says success and gives transfer row number as well.But destination table has no data.
Can someone please help here ?</p>
",<google-cloud-platform><google-bigquery><google-cloud-storage>
11541847,Java SipServlet to build VOIP phone calls (between Computer and analog phone/mobile),"<p>I'm interested in building VOIP that actually can be used to call to analog phone using SIP or H.323. But my question is that, is it even possible to build Computer to Phone &amp; Phone to Computer VOIP phone calls with SIP or H.323? Else what is the most common way of achieving this task? I've successfully built an application that i can transfer voices between two computers by using socket, and my guess is that building SIP to communicate with analog phone is quite complicated (even though i read some docs, i still haven't fully understood it) and has a quite different architecture than ordinary socket communication applications. So is it possible to achieve my goal using SIP servlet or H.323? And if you have experienced building it, could u plz share some of references or docs that you have used with me? I would appreciate it so much and I'm pretty sure it will be helpful for all the others who are looking forward to building similar app as mine.</p>

<p>=====================================</p>

<p>According to <a href=""https://stackoverflow.com/questions/2321582/begin-with-java-voip"">begin with java voip</a></p>

<p>a dude recommended using APIs like <a href=""http://public.ifbyphone.com/"" rel=""nofollow noreferrer"">http://public.ifbyphone.com/</a> or <a href=""https://www.tropo.com/home.jsp"" rel=""nofollow noreferrer"">https://www.tropo.com/home.jsp</a>  but i have strong feeling that these people will ask me to pay money to use their API, and all i want to do is just build it by myself and try-out only purpose without commercializing it at all. I've found a quite decent VOIP related thingy called VoiceXML, but is it the same kind of API or library as the ones I've mentioned already? What exactly is VoiceXML?</p>
",<java><android><servlets><sip><voip>
22318442,How to get UserRoles for users other then logged in,"<p>in the Index Action of the Account Controller, I want to be able to allow users to view users of equal or lesser status, but I'm not getting the results I want. One way only returns the Logged in User, the other does not return anything. A user can only have one Role. So far I have this,</p>

<pre><code>var um = new UserManager&lt;ApplicationUser&gt;(new UserStore&lt;ApplicationUser&gt;(new ApplicationDbContext()));
IList&lt;string&gt; roles;

foreach (var item in pUsers)
{
   userDetails = new listUsersViewModel();
   userDetails.id = item.id;
   userDetails.userName = cEncrypt.decryptUserName(item.userName.Substring(2));

   //***this only returns the role of Logged in User
   roles = um.GetRoles(item.id);

   //***this doesn't return any results
   string[] role = Roles.GetRolesForUser(item.userName);

   //make sure the logged in user has appropriate permissions to view list of users.
   if ((User.IsInRole(""Admin"") &amp;&amp; ((roles[0] == ""Admin"") || (roles[0] == ""Staff"") || (roles[0] == ""User"")))
      || (User.IsInRole(""Staff"") &amp;&amp; ((roles[0] == ""Staff"") || (roles[0] == ""User"")))
      || (User.IsInRole(""User"") &amp;&amp; User.Identity.GetUserId() == userDetails.id)
      )
      { userList.Add(userDetails); }
}
</code></pre>

<p>My web.config in the root of the project looks like this...</p>

<pre><code>&lt;system.web&gt;
  &lt;roleManager enabled=""true"" defaultProvider=""AspNetSqlRoleProvider""&gt;
    &lt;providers&gt;
      &lt;clear/&gt;
      &lt;add name=""AspNetSqlRoleProvider"" type=""System.Web.Security.SqlRoleProvider"" connectionStringName=""DefaultConnection"" applicationName=""myDatabaseName"" /&gt;
    &lt;/providers&gt;
  &lt;/roleManager&gt;
&lt;/system.web&gt;
</code></pre>

<p>Thanks for the help.</p>
",<c#><entity-framework><asp.net-mvc-5><roles><asp.net-identity>
58013131,How to export logs from Symfony profiler to an external file?,"<p>I am now using Symfony 4 LoggerInterface to create custom error messages to display on the logger in my dev toolbar.</p>

<pre><code>//use Psr\Log\LoggerInterface;
//public function __construct(LoggerInterface $logger)
$this-&gt;logger-&gt;alert('Not found Country with ID: '.$line['CodCtrDes'] );
</code></pre>

<p><a href=""https://i.stack.imgur.com/FFLby.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FFLby.png"" alt=""enter image description here""></a></p>

<p>I see the errors/warnings that I've created but I can't find the way to export those logs. I want to keep track of all the logs I generate on my controller by saving them in my project folder as .txt  </p>

<p>Is there any way of doing that? I couldn't find anything related.</p>
",<symfony4><profiler>
19629101,@PostConstruct analog for external final bean,"<p>I want to find analog <code>@PostConstruct</code> spring annotation for external bean. 
I don't have oportunity to change source code of this class and this class is final.</p>

<p>other words: how to invoke external method after bean constructing?</p>
",<java><spring><annotations><initialization>
58770885,How to log when the finalize method was not called?,"<p>I am not using the finalize method in my application but this question is out of curiosity.</p>

<p>Assume that there is finalize method in a class and I would like to log a warning message that finalize was not called.</p>

<p>How to do this ?</p>

<p>Any tips ? </p>
",<java><java-8>
28325392,snmp logging through syslog-ng,"<p>I want to log <code>snmpd logs</code> by <code>syslog-ng</code>.
I added below lines in <code>syslog-ng.conf</code> file</p>

<pre><code>filter f_snmpd { program(""snmpd""); };

destination df_snmpd { file(""/var/log/snmplog""); };

log {

    source(s_all);
    filter(f_snmpd);
    destination(df_snmpd);
};
</code></pre>

<p>But the above code is only capturing standard output logs liek below:</p>

<blockquote>
  <p>Feb  4 17:21:31 snmpd[1612]: snmpd: send_trap: Failure in sendto
  (Network is unreachable)</p>
</blockquote>

<p>But I want more logs for <code>snmpd</code>.
Please tell me how to collect all the logs of <code>snmpd daemon</code> through <code>syslog-ng</code> ?</p>

<p>Thanks</p>
",<syslog-ng><snmpd>
63157738,UseSerilog unknown reference in ConfigureWebHostDefaults,"<p>i followed few tutorials and im stuck building the default dotnet 3.1 with serilog
in program.cs
this line wont build
here is the code
<a href=""https://github.com/guymalka/serilog-dotnetcore/blob/master/Program.cs"" rel=""nofollow noreferrer"">https://github.com/guymalka/serilog-dotnetcore/blob/master/Program.cs</a>
what reference do I need to add here?</p>
",<asp.net-core><.net-core><serilog>
3730032,HTTP Error 405 Method not allowed error in admin log,"<p>I'm getting a strange error in my newly deployed application in appengine. In the error log it tells me that PageRank, TwitterBot and a couple of others. I would guess this is due to these try to get data using ajax or another async service resulting in ""same origin policy""-problem.</p>

<p>My question is does anyone know what these bots are trying to get? For example if pagerank (google page rank I would guess) can't get any info about my application would this effect my page rank. And anyone know what the twitterbot does? And if there is away to handle to provide a proper response?</p>
",<google-app-engine>
13944864,Why logging.handlers.TimedRotatingFileHandler creates new log files owned by root?,"<p>I want to rotate the logs of a Django / apache2 / wsgi website. But sometimes (not always, which is even more strange) logging.handlers.TimedRotatingFileHandler creates new log files owned by root!
So my application doesn't have write access any more to the log, and gives me a server error.</p>

<p>I have specified umask=0007 in my WSGIDaemonProcess setting, but that doesn't help either.</p>

<p>How can that happen? and how to fix it? </p>
",<logging><mod-wsgi>
22932324,Python script analyzing log files,"<p>I am creating a python script to analyze a log file(example: <a href=""http://www.monitorware.com/en/logsamples/apache.php"" rel=""nofollow"">http://www.monitorware.com/en/logsamples/apache.php</a>) and needs suggestions of methods that I can use to achieve this. </p>

<ol>
<li>reading the log file with <code>open</code> method. OK.</li>
<li>counting elapsed time of the log? Which method do I use to read from specific position within the log line? Example: <code>64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] ""GET /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables HTTP/1.1"" 401 12846
</code> How do I count elapsed time after a certain position like year in this case?
<br><br>
I also need to display requests served per minute, total amount of data sent, average amount of data sent, largest amount of data sent in a single request.</li>
</ol>
",<python><log-analysis>
71462393,Creating logger middleware using morgan,"<p>I would like to create a middleware using morgan, i tryed to export the middleware function, then require in app.js. I don't kown why this is not working</p>
<p><strong>Middleware:</strong></p>
<pre class=""lang-js prettyprint-override""><code>    const morgan = require('morgan');
    const rfs = require(&quot;rotating-file-stream&quot;);

    const rfsStream = rfs.createStream(&quot;logs/log.txt&quot;, {
        size: '10M', // rotate every 10 MegaBytes written
        interval: '1d', // rotate daily
        compress: 'gzip' // compress rotated files
    })

    function logger(req, res, next){
        morgan('tiny', {
        stream: rfsStream
        })
        next();
    }

    module.exports.logger = logger;
</code></pre>
<p><strong>App:</strong></p>
<pre class=""lang-js prettyprint-override""><code>    const express = require('express');
    const app = express();
    const PORT = 4000;
    const { logger } = require('./middlewares/logger');

    app.get('/', logger, (req, res) =&gt; {
        res.send('Hello World!')
    });

    app.listen(PORT, () =&gt; {
        console.log(`app running on port: ${PORT}`);
    });
</code></pre>
",<javascript><node.js><express><middleware><morgan>
71443756,Adding logs on the Azure Application insights from the ASP.Net MVC framework 4.6.2,"<p>I wanted to add logs on the Azure Application Insights in my application, ASP.Net Web application MVC, .Net Framework is 4.6.2.</p>
<p>I do have added references to below nuget packages</p>
<ul>
<li>Microsoft.ApplicationInsights</li>
<li>Microsoft.Extensions.Logging</li>
</ul>
<p>I do have added below code in Global.asax.cs in the applicatin_start
TelemetryConfiguration.Active.TelemetryInitializers.Add(new MyTelemetryInitializer());</p>
<p>Inside HomeController.cs, I have added below code, but it is giving me below error at the line _logger.LogTrace()</p>
<p><strong>Error</strong></p>
<p>System.ArgumentNullException: 'Value cannot be null.
Parameter name: logger'</p>
<p><strong>Code</strong></p>
<pre><code>public class HomeController : Controller
{
    private readonly ILogger&lt;HomeController&gt; _logger;
    public HomeController()
    {
        IServiceCollection services = new ServiceCollection();
        IServiceProvider serviceProvider = services.BuildServiceProvider();
        _logger = serviceProvider.GetService&lt;ILogger&lt;HomeController&gt;&gt;();
    }
    public ActionResult Index()
    {
        ViewBag.Title = &quot;Home Page&quot;;
        _logger.LogTrace(&quot;Some trace message from Version 462&quot;);
        return View();
    }
}
</code></pre>
<p>Please let me know where I am going wrong.</p>
<p>Thanks,
Tushar</p>
",<asp.net><azure-application-insights>
5444887,Java JNA redirecting output to logger,"<p>I am accessing OpenCV via JNA, when my processes takes too long the process a frame opencv prints a ""Camera dropped frame"" message. My problem is it produces too many messages which makes the console useless for my logging purposes. Below google code search shows it is printed to cout,</p>

<p><a href=""http://www.google.com/codesearch?hl=en&amp;lr=&amp;q=%22camera+dropped+frame%21%22&amp;sbtn=Search"" rel=""nofollow"">http://www.google.com/codesearch?hl=en&amp;lr=&amp;q=%22camera+dropped+frame%21%22&amp;sbtn=Search</a></p>

<p>I have tried to redirect both out and err to my logs but I still get the messages printed to console is there a way to get rid of them</p>

<pre>
<code>
      (System/setOut (proxy [java.io.PrintStream] [System/out] 
                       (print [s] ;;(trace s)
                              )
                       (println [s] ;;(trace s)
                                )
                       ))

      (System/setErr (proxy [java.io.PrintStream] [System/err] 
                       (print [s] ;;(trace s)
                              )
                       (println [s] ;;(trace s)
                                )
                       ))
</code>
</pre>
",<java><logging><java-native-interface><jna>
4703765,Implementing Open Source Library: How to handle logging?,"<p>I am in the process of implementing logging support in an open source library I am working on. Most 3rd party libraries seem to explicitly choose a ""preferred"" logging library such as <a href=""http://logging.apache.org/log4net/"" rel=""nofollow"">Log4Net</a> or <a href=""http://nlog-project.org/"" rel=""nofollow"">NLog</a> etc and then require that the consumer of their library ""deal with it"". Thankfully, we have a library like <a href=""http://netcommon.sourceforge.net/"" rel=""nofollow"">Common.Logging</a> to address this issue in our consuming application(s) that unifies these 3rd party library logging implementations.</p>

<p>I was going to try and avoid referencing another 3rd party library from my own open source library to avoid bringing in yet another assembly reference in to someone else's application. Perhaps this is not a concern, and I should just stop there? </p>

<p>Assuming that some people agree that excessive assembly references are annoying (and since someone will mention it), I personally, I don't like using ILMerge for this type of situation, as you may easily have several libraries that use Log4Net and if they each ILMerged in the assembly it is just bloating the size of an application in my opinion. </p>

<p>To that end, I was thinking of implementing and exposing a LogBridge to allow the consumer of my library to hook in to my logging calls if so desired (would be off by default). <em>Also let me stress that I am not talking about implementing my own logging framework, just ensuring that I expose logging if someone is concerned with comsuming it.</em> I was thinking the consuming implementation would appear something like:</p>

<pre><code>public class SomeSetupClass 
{
  private void SomeSetupMethod()
  {
    var log = LogManager.GetLogger(""LogSourceName"");
    var logBridge = new LogBridge()
                      {
                        DebugEnabled = log.IsDebugEnabled,
                        InformationEnabled = log.IsInfoEnabled,
                        WarningEnabled = log.IsWarnEnabled,
                        ErrorEnabled = log.IsErrorEnabled,
                        CriticalEnabled = log.IsFatalEnabled
                      };

    logBridge.DebugMessageReceived += (sender, e) =&gt; log.Debug(e.Message);
    logBridge.InformationMessageReceived += (sender, e) =&gt; log.Info(e.Message);
    logBridge.WarningMessageReceived += (sender, e) =&gt; log.Warn(e.Message);
    logBridge.ErrorMessageReceived += (sender, e) =&gt; log.Error(e.Message);
    logBridge.CrticalMessageReceived += (sender, e) =&gt; log.Fatal(e.Message);      }
  }
}
</code></pre>

<p>Does this approach make sense? Am I over thinking this after being on vacation for too long and I should just reference <a href=""http://logging.apache.org/log4net/"" rel=""nofollow"">Log4Net</a> or <a href=""http://nlog-project.org/"" rel=""nofollow"">NLog</a> etc and be done with it? Am I missing any major cons of this approach? Does the rough API make sense?</p>

<p>As always, curious what everyone thinks...</p>

<p><strong>Update</strong></p>

<p>Curious if people think that jgauffin solution is the better way to go? I had given it some thought prior to this post; my thought was that the LogBridge would be easier to hook up for consumers rather than requiring a custom interface to be implemented in a consuming project? Thoughts?</p>
",<.net><logging>
29002508,Getting error with PubNub PNLog,"<p>Hi I'm using PubNub api in my project. I'm getting <strong>Implicit declaration of function 'PNLog' is invalid in c99.</strong> I googled about this error, But I can't find solution.
Here is my code:</p>

<pre><code>- (void)pubnubClient:(PubNub *)client error:(PNError *)error 
{
    PNLog(PNLogGeneralLevel, self, @""PubNub client report that error occurred: %@"", error);
}

- (void)pubnubClient:(PubNub *)client willConnectToOrigin:(NSString *)origin 
{
    PNLog(PNLogGeneralLevel, self, @""PubNub client is about to connect to PubNub origin at: %@"", origin);
}

- (void)pubnubClient:(PubNub *)client didConnectToOrigin:(NSString *)origin 
{
    PNLog(PNLogGeneralLevel, self, @""PubNub client successfully connected to PubNub origin at: %@"", origin);
}
</code></pre>

<p>This error is killing my time. Please help me.</p>
",<ios><objective-c><iphone><xcode><pubnub>
28978556,Design pattern used in logging framework,"<p>I tried to search this question on internet, however couldn't find the answer.
Please excuse and point me if the question is duplicate.</p>

<p>Many times, I have been told that Logger uses Singleton as well as Factory pattern (i.e. when we are passing different debug level - ERROR, DEBUG... etc then getLogger() will return different objects)</p>

<p>I need more explanation, how Singleton and Factory pattern both are internally implemented with logger.</p>

<p>Please help.</p>

<p>/Saurabh</p>
",<logging><singleton><factory>
39411450,SonarQube complains: Either log or rethrow this exception,"<p>I am running SonarQube 5 for code quality check after integrating the code with Maven.</p>
<p>Sonar is complaining that I should:</p>
<blockquote>
<p>Either log or rethrow this exception.</p>
</blockquote>
<p>in following piece of code:</p>
<pre class=""lang-java prettyprint-override""><code>public static Date convertStringtoDate(String stringDate) {
    stringDate = StringUtils.trimToNull(stringDate);
    SimpleDateFormat dfm = new SimpleDateFormat(&quot;dd-MMM-yyyy&quot;);
    Date date = null;

    if (stringDate != null) {
        try {
            date = dfm.parse(stringDate);
        } catch (Exception e) {
            logger.info(&quot;Cannot convert String to Date: &quot;,convertStringtoDate(e.getMessage()));
        }
    }

    return date;    
}
</code></pre>
<p>What am I missing here?</p>
",<java><spring><exception><sonarqube>
13078129,how to define multiple log4j configs with Jetty server in web.xml,"<p>Here's what I want to do:
- being able to have separated log4j.properties for each different deployment ""war""
- being able to define in ant build, or web.xml, using system parameter on which log properties to use. </p>

<p>My project setup is Jetty with Jersey as REST API, without Spring. </p>

<p>I've done some research and it turns there are other Spring solutions to set  in webl.xml but I'm not using spring. 
I also know Jetty is using slf4j but if switching to slf4j, would I be able to do this more easily?</p>

<p>What would be a best way to solve this, so that in web.xml or ant build, log4j config can be customized defined?</p>

<p>Thanks a lot!</p>

<p>EDIT:
I figured that I can start another servlet with some init-param defined. Then on a separated  HttpServlet implementation to set the PropertyConfigurator.configure([name of the log4j config]);
Is this adding one more servlet an ideally way of handling this?</p>
",<log4j><jetty><config><web.xml>
12481605,Putting Logger.info in static block,"<p>I have the following class</p>

<pre><code>public class MyClass
{
    private static final Logger logger = Logger.getLogger(MyClass.class);

    static
    {
        logger.info(""some text"");
    }
}
</code></pre>

<p>Is it safe to assume that by the time we reach <code>logger.info</code>, the log4j system is initialized and is ready to emit logs? </p>

<p>It seems that if I am able to do a <code>Logger.getLogger()</code> and get back a valid Logger instance, it means that Log4j is initialized, right?</p>
",<java><log4j>
58266723,Drools Global Logger in DRL - Illegal class for global,"<p>I am trying to pass an slf4j Logger object to my Drools rule as a global.</p>

<p>In my calling Java class I define the logger and pass it to the rule via the setGlobal kie server command:</p>

<pre><code>private static final Logger LOGGER = LoggerFactory.getLogger(KieServerTester.class);

Command&lt;?&gt; setGlobalCommand = commandsFactory.newSetGlobal(""logger"", LOGGER);
    commands.add(setGlobalCommand);
</code></pre>

<p>And in my rule file I have the global defined as:</p>

<pre><code>global org.slf4j.Logger logger;
</code></pre>

<p>However when I execute the command I get this error:</p>

<blockquote>
  <p>ERROR [org.kie.server.services.drools.DroolsKieContainerCommandServiceImpl] (default task-1) Error calling container 'mycontainer': java.lang.RuntimeException: Illegal class for global. Expected [org.slf4j.Logger], found [java.util.LinkedHashMap].</p>
</blockquote>

<p>I have no idea where it's getting LinkedHashMap from. I have stepped through the calling code but can't see where the map appears.</p>

<p>If I change my global in the rule file to be a LinkedHashMap, I don't get the error.
So somehow it looks like my logger object in the Java class is being converted to a LinkedHashMap.</p>

<p>Any help appreciated, thanks.</p>
",<drools><kie><drools-kie-server><kie-server>
39616779,Send log from PhantomJS to Graylog2,"<p>I'm trying to send a log message from PhantomJS script to Graylog. Is there a way to do that?</p>
",<phantomjs><graylog2><graylog>
39606965,Logging web application request logs to a separate file,"<p>My application is on spring framework and for logging i am using LogBack and Slf4j.</p>

<p>I have written a filter to write request logs, currently my application as well as request log all go to a single file, as both are using log level of INFO. Is there a way i can push my application logs and requests to different files.</p>

<p>Any pointers and leads will be helpful. </p>
",<java><spring><logback><slf4j>
68343495,How to set log level for a RabbitMQ plugin,"<p>According to <a href=""https://www.rabbitmq.com/logging.html#log-message-categories"" rel=""nofollow noreferrer"">https://www.rabbitmq.com/logging.html#log-message-categories</a> I can set log levels for certain categories in RabbitMQ.</p>
<p>Now I want to set the log level of a specific plugin (namely <code>rabbitmq_auth_backend_oauth2</code>) to debug, is this possible?
If so, how can this be achieved?</p>
",<rabbitmq>
40853573,Cassandra console log messages,"<p>I'm using DataStax Cassandra on Windows 10 and accessing in Java. The log messages are appended to Eclipse console. I need to out them to the logger. I tried to update the logbakc and logback-tools xml files but got no effect.
I changed the level of STDOUT appender in logback to ERROR to print only the errors, the restarted the service but got no effect, all the messages are kept displayed in the console</p>

<pre><code>appender name=""STDOUT"" class=""ch.qos.logback.core.ConsoleAppender""&gt;
    &lt;filter class=""ch.qos.logback.classic.filter.ThresholdFilter""&gt;
      &lt;level&gt;ERROR&lt;/level&gt;
    &lt;/filter&gt;
    &lt;encoder&gt;
      &lt;pattern&gt;%-5level %date{HH:mm:ss,SSS} %msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
  &lt;/appender&gt;
</code></pre>

<p>Any advise?</p>
",<java><logging><cassandra>
13466472,Asynchronous write error log file,"<p>I am creating a public facing web site and one of the requirement is to write all the errors/warning in a log file. </p>

<p>I have try catch block everywhere and also I can catch the errors in the application error event.</p>

<p>Being a public facing web site, I am afraid that log file may grow exponentially (even if I create new files every day) and it may decrease the site performance. Is there any way to write the error files asynchronously, so it will   not have any impact on the users? </p>

<p>Any sample or guidance is highly appricated. </p>

<p>My site is in ASP.NET Web forms and c#.</p>

<p>Thanks</p>
",<c#><asp.net><logging><file-io><asynchronous>
59193732,How do I find the last instance of a string in a log?,"<p>I made a log file, and I want to take it and want to find the last instance that the specific user was online, the log file looks like this:</p>

<pre class=""lang-none prettyprint-override""><code>----------------------------------------------
Logging started: 2019-12-05 12:42:19.591833 

Num of members in Test Server: 12
Members: 

test12345#0720
A part of server: Test Server
Current status: idle
Current activity: None 

Logging complete
-----------------
</code></pre>

<p>Now this repeats multiple times because it adds a new log every <strong>X</strong> amount of time, and I want to find the last time Z user was online. (I have the name and discriminator of the user)</p>
",<python><python-3.x><string>
28583665,How to use docker logs,"<p>The question may be a bit of newbie.
I run <code>docker exec -it mycontainer bash</code> to enter into a daemon container(postgresSQL ),
and <code>echo</code> something.
now I exit it , and use <code>docker logs mycontainer</code> so as to see my echos.</p>

<p>According to</p>

<blockquote>
  <p>The docker logs command batch-retrieves logs present at the time of execution.
  The docker logs --follow command will continue streaming the new output from the container's STDOUT and STDERR.</p>
</blockquote>

<p>The <code>docker logs</code> listen <code>STDOUT</code> of the container, why I don't see my string just <em>echoed</em> inside it?</p>
",<docker>
39448149,How can Log4j be used with Spark cluster in a distributed environment?,"<p>In our project, we are going to use spark cluster with 100 nodes. For logging purpose, we are using log4j but not sure if it will be supported in a distributed environment. In this scenario,</p>

<ol>
<li>Where will be the logs written? Would there be any centralised location? </li>
<li>Would multiple nodes be able to write in a single log file?</li>
<li>It would be helpful if you could provide any documentation for the same</li>
</ol>
",<java><logging><apache-spark>
13347806,Software development methodology - Competitive Development,"<p>What is the name of the software development methodology in which:</p>

<ul>
<li>Multiple teams work on the same feature in isolation</li>
</ul>

<p>At the end of the sprint, each team presents solution and:</p>

<ul>
<li>The best solution wins and is accepted</li>
<li>The losing solutions are dropped</li>
</ul>
",<agile><methodology>
60250804,Need explanation on logging.level.org.hibernate.SQL,"<p>I'm messing around with Spring Data, and tryna see what happens at the time repository save new entity by using Logging. Easy solution: just 2 lines of properties into application.properties</p>

<p><code>logging.level.org.hibernate.type.descriptor.sql.BasicBinder = TRACE
 logging.level.org.hibernate.SQL = TRACE</code></p>

<p>but I wonder 2 things:<br>
1) Why Intellij doesn't autocomplete for me at <code>logging.level.org.hibernate.SQL = TRACE</code> (I'm using Intellij Ultimate - Student license (Version: 2019.3.3))<br>
2) Why there isn't any documentation on org.hibernate.SQL, and maybe it is the reason why Intellij can't suggest it (I tried finding it on <a href=""https://docs.jboss.org/hibernate/orm/3.5/javadocs/org/hibernate/"" rel=""nofollow noreferrer"">https://docs.jboss.org/hibernate/orm/3.5/javadocs/org/hibernate/</a>)<br>
I'm just really can't get over it.
Really appreciate any more clear answer on this!</p>
",<java><spring><hibernate><jpa><spring-data>
57900363,Jenkins on windows: How to I enable log rotation for `jenkins.out.log`,"<p>We currently run Jenkins on a Windows machine and the system log (<code>jenkins.out.log</code> and <code>access.log</code>) is growing quite huge. Until now I did not find a way to enable log rotation when running Jenkins on Windows.</p>

<p>The <a href=""https://stackoverflow.com/questions/31610924/how-to-enable-log-rotation-in-jenkins-for-weekly"">post here</a> doesn't answer this question specifically and also mention the job log. My concern is another.</p>

<p><a href=""https://wiki.jenkins.io/display/JENKINS/Logging"" rel=""nofollow noreferrer"">Official documentation</a> doesn't state anything, neither does the <a href=""https://support.cloudbees.com/hc/en-us/articles/221764048-Log-file-rotation"" rel=""nofollow noreferrer"">the Cloudbees docu</a></p>
",<jenkins><logging>
23961594,How can I do logging in Azure Web Jobs?,"<p>So I have tried:</p>

<pre><code>Trace.TraceInformation(""Trace.Information Found message on queue"");
Debug.WriteLine(""Debug Found message on queue""); 
Trace.WriteLine(""Trace.WriteLine Found message on queue"");
Console.WriteLine(""Console.WriteLine Found message on queue"");
</code></pre>

<p>But neither of them outputs to the Azure portal Web Jobs output log.</p>

<p>What am I missing?</p>
",<azure><azure-webjobs>
11285533,crash log SIGABRT after selecting picture with UIImagePicker,"<p>Could someone help me and explain the following crash log?</p>

<p>I'm building my first (iOS) app and incidentally got this crash after selecting (and zooming) a picture from  my PhotoLibrary.</p>

<p>Looking at the log, it seems to crash a bit later, though.</p>

<p>I'm new to the crash logs, could someone point out the exact reason/location of the crash for me to learn how to read this?
Are code fragments necessary for analysis?</p>

<p>Thanks in advance!</p>

<pre><code>Incident Identifier: 806191F3-8C7A-4B77-B395-192E7C63AD12
CrashReporter Key:   ec9cb673f6ebb95077c5b905e3b9417a68d15d19
Hardware Model:      iPhone4,1
Process:         Mijn Kinderen [23756]
Path:            /var/mobile/Applications/0ED97506-C765-4D19-B3B1-6A04AFCABBB8/Mijn Kinderen.app/Mijn Kinderen
Identifier:      Mijn Kinderen
Version:         ??? (???)
Code Type:       ARM (Native)
Parent Process:  launchd [1]

Date/Time:       2012-06-26 15:44:20.011 +0200
OS Version:      iPhone OS 5.1.1 (9B206)
Report Version:  104

Exception Type:  EXC_CRASH (SIGABRT)
Exception Codes: 0x00000000, 0x00000000
Crashed Thread:  0

Last Exception Backtrace:
0   CoreFoundation                  0x358b588f __exceptionPreprocess + 163
1   libobjc.A.dylib                 0x37c5c259 objc_exception_throw + 33
2   CoreFoundation                  0x358b5789 +[NSException raise:format:] + 1
3   Foundation                      0x3539d3a3 -[NSAssertionHandler handleFailureInMethod:object:file:lineNumber:description:] + 91
4   UIKit                           0x33556807 -[UIDatePickerView _updateBitsForDate:forced:andReload:animateIfNeeded:] + 147
5   UIKit                           0x334756c5 -[UIDatePickerView _setDate:animated:forced:] + 349
6   UIKit                           0x33475563 -[UIDatePickerView setDate:animated:] + 31
7   UIKit                           0x33556385 -[UIDatePicker setDate:] + 37
8   Mijn Kinderen                   0x000e2611 -[MKWijzigGebeurtenisViewController viewDidLoad] (MKWijzigGebeurtenisViewController.m:68)
9   UIKit                           0x33322c8b -[UIViewController view] + 167
10  UIKit                           0x33347481 -[UIViewController nextResponder] + 21
11  UIKit                           0x3330bbd5 -[UIResponder _containsResponder:] + 37
12  UIKit                           0x333ce359 -[UINavigationController defaultFirstResponder] + 57
13  UIKit                           0x333143b5 -[UIResponder(Internal) _deepestDefaultFirstResponder] + 25
14  UIKit                           0x33314263 -[UIResponder(Internal) _promoteDeepestDefaultFirstResponder] + 31
15  UIKit                           0x333ce31f -[UIWindowController transitionViewDidStart:] + 83
16  UIKit                           0x333836cb -[UITransitionView _didStartTransition] + 71
17  UIKit                           0x3338300f -[UITransitionView transition:fromView:toView:] + 999
18  UIKit                           0x333ccc05 -[UIWindowController transition:fromViewController:toViewController:target:didEndSelector:] + 4937
19  UIKit                           0x33426d71 -[UIViewController _dismissViewControllerWithTransition:from:completion:] + 1733
20  UIKit                           0x33388d85 -[UIViewController dismissViewControllerWithTransition:completion:] + 757
21  UIKit                           0x33388d85 -[UIViewController dismissViewControllerWithTransition:completion:] + 757
22  Mijn Kinderen                   0x000e303f -[MKWijzigGebeurtenisViewController imagePickerController:didFinishPickingMediaWithInfo:] (MKWijzigGebeurtenisViewController.m:180)
23  UIKit                           0x33554c5b -[UIImagePickerController _imagePickerDidCompleteWithInfo:] + 111
24  PhotoLibrary                    0x31593079 PLNotifyImagePickerOfImageAvailability + 45
25  PhotoLibrary                    0x315a4797 -[PLUICameraViewController cameraView:photoSaved:] + 131
26  PhotoLibrary                    0x315d28db -[PLCameraView cropOverlay:didFinishSaving:] + 227
27  CoreFoundation                  0x358141fb -[NSObject performSelector:withObject:] + 43
28  Foundation                      0x353d8747 __NSThreadPerformPerform + 351
29  CoreFoundation                  0x35889ad3 __CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE0_PERFORM_FUNCTION__ + 15
30  CoreFoundation                  0x3588929f __CFRunLoopDoSources0 + 215
31  CoreFoundation                  0x35888045 __CFRunLoopRun + 653
32  CoreFoundation                  0x3580b4a5 CFRunLoopRunSpecific + 301
33  CoreFoundation                  0x3580b36d CFRunLoopRunInMode + 105
34  GraphicsServices                0x374a7439 GSEventRunModal + 137
35  UIKit                           0x33317cd5 UIApplicationMain + 1081
36  Mijn Kinderen                   0x000da36b main (main.m:16)
37  Mijn Kinderen                   0x000da310 start + 40


Thread 0 name:  Dispatch queue: com.apple.main-thread
Thread 0 Crashed:
0   libsystem_kernel.dylib          0x3616b32c __pthread_kill + 8
1   libsystem_c.dylib               0x32cb7208 pthread_kill + 48
2   libsystem_c.dylib               0x32cb0298 abort + 88
3   libc++abi.dylib                 0x35c6df64 abort_message + 40
4   libc++abi.dylib                 0x35c6b346 _ZL17default_terminatev + 18
5   libobjc.A.dylib                 0x37c5c350 _objc_terminate + 140
6   libc++abi.dylib                 0x35c6b3be _ZL19safe_handler_callerPFvvE + 70
7   libc++abi.dylib                 0x35c6b44a std::terminate() + 14
8   libc++abi.dylib                 0x35c6c81e __cxa_rethrow + 82
9   libobjc.A.dylib                 0x37c5c2a2 objc_exception_rethrow + 6
10  CoreFoundation                  0x3580b506 CFRunLoopRunSpecific + 398
11  CoreFoundation                  0x3580b366 CFRunLoopRunInMode + 98
12  GraphicsServices                0x374a7432 GSEventRunModal + 130
13  UIKit                           0x33317cce UIApplicationMain + 1074
14  Mijn Kinderen                   0x000da364 main (main.m:16)
15  Mijn Kinderen                   0x000da308 start + 32

Thread 1 name:  Dispatch queue: com.apple.libdispatch-manager
Thread 1:
0   libsystem_kernel.dylib          0x3615b3a8 kevent + 24
1   libdispatch.dylib               0x34745f04 _dispatch_mgr_invoke + 708
2   libdispatch.dylib               0x34745c22 _dispatch_mgr_thread + 30

Thread 2 name:  WebThread
Thread 2:
0   libsystem_kernel.dylib          0x3616b0d8 __psynch_mutexwait + 24
1   libsystem_c.dylib               0x32c6c674 pthread_mutex_lock + 376
2   WebCore                         0x316674e8 _ZL17_WebTryThreadLockb + 208
3   WebCore                         0x316677ec _ZL14WebRunLoopLockP19__CFRunLoopObservermPv + 24
4   CoreFoundation                  0x35889b14 __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__ + 12
5   CoreFoundation                  0x35887d50 __CFRunLoopDoObservers + 252
6   CoreFoundation                  0x3588816a __CFRunLoopRun + 946
7   CoreFoundation                  0x3580b49e CFRunLoopRunSpecific + 294
8   CoreFoundation                  0x3580b366 CFRunLoopRunInMode + 98
9   WebCore                         0x3170ac9c _ZL12RunWebThreadPv + 396
10  libsystem_c.dylib               0x32c7872e _pthread_start + 314
11  libsystem_c.dylib               0x32c785e8 thread_start + 0

Thread 3 name:  com.apple.coremedia.player.async
Thread 3:
0   libsystem_kernel.dylib          0x3616b068 __psynch_cvwait + 24
1   libsystem_c.dylib               0x32c78a46 _pthread_cond_wait + 634
2   libsystem_c.dylib               0x32c787c2 pthread_cond_wait + 34
3   CoreMedia                       0x309ec868 FigSemaphoreWaitRelative + 268
4   MediaToolbox                    0x3670f3e6 fpa_AsyncMovieControlThread + 22
5   CoreMedia                       0x30a0b8b4 figThreadMain + 168
6   libsystem_c.dylib               0x32c7872e _pthread_start + 314
7   libsystem_c.dylib               0x32c785e8 thread_start + 0

Thread 4 name:  Dispatch queue: com.apple.camera.avcapturesession
Thread 4:
0   libsystem_kernel.dylib          0x3615b004 mach_msg_trap + 20
1   libsystem_kernel.dylib          0x3615b1fa mach_msg + 50
2   CoreFoundation                  0x358893ec __CFRunLoopServiceMachPort + 120
3   CoreFoundation                  0x35888124 __CFRunLoopRun + 876
4   CoreFoundation                  0x3580b49e CFRunLoopRunSpecific + 294
5   CoreFoundation                  0x3580b366 CFRunLoopRunInMode + 98
6   AVFoundation                    0x357514d0 -[AVRunLoopCondition _waitInMode:untilDate:] + 348
7   AVFoundation                    0x3575136c -[AVRunLoopCondition waitUntilDate:inMode:] + 20
8   AVFoundation                    0x3573e13a -[AVCaptureSession _stopPreviewing] + 438
9   AVFoundation                    0x3573e2d6 -[AVCaptureSession _setRunning:] + 166
10  AVFoundation                    0x3573de42 -[AVCaptureSession stopRunning] + 274
11  PhotoLibrary                    0x31584590 __33-[PLCameraController stopPreview]_block_invoke_0 + 96
12  libdispatch.dylib               0x34742c52 _dispatch_call_block_and_release + 6
13  libdispatch.dylib               0x34744d08 _dispatch_queue_drain + 268
14  libdispatch.dylib               0x34744b6e _dispatch_queue_invoke$VARIANT$mp + 34
15  libdispatch.dylib               0x347457e0 _dispatch_worker_thread2 + 204
16  libsystem_c.dylib               0x32c72df4 _pthread_wqthread + 288
17  libsystem_c.dylib               0x32c72cc8 start_wqthread + 0

Thread 5:
0   libsystem_kernel.dylib          0x3616bcd4 __workq_kernreturn + 8
1   libsystem_c.dylib               0x32c72f36 _pthread_wqthread + 610
2   libsystem_c.dylib               0x32c72cc8 start_wqthread + 0

Thread 0 crashed with ARM Thread State:
    r0: 0x00000000    r1: 0x00000000      r2: 0x00000001      r3: 0x00000000
    r4: 0x00000006    r5: 0x3eec2d98      r6: 0x00000002      r7: 0x2fed7a48
    r8: 0x002ee2f0    r9: 0x00000000     r10: 0x3f85b9b4     r11: 0x00000000
    ip: 0x00000148    sp: 0x2fed7a3c      lr: 0x32cb720f      pc: 0x3616b32c
  cpsr: 0x000f0010

Binary Images:
   0xd9000 -    0xe6fff +Mijn Kinderen armv7  &lt;f6dfc4f1cc023981af9c8c1f978561c8&gt; /var/mobile/Applications/0ED97506-C765-4D19-B3B1-6A04AFCABBB8/Mijn Kinderen.app/Mijn Kinderen
0x2fed8000 - 0x2fef9fff  dyld armv7  &lt;77eddfd654df393ba9c95ff01715fd08&gt; /usr/lib/dyld
0x30537000 - 0x305eafff  iTunesStore armv7  &lt;b3c0cce5f8e632e18f841c32b68f57a1&gt; /System/Library/PrivateFrameworks/iTunesStore.framework/iTunesStore
0x305fd000 - 0x30603fff  MobileKeyBag armv7  &lt;e1f06241ef0e3f0aae00f15df572077e&gt; /System/Library/PrivateFrameworks/MobileKeyBag.framework/MobileKeyBag
0x306d7000 - 0x307fcfff  JavaScriptCore armv7  &lt;2ffc6c87b94434288366bd53765ee267&gt; /System/Library/PrivateFrameworks/JavaScriptCore.framework/JavaScriptCore
0x30829000 - 0x30835fff  Accounts armv7  &lt;79f22009b1173e1e81f70fc5c0410119&gt; /System/Library/Frameworks/Accounts.framework/Accounts
0x30836000 - 0x3083cfff  liblockdown.dylib armv7  &lt;9e45ce468a6f31e5b8263f2c224aa800&gt; /usr/lib/liblockdown.dylib
0x308bf000 - 0x308d4fff  libresolv.9.dylib armv7  &lt;66f7557fa4b43979b186e00271839fdb&gt; /usr/lib/libresolv.9.dylib
0x309e6000 - 0x309e9fff  CoreTime armv7  &lt;a398de5ba1e43a11b7008e9bb5a7f6fe&gt; /System/Library/PrivateFrameworks/CoreTime.framework/CoreTime
0x309ea000 - 0x30a32fff  CoreMedia armv7  &lt;e274e1b894753b2eb05cf7b22a36d0c1&gt; /System/Library/Frameworks/CoreMedia.framework/CoreMedia
0x30a6e000 - 0x30fb2fff  FaceCoreLight armv7  &lt;f326d88709683520b251dc53cb847c11&gt; /System/Library/PrivateFrameworks/FaceCoreLight.framework/FaceCoreLight
0x3153d000 - 0x31660fff  PhotoLibrary armv7  &lt;cff5092ea3343d8ebb2159c93c00ac68&gt; /System/Library/PrivateFrameworks/PhotoLibrary.framework/PhotoLibrary
0x31661000 - 0x31e20fff  WebCore armv7  &lt;2690c38c9c5f3c09975d619dd1dfbed7&gt; /System/Library/PrivateFrameworks/WebCore.framework/WebCore
0x31e33000 - 0x31f0bfff  vImage armv7  &lt;caf3648be2933384b6aa1ae7408ab4f0&gt; /System/Library/Frameworks/Accelerate.framework/Frameworks/vImage.framework/vImage
0x31f0c000 - 0x320f0fff  AudioToolbox armv7  &lt;c91e27850452330ea804db6408840fd2&gt; /System/Library/Frameworks/AudioToolbox.framework/AudioToolbox
0x320f1000 - 0x3213bfff  libvDSP.dylib armv7  &lt;441b42aca07b3da39feab25f8349918f&gt; /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libvDSP.dylib
0x32163000 - 0x32179fff  libmis.dylib armv7  &lt;258bc92be5823b239b4412dd42cb4807&gt; /usr/lib/libmis.dylib
0x32185000 - 0x32342fff  ImageIO armv7  &lt;02e3578171fa3b6a969b244275fd2bab&gt; /System/Library/Frameworks/ImageIO.framework/ImageIO
0x324bb000 - 0x324ccfff  libxpc.dylib armv7  &lt;ccf25b1e49ce3b2fa58d8c8546755505&gt; /usr/lib/system/libxpc.dylib
0x324d4000 - 0x324edfff  Twitter armv7  &lt;8fe6d77b99b43d2287e9c51bc4b22456&gt; /System/Library/Frameworks/Twitter.framework/Twitter
0x326df000 - 0x327d0fff  QuartzCore armv7  &lt;35d64a9da5523ae08c9e41511fd3061b&gt; /System/Library/Frameworks/QuartzCore.framework/QuartzCore
0x327e3000 - 0x327e6fff  libsystem_network.dylib armv7  &lt;356cb66612e836968ef24e6e5c3364cc&gt; /usr/lib/system/libsystem_network.dylib
0x32850000 - 0x32856fff  XPCObjects armv7  &lt;dc568831fa5b3b22b673c62bc9d21d16&gt; /System/Library/PrivateFrameworks/XPCObjects.framework/XPCObjects
0x32857000 - 0x32893fff  IMFoundation armv7  &lt;253125b9103c3d13b66923ac6893c25b&gt; /System/Library/PrivateFrameworks/IMCore.framework/Frameworks/IMFoundation.framework/IMFoundation
0x328c0000 - 0x328e0fff  libxslt.1.dylib armv7  &lt;39348471007e39dab80af68b08390456&gt; /usr/lib/libxslt.1.dylib
0x3293d000 - 0x32949fff  CoreVideo armv7  &lt;364fa32d513f3c11b50970120545f1a8&gt; /System/Library/Frameworks/CoreVideo.framework/CoreVideo
0x3294a000 - 0x3296dfff  Bom armv7  &lt;c3435ecd2e5839f89de51edad0e1bb00&gt; /System/Library/PrivateFrameworks/Bom.framework/Bom
0x3299b000 - 0x32a1efff  MapKit armv7  &lt;e39706ac199134a497954e1f1d6d7245&gt; /System/Library/Frameworks/MapKit.framework/MapKit
0x32a1f000 - 0x32a69fff  ManagedConfiguration armv7  &lt;f1fbb825def23043830a095b953a9c94&gt; /System/Library/PrivateFrameworks/ManagedConfiguration.framework/ManagedConfiguration
0x32a84000 - 0x32a8afff  MobileIcons armv7  &lt;ed1b46f917903c9b9baaa2be4392dafe&gt; /System/Library/PrivateFrameworks/MobileIcons.framework/MobileIcons
0x32a8d000 - 0x32a91fff  IOMobileFramebuffer armv7  &lt;42dbc26828e934acabb4f3b0a35d8250&gt; /System/Library/PrivateFrameworks/IOMobileFramebuffer.framework/IOMobileFramebuffer
0x32a92000 - 0x32a93fff  libremovefile.dylib armv7  &lt;402f8956975d3b6fb86ab9b31a43242c&gt; /usr/lib/system/libremovefile.dylib
0x32a94000 - 0x32a95fff  libsystem_sandbox.dylib armv7  &lt;6a8f2f33c7543808a0f4599101c3b61a&gt; /usr/lib/system/libsystem_sandbox.dylib
0x32aa4000 - 0x32aa6fff  MobileInstallation armv7  &lt;215d93dbb0f63cbf828f9126eb7b5349&gt; /System/Library/PrivateFrameworks/MobileInstallation.framework/MobileInstallation
0x32adc000 - 0x32c13fff  MusicLibrary armv7  &lt;32bc794969e534df97a14dc4be228408&gt; /System/Library/PrivateFrameworks/MusicLibrary.framework/MusicLibrary
0x32c14000 - 0x32c40fff  libtidy.A.dylib armv7  &lt;3aacc5b650e037c086a8ff6657d154bf&gt; /usr/lib/libtidy.A.dylib
0x32c41000 - 0x32c65fff  PrintKit armv7  &lt;08509c7bc915358b953de6f5cbef5c56&gt; /System/Library/PrivateFrameworks/PrintKit.framework/PrintKit
0x32c6a000 - 0x32cf6fff  libsystem_c.dylib armv7  &lt;f859ce1ad1773f0ba98d7c6e135b7697&gt; /usr/lib/system/libsystem_c.dylib
0x32d6d000 - 0x32d7efff  DataAccessExpress armv7  &lt;e6144ba265da3bb7b9a263aa1a29b054&gt; /System/Library/PrivateFrameworks/DataAccessExpress.framework/DataAccessExpress
0x32dd9000 - 0x32de0fff  MailServices armv7  &lt;ab2388ce733e38b7a261273a401bbbf1&gt; /System/Library/PrivateFrameworks/MailServices.framework/MailServices
0x32dfc000 - 0x32dfdfff  libdnsinfo.dylib armv7  &lt;9aede8d6579d3430ac39ae5f95cce498&gt; /usr/lib/system/libdnsinfo.dylib
0x32dfe000 - 0x32e01fff  CaptiveNetwork armv7  &lt;f5cc4b97ce9432da9426f12621453325&gt; /System/Library/PrivateFrameworks/CaptiveNetwork.framework/CaptiveNetwork
0x32e02000 - 0x32ea8fff  AddressBookUI armv7  &lt;da424fecc66e3628ab03378ae80b38fc&gt; /System/Library/Frameworks/AddressBookUI.framework/AddressBookUI
0x32ee9000 - 0x32f24fff  libCGFreetype.A.dylib armv7  &lt;55941c96cf1f3b048e72a148c4496c16&gt; /System/Library/Frameworks/CoreGraphics.framework/Resources/libCGFreetype.A.dylib
0x332e6000 - 0x33788fff  UIKit armv7  &lt;cd513a2f22f53d698c3e10f6fe48a63e&gt; /System/Library/Frameworks/UIKit.framework/UIKit
0x33789000 - 0x337b5fff  ACTFramework armv7  &lt;0bc67086eb7b31d090bb4c9c7a54bfb2&gt; /System/Library/PrivateFrameworks/ACTFramework.framework/ACTFramework
0x338de000 - 0x33923fff  GeoServices armv7  &lt;a26be2e76e8730ab91a16502aba376be&gt; /System/Library/PrivateFrameworks/GeoServices.framework/GeoServices
0x33962000 - 0x33967fff  libcopyfile.dylib armv7  &lt;52e874396c393ed29099789ce702cfe2&gt; /usr/lib/system/libcopyfile.dylib
0x33989000 - 0x3399cfff  DataDetectorsCore armv7  &lt;3f4596cbe1b13fdcb427d87de21df3f6&gt; /System/Library/PrivateFrameworks/DataDetectorsCore.framework/DataDetectorsCore
0x339a9000 - 0x33a06fff  StoreServices armv7  &lt;6ce256d3cf433e4aa1af8d696bf1f75d&gt; /System/Library/PrivateFrameworks/StoreServices.framework/StoreServices
0x33a0c000 - 0x33b7ffff  MediaPlayer armv7  &lt;63cdf8f9c66d36e7a4e69e2f6cae854f&gt; /System/Library/Frameworks/MediaPlayer.framework/MediaPlayer
0x33ba1000 - 0x33beafff  AddressBook armv7  &lt;b17a2962e9043e0385c3c2c652155f2b&gt; /System/Library/Frameworks/AddressBook.framework/AddressBook
0x33d2d000 - 0x33d33fff  libnotify.dylib armv7  &lt;9406297de3e43742887890662a87ab53&gt; /usr/lib/system/libnotify.dylib
0x33e19000 - 0x33e23fff  libvMisc.dylib armv7  &lt;e8248c797b9b363594bb652ddf7ce16d&gt; /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libvMisc.dylib
0x341d9000 - 0x341e8fff  SpringBoardServices armv7  &lt;a2363f8ed49932dba415d2d4cd32fb74&gt; /System/Library/PrivateFrameworks/SpringBoardServices.framework/SpringBoardServices
0x341e9000 - 0x341eefff  libsystem_dnssd.dylib armv7  &lt;27bb5462450732e380f5a2c170546e93&gt; /usr/lib/system/libsystem_dnssd.dylib
0x341f5000 - 0x341fffff  libbz2.1.0.dylib armv7  &lt;40e4045fb79e382b8833707746cf28b1&gt; /usr/lib/libbz2.1.0.dylib
0x34290000 - 0x34294fff  Marco armv7  &lt;8dea3e558fe534ff868fc92e215ce53b&gt; /System/Library/PrivateFrameworks/Marco.framework/Marco
0x342d9000 - 0x342fefff  OpenCL armv7  &lt;f4b08361179a3f6bb033415b0d7c6251&gt; /System/Library/PrivateFrameworks/OpenCL.framework/OpenCL
0x34333000 - 0x34339fff  MediaStream armv7  &lt;d3473621f67036dda5ecabeb14c62b4e&gt; /System/Library/PrivateFrameworks/MediaStream.framework/MediaStream
0x3433a000 - 0x34350fff  EAP8021X armv7  &lt;952fcfdec0633aff923768fca1a26fcb&gt; /System/Library/PrivateFrameworks/EAP8021X.framework/EAP8021X
0x343a7000 - 0x343e5fff  IOKit armv7  &lt;fcda71d29d6136dfbd84c1725f4998e5&gt; /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit
0x34487000 - 0x344b0fff  AppleAccount armv7  &lt;2ba44023410231fcb3f72f762ea3ce6e&gt; /System/Library/PrivateFrameworks/AppleAccount.framework/AppleAccount
0x344f0000 - 0x34546fff  GMM armv7  &lt;6b2f7e1aa6be3d69b4c4cf54ed960602&gt; /System/Library/PrivateFrameworks/GMM.framework/GMM
0x34556000 - 0x3469ffff  libicucore.A.dylib armv7  &lt;b70646b63f1f3b33896dd8cb91b8dab1&gt; /usr/lib/libicucore.A.dylib
0x346a0000 - 0x346a0fff  liblangid.dylib armv7  &lt;644ff4bcfbf337b5b5859e3f0fc0a9a8&gt; /usr/lib/liblangid.dylib
0x346a1000 - 0x346acfff  AccountSettings armv7  &lt;373e59421d983c93931cfbad87b1ae35&gt; /System/Library/PrivateFrameworks/AccountSettings.framework/AccountSettings
0x346c8000 - 0x346fffff  Security armv7  &lt;eea56f71fde83c2981f9281dc7823725&gt; /System/Library/Frameworks/Security.framework/Security
0x3473d000 - 0x34741fff  libAccessibility.dylib armv7  &lt;9a17d07b5a3b38cfafdf16f78c99b572&gt; /usr/lib/libAccessibility.dylib
0x34742000 - 0x34758fff  libdispatch.dylib armv7  &lt;9ecfaef4110a3bf9a92d12f0fe8d1d78&gt; /usr/lib/system/libdispatch.dylib
0x34780000 - 0x347d1fff  libstdc++.6.dylib armv7  &lt;c352af5a742e3c7a8d4d7e5f6f454793&gt; /usr/lib/libstdc++.6.dylib
0x347d2000 - 0x347d9fff  AssetsLibraryServices armv7  &lt;38132ecfd74b325fb1a4142bab663c19&gt; /System/Library/PrivateFrameworks/AssetsLibraryServices.framework/AssetsLibraryServices
0x347f9000 - 0x3480afff  AirTraffic armv7  &lt;c9eb888c1bd1322cbda5b01d41be0c7d&gt; /System/Library/PrivateFrameworks/AirTraffic.framework/AirTraffic
0x348a4000 - 0x348a5fff  CoreSurface armv7  &lt;97f871f09f503c98a6371c2b657430d8&gt; /System/Library/PrivateFrameworks/CoreSurface.framework/CoreSurface
0x348c7000 - 0x348d3fff  libz.1.dylib armv7  &lt;36ce86a3dc8c344596c8c325615f374b&gt; /usr/lib/libz.1.dylib
0x348ec000 - 0x34904fff  ChunkingLibrary armv7  &lt;c73a4b4b38ae3702bc1feae489d31634&gt; /System/Library/PrivateFrameworks/ChunkingLibrary.framework/ChunkingLibrary
0x34905000 - 0x3490dfff  MobileWiFi armv7  &lt;b76c3e9fb78234c392058250d4620e72&gt; /System/Library/PrivateFrameworks/MobileWiFi.framework/MobileWiFi
0x3490e000 - 0x34912fff  libGFXShared.dylib armv7  &lt;998fccc16cf735dbb62324202995e193&gt; /System/Library/Frameworks/OpenGLES.framework/libGFXShared.dylib
0x34a9d000 - 0x34ab1fff  PersistentConnection armv7  &lt;54091a638f8731cd85ccf00fa06972c3&gt; /System/Library/PrivateFrameworks/PersistentConnection.framework/PersistentConnection
0x34e82000 - 0x34ec6fff  MobileCoreServices armv7  &lt;757226927a873d5492be721908077b48&gt; /System/Library/Frameworks/MobileCoreServices.framework/MobileCoreServices
0x34ef8000 - 0x34f05fff  libbsm.0.dylib armv7  &lt;750a0de73a733019a77144b805d4d2f8&gt; /usr/lib/libbsm.0.dylib
0x350a8000 - 0x3517ffff  CFNetwork armv7  &lt;765a472c824830eea91b8f02d12867e4&gt; /System/Library/Frameworks/CFNetwork.framework/CFNetwork
0x35180000 - 0x351fffff  libsqlite3.dylib armv7  &lt;bf01f5ed47b033d8bde30d735ff44416&gt; /usr/lib/libsqlite3.dylib
0x352de000 - 0x352e2fff  FTClientServices armv7  &lt;21de970d7ebb3e7fb502a0a5451b0806&gt; /System/Library/PrivateFrameworks/FTClientServices.framework/FTClientServices
0x35334000 - 0x354b2fff  Foundation armv7  &lt;c40ddb073142315bb4ebb214343d0b7f&gt; /System/Library/Frameworks/Foundation.framework/Foundation
0x354d5000 - 0x354dbfff  IAP armv7  &lt;17eddbf5590d3cb88d4acbda27447f5b&gt; /System/Library/PrivateFrameworks/IAP.framework/IAP
0x354ef000 - 0x35581fff  HomeSharing armv7  &lt;11ca6ed6f8c0377aba1d3e03484c380f&gt; /System/Library/PrivateFrameworks/HomeSharing.framework/HomeSharing
0x3558e000 - 0x3565efff  WebKit armv7  &lt;3c5dd2ec46fe3e189c25bba78ad88fa1&gt; /System/Library/PrivateFrameworks/WebKit.framework/WebKit
0x356de000 - 0x35794fff  AVFoundation armv7  &lt;35cb7a0eb1dc3554a777c1cc11cb0415&gt; /System/Library/Frameworks/AVFoundation.framework/AVFoundation
0x35795000 - 0x3579bfff  liblaunch.dylib armv7  &lt;aa2bcba6fc7a36a191958fef2e995475&gt; /usr/lib/system/liblaunch.dylib
0x3579f000 - 0x357e8fff  libc++.1.dylib armv7  &lt;5b690e5dd5a43a7fb166ade9fe58a7a4&gt; /usr/lib/libc++.1.dylib
0x357e9000 - 0x357ecfff  libcompiler_rt.dylib armv7  &lt;b2c05d8601c13be884097192dca4e187&gt; /usr/lib/system/libcompiler_rt.dylib
0x357fc000 - 0x35913fff  CoreFoundation armv7  &lt;6d450fe923d7387f8b01845e0edd713d&gt; /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation
0x35a9e000 - 0x35af6fff  CoreAudio armv7  &lt;be335e8eb6f93594b028a6ddd503a183&gt; /System/Library/Frameworks/CoreAudio.framework/CoreAudio
0x35af9000 - 0x35af9fff  libkeymgr.dylib armv7  &lt;ebd2dddf55d83cf48a18913968775960&gt; /usr/lib/system/libkeymgr.dylib
0x35b02000 - 0x35b11fff  OpenGLES armv7  &lt;e80acc691001301e96101bb89d940033&gt; /System/Library/Frameworks/OpenGLES.framework/OpenGLES
0x35b12000 - 0x35b12fff  Accelerate armv7  &lt;55b24cf91a8b3532bde6733c96f14c08&gt; /System/Library/Frameworks/Accelerate.framework/Accelerate
0x35b15000 - 0x35b24fff  GenerationalStorage armv7  &lt;d84c3fd0e7bd36e78c256f2f4c5a4e91&gt; /System/Library/PrivateFrameworks/GenerationalStorage.framework/GenerationalStorage
0x35c67000 - 0x35c6efff  libc++abi.dylib armv7  &lt;bab4dcbfc5943d3fbb637342d35e8045&gt; /usr/lib/libc++abi.dylib
0x35c95000 - 0x35ce1fff  CoreTelephony armv7  &lt;b8f80d5d594c31d2b5d8fba9fdedb7e1&gt; /System/Library/Frameworks/CoreTelephony.framework/CoreTelephony
0x35d64000 - 0x35e0efff  libBLAS.dylib armv7  &lt;bf822cc1a3243ae7b104cf73ca22d352&gt; /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libBLAS.dylib
0x35e30000 - 0x35e33fff  libmacho.dylib armv7  &lt;e52b77623bd031bc807e77029566c777&gt; /usr/lib/system/libmacho.dylib
</code></pre>

<p>------------------- cut here</p>
",<ios>
67607233,flutter access call logs,"<p>i want to get my call logs and i used call logs package and on button click, i call tthis function</p>
<pre><code> void calllog() async{
    Iterable&lt;CallLogEntry&gt; entries = await CallLog.get();
    for (var item in entries) {
      print(item.name);
    }
  }
</code></pre>
<p>but its shooting me an error like this</p>
<pre><code>[ERROR:flutter/lib/ui/ui_dart_state.cc(186)] Unhandled Exception: PlatformException(INTERNAL_ERROR, Attempt to invoke interface method 'java.util.Iterator java.util.List.iterator()' on a null object reference, null, null)
</code></pre>
<p>PS: i am using this package: call_log: ^3.0.3</p>
",<flutter><dart>
23366656,No log file when using jHiccup on Tomcat application,"<p>I am trying to use jHiccup with application which runs on Tomcat7. I have tried to do it in this way:</p>

<p>jHiccup -p tomcat_pid</p>

<p>I didn't receive any error but there was no log neither.</p>

<p>Then I tried to make changes in catalina.sh described here <a href=""https://github.com/giltene/jHiccup"" rel=""nofollow"">https://github.com/giltene/jHiccup</a> and in posts on jHiccup forum. Tomcat started succesfully but there where no hlog file.  Can sb help me please?</p>
",<tomcat>
58546637,Elasticsearch index not being created with settings from logstash template,"<p>I have a bulk upload for a new index that I'm sending to my ES cluster from logstash.  As such I want replication and refreshing turned off until the load is done, and I'll re-enable those values after the upload is complete.</p>

<p>I have a config file that looks like the following</p>

<pre><code>input {
      stdin { type =&gt; stdin }
}
filter {
  csv {
     separator =&gt; "" ""
     columns =&gt; [ ...]
  }
}

output {
   amazon_es {
     hosts =&gt;
         [""my-domain.us-east-1.es.amazonaws.com""]
     index =&gt; ""my-index""
     template =&gt; ""conf/my-index-template.json""
     template_name =&gt; ""my-index-template-name""
     region =&gt; ""us-east-1""
  }
}
</code></pre>

<p>And the template file looks like</p>

<pre><code>{
    ""template"" : ""my-index-template-name"",
    ""mappings"" : {
      ...
    },
    ""settings"" : {
      ""index"" : {
        ""number_of_shards"" : ""48"",
        ""number_of_replicas"" : ""0"",
        ""refresh_interval"": ""-1""
      }
    }
}
</code></pre>

<p>And when I run logstash and go to look at the settings for that index, the mappings are all respected from this template which is good, but everything in the <code>settings</code> section is ignored and it takes on default values (i.e. <code>number_of_shards=5</code>, and <code>number_of_replicas=1</code>)</p>

<p><strong>Some investigation notes:</strong>
If I get the template after it's installed from ES itself I see the proper values in the template (for both <code>mappings</code> and <code>settings</code>).  They just don't seem to be applying to the index</p>

<p>Also if I take the contents of the template file and create the index manually w/ a <code>PUT</code> it shows up as I would expect</p>

<p>My logstash version is 7.3.0 and my elasticsearch version is 6.7</p>

<p>Not sure what I'm doing wrong here</p>
",<elasticsearch><logstash><aws-elasticsearch>
12482792,OracleDB export to MySQL. DBCatalog Named None,"<p>I'm attempting to export an OracleDB to MySQL and started attempting using workbench.  I run into the following error:</p>

<p>SystemError: DataError(""('22003', '[22003] [Oracle][ODBC]Numeric value out of range. (0) (SQLGetData)')""): error calling Python module function DbGenericRE.reverseEngineer*** ERROR: Reverse engineer selected schemata: DataError(""('22003', '[22003] [Oracle][ODBC]Numeric value out of range. (0) (SQLGetData)')""): error calling Python module function DbGenericRE.reverseEngineerFailed</p>

<p>I suspect this might be happening because the DBCatalog is named none which is null in python.</p>

<p>I'm looking for a workaround or  better tool for solving the problem.</p>
",<python><mysql><oracle><migration>
27593306,Inference engine prolog,"<p>I am trying to build an inference engine in prolog. </p>

<p>For example, here are some rules </p>

<pre><code>R1 : A and B -&gt; C
R2 : E and F -&gt; D
R3 : G and T -&gt; H
</code></pre>

<p>I wanted to do it like this </p>

<pre><code>c :- a,b
d :- e,f
h :- g,t
</code></pre>

<p>but I have to use a predicate ""rule/1"" defined as follows </p>

<p><code>rule(Ri) :- ""if conditions then conclusions"".</code></p>

<p>For example :</p>

<pre><code>rule(r1) :- ""if a and b then c"".
</code></pre>

<p>How can I do ?</p>
",<prolog><inference-engine>
68031568,Django saveing logged in logged in user as ForeignKey,"<p>I have model with a ForeignKey &quot;log_written_by&quot; and I want that to be the logged in user.</p>
<p>How should i state that in my forms.py as a hiddenfield?</p>
<pre><code>class AssetLog(models.Model):

    # Relationships
    log_written_by = models.ForeignKey(&quot;auth.User&quot;, on_delete=models.SET_NULL, blank=True, null=True)
    asset_case = models.ForeignKey(&quot;asset_app.AssetCase&quot;, on_delete=models.CASCADE)

    # Fields
    date_time_log = models.DateTimeField()
    notes = models.TextField(max_length=1024)
    created = models.DateTimeField(auto_now_add=True, editable=False)

    class Meta:
        pass

    def __str__(self):
        return str(self.pk)

    def get_absolute_url(self):
        return reverse(&quot;asset_app_AssetLog_detail&quot;, args=(self.pk,))

    def get_update_url(self):
        return reverse(&quot;asset_app_AssetLog_update&quot;, args=(self.pk,))
</code></pre>
",<django><foreign-keys><hidden-field>
56245383,How to select data from 'logged in user' from database to a graph,"<p>I need help with some code. I want to <strong>select</strong> data from mySQL to a <strong>graph</strong> on my web page. 
The data <strong>must</strong> be from the <strong>current</strong> <strong>logged</strong> <strong>in</strong> <strong>user</strong>, and when I select data to a card it works fine, but when I select it to a graph the graph disappears. </p>

<p>I'm using this code for the cards, and it works fine:</p>

<pre><code> $sql = ""SELECT energyexpenditure FROM energy4project WHERE user_id =  '{$_SESSION[""user_id""]}' ORDER BY time_stamp DESC LIMIT 1;"";
</code></pre>

<p>This is the code for my current graph that <strong>don't</strong> show data based on logged in user:</p>

<pre><code>&lt;?php
header('Content-Type: application/json');

        $host = ""localhost"";
        $user = ""`blabla"";
        $pwd = ""blabla"";
        $db = ""blabla"";
        $conn = new mysqli($host, $user, $pwd, $db);

        // Check connection
        if ($conn-&gt;connect_error) {
            die(""Connection failed: "" . $conn-&gt;connect_error);
        }


         $sql = ""SELECT energyexpenditure, time_stamp FROM energy4project ORDER BY time_stamp DESC LIMIT 7;"";

        $result = $conn-&gt;query($sql);


$data = array();
foreach ($result as $row) {
    $data[] = $row;
}

mysqli_close($conn);

echo json_encode($data);
?&gt;
</code></pre>

<p>When I implement the code from the cards in the graph code it doesn't work.<br>
Why does the <code>SELECT WHERE user = '{$_SESSION[""user_id""]}</code> not work in the graphs?</p>
",<php><mysql><graph><charts>
62396452,Logistic Regression - class_weight balanced vs dict argument,"<p>When using sklearn LogisticRegression function for binary classification of imbalanced training dataset (e.g., 85% pos class vs 15% neg class), is there a difference between setting the  class_weight argument to 'balanced' vs setting it to {0:0.15, 1:0.85} ?
Based on the documentations, it appears to me that using the 'balanced' argument will do the same thing as providing the dictionary.</p>

<p><strong>class_weight</strong></p>

<blockquote>
  <p>The “balanced” mode uses the values of y to automatically adjust
  weights inversely proportional to class frequencies in the input data
  as n_samples / (n_classes * np.bincount(y)).</p>
</blockquote>
",<scikit-learn><logistic-regression><imbalanced-data>
58673282,How to make time variable continuous in a netcdf forcing climatology file?,"<p>I am having a forcing NetCDF climatology file that has 4 dimensions, i.e. time, lat, long and lev. I am reading this file using Flexible Modelling System (FMS) from GFDL. I want to keep the time continuous, or something like a periodic boundary condition. For example, I should provide just one year monthly file, and the model should directly pick up the corresponding month from my file without exactly checking the specific year. I am performing some experiments in which some forcings are kept fixed and others changing (to provide a context why I want to do this).</p>
",<netcdf><atmosphere><nco><cdo-climate>
39913627,Switch off line breaking in FPM log,"<p>Is there a way to switch off line breaking in php-fpm log? It would be much more comfortable to log data without line breaks, cause when you grep something from log it outputs only first line of log entry, while there can be some additional info like var dump or stack trace that's being cut off if there were line breaks. It was good in apache, cause it escapes them, and it's better to use sed when necessary, but now it's kinda painful(</p>
",<php><logging><fpm>
59132974,Two log4net configuration files on same solution,"<p>I have an solution which consist of multiple projects.its a desktop application  I need to have two separate log4net configurations for those projects since one project contains a library that uses log4net itself.  On one project log4net configured in App.config and other project it is configured in log4net.configuration file.</p>

<p>below is one configuration file
'''</p>

<pre><code>&lt;configSections&gt;

    &lt;section name=""log4net"" type=""log4net.Config.Log4NetConfigurationSectionHandler,Log4net""/&gt;
  &lt;/configSections&gt;
  &lt;log4net&gt;
    &lt;root&gt;
      &lt;level value=""DEBUG""/&gt;
      &lt;appender-ref ref=""SmtpAppender""/&gt;
      &lt;appender-ref ref=""LogFileAppender""/&gt;
      &lt;appender-ref ref=""ColoredConsoleAppender""/&gt;
    &lt;/root&gt;
    &lt;appender name=""LogFileAppender"" type=""log4net.Appender.RollingFileAppender""&gt;
      &lt;param name=""File"" value=""D:\seperatelog.txt""/&gt;
      &lt;param name=""AppendToFile"" value=""true""/&gt;

      &lt;rollingStyle value=""Date"" /&gt;
      &lt;datePattern value=""'On_'yyyy-MM-dd'.log'"" /&gt;
      &lt;appendToFile value=""true"" /&gt;
      &lt;maxSizeRollBackups value=""14"" /&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%date [%thread] %level %logger - %message%newline"" /&gt;
      &lt;/layout&gt;
      &lt;staticLogFileName value=""true""/&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%date [%thread] %-5level %logger: %message%newline""/&gt;
      &lt;/layout&gt;
    &lt;/appender&gt;
    &lt;appender name=""ColoredConsoleAppender"" type=""log4net.Appender.ConsoleAppender""&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%date [%thread] %-5level %logger: %message%newline""/&gt;
      &lt;/layout&gt;
    &lt;/appender&gt;
    &lt;appender name=""SmtpAppender"" type=""log4net.Appender.SmtpAppender""&gt;
      &lt;to value=""bobby.chopra@prcm.com""/&gt;
      &lt;from value=""TagFileUploader@prcm.com""/&gt;
      &lt;subject value=""TagFileUploader ERROR""/&gt;
      &lt;smtpHost value=""prc-mn-ex01""/&gt;
      &lt;bufferSize value=""512""/&gt;
      &lt;lossy value=""true""/&gt;
      &lt;evaluator type=""log4net.Core.LevelEvaluator""&gt;
        &lt;threshold value=""ERROR""/&gt;
      &lt;/evaluator&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%date [%thread] %-5level %logger: %message%newline""/&gt;
      &lt;/layout&gt;
    &lt;/appender&gt;
    &lt;appender name=""cargillsJournal"" type=""log4net.Appender.FileAppender""&gt;
      &lt;param name=""File"" value=""D:\BankInABoxffffff-log.txt""/&gt;
      &lt;param name=""AppendToFile"" value=""true""/&gt;
      &lt;rollingStyle value=""Date"" /&gt;
      &lt;datePattern value=""'On_'yyyy-MM-dd'.log'"" /&gt;
      &lt;appendToFile value=""true"" /&gt;
      &lt;maxSizeRollBackups value=""14"" /&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%date [%thread] %level %logger - %message%newline"" /&gt;
      &lt;/layout&gt;
      &lt;staticLogFileName value=""true""/&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%date [%thread] %-5level %logger: %message%newline""/&gt;
      &lt;/layout&gt;
    &lt;/appender&gt;
  &lt;/log4net&gt;
</code></pre>

<p>Other configuration file is below</p>

<pre><code>      &lt;log4net&gt;
    &lt;root&gt;
      &lt;level value=""ALL"" /&gt;
      &lt;appender-ref ref=""console"" /&gt;     
    &lt;/root&gt;
    &lt;appender name=""console"" type=""log4net.Appender.ConsoleAppender""&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%date - %message%newline"" /&gt;
      &lt;/layout&gt;
    &lt;/appender&gt;
    &lt;appender name=""RollingLogFileAppender"" type=""log4net.Appender.RollingFileAppender""&gt;
      &lt;file value=""rolling-log.txt"" /&gt;
      &lt;appendToFile value=""true"" /&gt;
      &lt;maxSizeRollBackups value=""10"" /&gt;
      &lt;maximumFileSize value=""100"" /&gt;
      &lt;rollingStyle value=""Size"" /&gt;
      &lt;staticLogFileName value=""true"" /&gt;
      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;header value=""[Header]&amp;#13;&amp;#10;"" /&gt;
        &lt;footer value=""[Footer]&amp;#13;&amp;#10;"" /&gt;
        &lt;conversionPattern value=""%date [%thread] %-5level %logger [%ndc] - %message%newline"" /&gt;
      &lt;/layout&gt;
    &lt;/appender&gt;
    &lt;logger name=""LoggingExample""&gt;
      &lt;!-- &lt;appender-ref ref=""B"" /&gt; --&gt;
      &lt;level value=""ALL"" /&gt;
      &lt;appender-ref ref=""RollingLogFileAppender"" /&gt;
    &lt;/logger&gt;
   &lt;/log4net&gt;
</code></pre>

<p>those two log file load correctly but they all write on to the same log file seperatelog.txt</p>

<p>What i need is to have two separate files to create for those 2 configurations.</p>
",<c#><log4net><log4net-configuration><log4net-appender>
29079926,"LogStash failed action with response of 500, dropping action","<p>I am trying to configure LogStash to watch a file and send events to elasticsearch server. </p>

<p>When I start logstash to output to stdout, it runs fine: </p>

<pre><code>stdout { 
    codec =&gt; rubydebug
}
</code></pre>

<p>But when I add elasticsearch output: </p>

<pre><code>elasticsearch {
    cluster =&gt; 'myclustername'
    host =&gt; 'myip'
    node_name =&gt; 'Aragorn'
}
</code></pre>

<p>Logstash starts up </p>

<pre><code>Mar 16, 2015 3:44:24 PM org.elasticsearch.node.internal.InternalNode &lt;init&gt;
INFO: [Aragorn] version[1.4.0], pid[7136], build[bc94bd8/2014-11-05T14:26:12Z]
Mar 16, 2015 3:44:24 PM org.elasticsearch.node.internal.InternalNode &lt;init&gt;
INFO: [Aragorn] initializing ...
Mar 16, 2015 3:44:24 PM org.elasticsearch.plugins.PluginsService &lt;init&gt;
INFO: [Aragorn] loaded [], sites []
Mar 16, 2015 3:44:25 PM org.elasticsearch.node.internal.InternalNode &lt;init&gt;
INFO: [Aragorn] initialized
Mar 16, 2015 3:44:25 PM org.elasticsearch.node.internal.InternalNode start
INFO: [Aragorn] starting ...
Mar 16, 2015 3:44:25 PM org.elasticsearch.transport.TransportService doStart
INFO: [Aragorn] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.98.134.83:9300]}
Mar 16, 2015 3:44:25 PM org.elasticsearch.discovery.DiscoveryService doStart
INFO: [Aragorn] myclustername/RjasP2X0ShKXEl0f2WRxBA
Mar 16, 2015 3:44:30 PM org.elasticsearch.cluster.service.InternalClusterService$UpdateTask run
INFO: [Aragorn] detected_master [Aragorn][0YytUoWlQ2qgw2_0i5V4mQ][SOMEMACHINE][inet[/myip:9300]], added {[Aragorn][0YytUoWlQ2qgw2_0i5V4mQ][
SOMEMACHINE][inet[/myip:9300]],}, reason: zen-disco-receive(from master [[Aragorn][0YytUoWlQ2qgw2_0i5V4mQ][SOMEMACHINE][inet[/myip:9300]]])
Mar 16, 2015 3:44:30 PM org.elasticsearch.node.internal.InternalNode start
INFO: [Aragorn] started
</code></pre>

<p>But when messages start coming in, nothing is in fact sent to elasticsearch and these start to appear in logstash output: </p>

<pre><code>WARNING: [Aragorn] Message not fully read (response) for [28] handler org.elasticsearch.action.support.master.TransportMasterNodeOperationAction$6@17b
531e, error [true], resetting
Mar 16, 2015 3:44:54 PM org.elasticsearch.transport.netty.MessageChannelHandler messageReceived
WARNING: [Aragorn] Message not fully read (response) for [29] handler org.elasticsearch.action.support.master.TransportMasterNodeOperationAction$6@130
82f0, error [true], resetting
</code></pre>

<p>and </p>

<pre><code>{:timestamp=&gt;""2015-03-16T15:44:54.377000+0100"", :message=&gt;""failed action with response of 500, dropping action...
</code></pre>

<p>(the above message is much longer but does not seem to contain any useful diagnostics)</p>

<p>What might be wrong? </p>
",<elasticsearch><logstash>
57435034,Redux props logging incorrect data,"<p>Right now I am trying to console.log this.streamCreatorUid, but I'm running into a peculiar issue. In my redux debugger, I can clearly see my data in the proper place. </p>

<p>Here is my redux data for the stream creator, directly from my debugger.</p>

<pre><code>streams -
[0] - 
{category(pin): ""Oldschool Runescape""
displayName(pin): ""admin""
streamId(pin): ""98ebc719-c7d5-4558-b99d-2d9f8306ec64""
title(pin): ""accounttest""
uid(pin): ""wsFc7pIMq5dMtw9hPU86DzUTdLO2""
}
</code></pre>

<p>I am trying to console.log this.streamCreatorUid from my mapstatetoprops, but it is returning the current user <code>Uid</code> of <code>u9TcrICehNMlAmqyDHQY77L9CXq1</code> instead. I'm quite confused as to why this is happening, considering this is not the data shown in my debugger.</p>

<p>This is for a personal project. In the past I've accessed <code>redux</code> props like this with no issues, now I'm not quite sure why this is happening.  </p>

<pre><code>
import React from 'react';
import { database } from '../../../firebaseconfig.js';
import { connect } from 'react-redux';


class StreamFollow extends React.Component {
  constructor(props) {
    super(props);
    this.uid = this.props.uid;
    this.displayName = this.props.displayName;
    this.streamCreatorUid = this.props.streamCreatorUid;
    this.streamCreatorDisplayName = this.props.streamCreatorDisplayName;
  }

  componentShouldUpdate(prevProps) {
    if (this.props.uid !== prevProps.uid) {
      this.uid = this.props.uid
    }

    if (this.props.streamCreatorUid !== prevProps.streamCreatorUid) {
      this.streamCreatorUid = this.props.streamCreatorUid;
    }
  }

  //creates a follower object under the stream creators uid
  createFollower = (e) =&gt; {
    const followerRef = database.ref(`User_Follow_Info/${e}/Follower`)

    const followerInfoObject = {
      uid: this.uid,
      displayName: this.displayName
    }

    followerRef.push(followerInfoObject);

  }

  //creates a following object under the users uid 

  //Add in checks to see if following object already exists. We can't follow someone multiple times

  createFollowing = (user) =&gt; {
    const followingRef = database.ref(`User_Follow_Info/${user}/Following`);

    const followingInfoObject = {
      uid: this.streamCreatorUid,
      displayName: this.streamCreatorDisplayName
    }


    console.log(this.streamCreatorDisplayName)
    //Check to see if follow already exists. 
    /*followingRef.once('value', function (snapshot) {
      if (snapshot.hasChild(DATA HERE)) {
        alert('exists');
      }
    }); */
    var isSignedIn = this.isSignedIn;

    followingRef.orderByChild('uid').equalTo(this.uid).once('value').then(snapshot =&gt; {


      console.log(snapshot.val());
      console.log(this.streamCreatorUid);
      if (isSignedIn) {
        console.log(snapshot.val())
        return
      } else {
        followingRef.push(followingInfoObject);
      }
    })

  }


  onSubmit = () =&gt; {
    if (this.props.isSignedIn === true) {
      this.createFollowing(this.uid);
      this.createFollower(this.streamCreatorUid);
    } else {
      //add in a sign in modal if user is not logged in
      console.log('please sign in')
    }
  }

  render() {
    return (
      &lt;div&gt;
        &lt;button onClick={this.onSubmit}&gt;Follow&lt;/button&gt;
      &lt;/div&gt;
    );
  }
}

const mapStateToProps = (state) =&gt; {
  return {
    isSignedIn: state.auth.isSignedIn,
    displayName: state.auth &amp;&amp; state.auth.userInfo ? state.auth.userInfo.displayName : null,
    uid: state.auth &amp;&amp; state.auth.userInfo ? state.auth.userInfo.uid : null,
    streamCreatorUid: state.streams &amp;&amp; state.streams[0] ? state.streams[0].uid : null,
    streamCreatorDisplayName: state.streams &amp;&amp; state.streams[0] ? state.streams[0].displayName : null,
  }
}

export default connect(mapStateToProps)(StreamFollow);

</code></pre>
",<javascript><redux><react-redux>
39254465,Using custom Log4j2 plugins in JEE Web Application,"<h3>Background</h3>

<p>I am developing a Java web application, packaged as a WAR in an EAR, which utilizes Log4j2 for logging, and am encountering an issue when deploying the application to a development server. The logging relies on a custom filter (based on <a href=""https://stackoverflow.com/a/24052506"">this</a> answer), located in a separate JAR, which is used to set the log level per client.</p>

<p>On my local machine, specifically when the EAR is running via the IDE, the filter is loaded (<code>Took 0.x seconds to load 1 plugins from package a.b.c</code>) and works as expected . On the development server, and on my local machine when exported and loaded manually via the Admin Console, the filter is not loaded (<code>Took 0.x seconds to load 0 plugins from package a.b.c</code>), and thus logging does not function as desired .</p>

<p>The EAR layout looks approximately like this:</p>

<pre><code>.
├── lib
|   ├── Common.jar
|   |   ├── CustomFilter.class
|   |   └── OtherCustomUtils.class
|   ├── log4j-api.jar
|   ├── log4j-core.jar
|   └── [more third party JARs]
├── WebApp.war
|   ├── WebApp.class
|   └── WEB-INF
|       ├── lib
|       |   ├── log4j-web.jar
|       |   └── [more third party JARs]
|       ├── log4j2.xml
|       └── web.xml
├── SomeEJB.jar
|   └── ClassThatAlsoUsesCommonJar.class
└── META-INF
    └── application.xml
</code></pre>

<p><br/></p>

<h3>Analysis and Attempts</h3>

<p>My hypothesis is that the classes in Common.jar are simply not being loaded by the classloader before Log4j2 is initialized and configured. Here's what I've tried thus far: </p>

<ul>
<li>Initially I feared that it might be a conflict between the EAR's and web module's classloaders; I think I eliminated this possibility by configuring the deployed EAR to only use one classloader for the whole application, but I could be wrong.

<ul>
<li>I've left the EAR in this condition since. Hopefully this isn't screwing everything up.</li>
</ul></li>
<li>I'm currently using log4j-web, as recommended by the ""<a href=""https://logging.apache.org/log4j/2.x/manual/webapp.html"" rel=""nofollow noreferrer"">Using Log4j 2 In Web Applications</a>"" page. With minimal configuration I observe that it runs and loads the log4j2.xml almost immediately after starting the web app. While running in the IDE I presume the Common.jar is already loaded, so this is OK, while on the development server (or installed manually on local) Common.jar doesn't seem to be loaded yet, and the search for the plugin fails.

<ul>
<li>Removing log4j2-web and just letting log4j2 initialize itself on first-call doesn't seem to fix this problem (first call to log4j2 happens before first call to any class in Common.jar)</li>
<li>Logs are going to a couple files and databases, so I don't think I want to have this application running <em>without</em> log4j-web.</li>
</ul></li>
<li>Acknowledging that log4j-web is a web fragment, I thought to try and make Common.jar a web fragment, and specify that it load before log4j-web via the web.xml in the web app. I have next to no idea what I'm doing here, so I probably messed this up. Furthermore, this requires that Common.jar be in WEB-INF/lib, which may or may not be a big deal?

<ul>
<li>The EJB project depends on Common.jar, so it needs it to be loaded, but since I'm using one classloader for the whole app I assume if the web app loads it first, and then the EJB needs it later, it'll already be there?</li>
</ul></li>
</ul>

<p>I'll admit that my hypothesis hinges entirely on the idea that my application server doesn't eagerly load all of the classes in all of the JARs in the EAR's lib directory.</p>

<p><br/></p>

<h3>Desired Solution</h3>

<p>A simple configuration-based fix would be ideal. I'm still a novice at best when it comes to crafting JEE applications, so I wouldn't be surprised to find an option buried somewhere to explicitly specify that everything in Common.jar be preloaded (assuming it isn't already?)</p>

<p>An actual code change is not out of the question of course. I'd just prefer not to. </p>

<p><br/></p>

<h3>Environment</h3>

<ul>
<li>Java Version: 1.7.1</li>
<li>JEE Version: 6</li>
<li>Log4j2 Version: 2.6.2</li>
<li>Application Server: WebSphere 8.5.5.6</li>
<li>IDE: Rational Software Architect 8.5 (Eclipse 3.6?)</li>
</ul>

<p><br/></p>

<h3>Similar Questions</h3>

<ul>
<li><a href=""https://stackoverflow.com/questions/29745938/log4j2-2-1-custom-plugin-not-detected-by-packages-attribute"">Log4j2 (2.1) custom plugin not detected by packages attribute</a> and <a href=""https://stackoverflow.com/questions/29243229/log4j2-custom-filter"">Log4j2 custom filter</a>

<ul>
<li>using packages attribute, works on local</li>
</ul></li>
<li><a href=""https://stackoverflow.com/questions/33237830/log4j2-custom-plugins-not-working-in-ear"">Log4j2 custom plugins not working in EAR</a>

<ul>
<li>application set to use one classloader</li>
</ul></li>
<li><a href=""https://stackoverflow.com/questions/33214821/custom-plugin-not-getting-detected-in-ear-with-log4j2-api"">Custom plugin not getting detected in EAR with log4j2 API</a>

<ul>
<li>not using Maven, packages attribute works now, questioner doesn't appear to be using log4j-web</li>
</ul></li>
</ul>
",<jakarta-ee><plugins><log4j2><ear>
19935141,This log is provided by the In-Memory Error Log. ** ELMAH**,"<p>I included ELMAH (no configuration needed) to my web application</p>

<p>it seems working fine.. </p>

<p>but I am worried of the log configuration that was setup automatically as:
This log is provided by the In-Memory Error Log.</p>

<p>my question is:</p>

<p>would this strain the resources and the RAM causing the application degradation ??</p>

<p>should I consider other setup like XML or SQL??</p>

<p>Regards </p>
",<asp.net><elmah>
67369370,Logger.php deleting itself,"<p>Whenever I launch a php site using Visual Studio code, my logger.php delets itself after a few seconds, making it impossible for to navigate further.
I had a first folder without any logger.php so I had to import a friend's folder with a working logger.php.</p>
",<php><logging>
39284523,Regenerating a Corrupted Git Repo from Log Files?,"<p>I hit a random bluescreen on windows and when I restarted, my git repo was corrupted. It's a local-only repo and my backups are several weeks old. I've tried a number of different things (documented below) to get it working, but to no avail. Re-cloning the local repo yields the same corruption as the original. I can't commit anything new to the repo.</p>

<p>However, <code>git log</code> and <code>git show</code> still appear to work perfectly. Is there some way I can recreate a new git repo from the output of these commands?</p>

<hr>

<p>What I have tried to get it working again:</p>

<p>git status does not work:</p>

<pre><code>&gt; git status --long -v
error: inflate: data stream error (incorrect header check)
fatal: failed to read object 143fd2fe59980f9b4aec9b1b696e4d2ab5bd0465: 
&gt; git fsck --full
error: inflate: data stream error (incorrect header check)
error: unable to unpack 143fd2fe59980f9b4aec9b1b696e4d2ab5bd0465 header
error: inflate: data stream error (incorrect header check)
fatal: loose object 143fd2fe59980f9b4aec9b1b696e4d2ab5bd0465 (stored in .git/objects/14/3fd2fe59980f9b4aec9b1b696e4d2ab5bd0465) is
corrupt
&gt; mv .git/objects/14/3fd2fe59980f9b4aec9b1b696e4d2ab5bd0465 .git/objects/14/3fd2fe59980f9b4aec9b1b696e4d2ab5bd0465.bak
&gt; git fsck --full
Checking object directories: 100% (256/256), done.
Checking objects: 100% (56357/56357), done.
broken link from    tree 85532cceff0ea16036538bfb47adc1f1ecdb1009
              to    tree 143fd2fe59980f9b4aec9b1b696e4d2ab5bd0465
...
missing tree 143fd2fe59980f9b4aec9b1b696e4d2ab5bd0465
...
</code></pre>

<p>I've also tried the following, which did not help:</p>

<pre><code>&gt; git checkout 444ea90502abc17eb2e55365e550a2e0dc95af61
error: inflate: data stream error (incorrect header check)
fatal: failed to read object 143fd2fe59980f9b4aec9b1b696e4d2ab5bd0465: Invalid argument
&gt; git reset --hard
error: inflate: data stream error (incorrect header check)
fatal: failed to read object 143fd2fe59980f9b4aec9b1b696e4d2ab5bd0465: Invalid argument
</code></pre>
",<git><corruption><fsck>
72608219,ECS Task failed to start with no logs,"<p>I am trying to deploy a service on AWS ECS where task is failing to start and fails after 3-4 minutes. No logs are found for the failure. It just changes from PENDING -&gt; STOPPED.</p>
<p><a href=""https://i.stack.imgur.com/Rj4rX.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Rj4rX.png"" alt=""enter image description here"" /></a></p>
<p>After few failures (PENDING -&gt; STOPPED) on task like this, the service comes up after a few retry and it moves from PENDING -&gt; RUNNING without any interruptions. I am trying to debug why it goes (PENDING -&gt; STOPPED) many times before running correctly.</p>
<p>Docker images of the service is around ~10GB and service is deployed on GD4N.xlarge instance.</p>
<p>It looks like it is timing out while pulling the docker image of 10GB and stopping down. I have tried setting down ECS_CONTAINER_START_TIMEOUT but still it fails with same error under same timing failing in 3-4 minutes.
<a href=""https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html"" rel=""noreferrer"">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html</a></p>
<pre><code>            autoScalingGroup.addUserData(...[
                `echo ECS_CONTAINER_START_TIMEOUT=9m &gt;&gt; /etc/ecs/ecs.config`,  // increasing the start timeout for containers
                `echo ECS_CONTAINER_CREATE_TIMEOUT=9m &gt;&gt; /etc/ecs/ecs.config`,  // increasing the create timeout for containers
                `echo ECS_LOGLEVEL=debug &gt;&gt; /etc/ecs/ecs.config`,  // debug mode for ecs agent
                `echo ECS_IMAGE_PULL_BEHAVIOR=prefer-cached &gt;&gt; /etc/ecs/ecs.config`,  // debug mode for ecs agent
                `echo ECS_IMAGE_PULL_INACTIVITY_TIMEOUT=5m &gt;&gt; /etc/ecs/ecs.config`,  // debug mode for ecs agent
            ])
</code></pre>
<p>I am looking for direction on how it can debugged further?
And how i can increase the timeout from PENDING to RUNNING, so it does not stop.</p>
",<amazon-web-services><amazon-ecs>
32479530,Using docker-compose with GELF log driver,"<p>According <a href=""https://docs.docker.com/reference/logging/overview/"">to the official Docker docs</a>, it is possible to get the <code>stdout</code> and <code>stderr</code> output of a container as <a href=""https://www.graylog.org/resources/gelf/"">GELF messages</a> which is a format that is understood by e.g. <a href=""https://www.graylog.org/"">Graylog / Graylog2</a> and <a href=""https://www.elastic.co/products/logstash"">logstash</a>.</p>

<p>This works fine when I run my containers manually from the command line. For instance,</p>

<pre><code>docker run --log-driver=gelf --log-opt gelf-address=udp://localhost:12201 busybox echo This is my  message.
</code></pre>

<p>will send a log message to my Graylog2 server running on localhost which has a UDP input listener configured at port 12201.</p>

<p>Now, I want to use the same log options with <a href=""https://docs.docker.com/compose/"">docker-compose</a> which, according to the docs, <a href=""https://docs.docker.com/compose/yml/#log-driver"">should be possible in principle</a>. However, the docs do not mention any log formats but <code>json-file</code>, <code>syslog</code> and <code>none</code> and when I include something like</p>

<pre><code>my-container:
  container_name: ...
  build: ...
  ports: ...
  log_driver: ""gelf""
  log_opt:
    gelf-address: ""udp://localhost:12201""
</code></pre>

<p>in my <code>docker-compose.yml</code> file then <code>docker-compose up</code> fails with:</p>

<pre><code>Traceback (most recent call last):
  File ""&lt;string&gt;"", line 3, in &lt;module&gt;
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.cli.main"", line 39, in main
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.cli.docopt_command"", line 21, in sys_dispatch
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.cli.command"", line 27, in dispatch
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.cli.docopt_command"", line 24, in dispatch
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.cli.command"", line 59, in perform_command
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.cli.main"", line 495, in up
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.project"", line 265, in up
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.service"", line 369, in execute_convergence_plan
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.service"", line 270, in create_container
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.service"", line 643, in _get_container_create_options
  File ""/code/build/docker-compose/out00-PYZ.pyz/compose.service"", line 656, in _get_container_host_config
  File ""/code/build/docker-compose/out00-PYZ.pyz/docker.utils.types"", line 27, in __init__
ValueError: LogConfig.type must be one of (json-file, syslog, none)
</code></pre>

<p>For the record, this was on docker-compose 1.4.0 and docker 1.8.1, build d12ea79.</p>

<p>Apparently, Docker and docker-compose are not at the same level of implementation here. I just found that this has already been solved and included in the <code>Master branch</code> on Github, see
<a href=""https://github.com/docker/compose/issues/1869"">https://github.com/docker/compose/issues/1869</a>
and
<a href=""https://github.com/docker/docker-py/pull/724"">https://github.com/docker/docker-py/pull/724</a> .</p>

<p>Is there any way to either re-install docker-compose from the current Master branch or to add this to an existing installation manually? I could not find the file where the commit goes to anywhere on my host...</p>
",<logging><docker><docker-compose>
13063722,Unknown reason of logs on iPad (not iPhone),"<p>I am using images in my iOS application.</p>

<p>When I test my app on iPad, Xcode return that logs:</p>

<blockquote>
  <p><em>*</em> -[__NSCFString stringByAppendingPathExtension:]: cannot append
  extension 'png' to path '~iPad@2x'</p>
</blockquote>

<p>What it means?</p>

<p>p.s. When I test my app on iPhone, Xcode dont return that logs.</p>

<p>Thank you!</p>
",<ios><ipad><logging>
23152739,How to make Scrapy show user agent per download request in log?,"<p>I am learning <a href=""http://scrapy.org/"" rel=""noreferrer"">Scrapy</a>, a web crawling framework.  </p>

<p>I know I can set <code>USER_AGENT</code> in <code>settings.py</code> file of the Scrapy project. When I run the Scrapy, I can see the <code>USER_AGENT</code>'s value in <code>INFO</code> logs.<br>
This <code>USER_AGENT</code> gets set in every download request to the server I want to crawl.  </p>

<p>But I am using multiple <code>USER_AGENT</code> <strong>randomly</strong> with the help of <a href=""http://tangww.com/2013/06/UsingRandomAgent/"" rel=""noreferrer"">this solution</a>. I guess this randomly chosen <code>USER_AGENT</code> would be working. I want to confirm it. So, how I can make Scrapy <strong>shows</strong> <code>USER_AGENT</code> per download request so I can see the value of <code>USER_AGENT</code> in the logs? </p>
",<python><web-scraping><scrapy><web-crawler><user-agent>
48363324,SAS auto log clear with rsubmit,"<p>I used to add <code>dm ""out;clear;log;clear;"";</code> to clear the log and prevent the code from pausing for input. However, now I am using WRDS remote connection. This line after rsubmit does not work and the I lost connection to the server because I was not by the computer when the log was full and needed for user input to be cleared. Is there a way to prevent the code from stopping? Here is what I am doing now.</p>

<pre><code>options ls = 78 ps = 66;

********************connect to WRDs;***************************************;
%let wrds = wrds.utexas.edu 4016;options comamid = TCP remote=WRDS;
signon username=_prompt_;
*************************************************************************;

rsubmit;
libname qa""F:\research2\transcripts"";
libname cq '/wrds/nyse/sasdata/taqms/cq';


proc upload data=qa.daylist out=daylist; run;
data daylist;set daylist;traday2 = input(put(traday,yymmddn8.),8.);drop traday;rename traday2=traday;run;
options errors=2;

data intraday;run;
%macro temp;
%do i = 1 %to 2215; 
.......
dm ""out;clear;log;clear;"";
%end;
%mend;
%Temp;
</code></pre>
",<sas><remote-server><wrds>
48502161,"'NoneType' object is not callable error when using couchbase with git, logbook module","<p>I'd experienced weird result when testing couchbase python SDK.
below is the source code and result:</p>

<pre><code># xxx.py
from gcouchbase.bucket import Bucket
dsn = 'couchbase://[url-of-couchbase]/[bucket-name]'
db = Bucket(dsn)

# yyy.py
import logbook
import git
from xxx import db


# python yyy.py
Traceback (most recent call last):
  File ""/home/username/env/local/lib/python2.7/site-packages/gcouchbase/iops_gevent10.py"", line 88, in timer_event_factory
    return GEventTimer()
TypeError: 'NoneType' object is not callable
[1]    8546 abort (core dumped)  python yyy.py
</code></pre>

<p>The weird thing is, when I remove <code>import git</code> or <code>import logbook</code> from yyy.py, the error doesn't happen.
Is there any reason for this error? should any resource for couchdb be disposed?</p>
",<python><couchbase>
19486477,Is it possible to prevent git from immediately removing the reflog of deleted branches?,"<p><code>git branch -d &lt;branch&gt;</code> deletes the branch and also it's reflog (in <code>.git/logs/refs/heads/&lt;branch&gt;</code>). Yes, you can probably recover the branch from <code>HEAD</code>'s reflog, but why throw away the branch's reflog immediately? Surely it would be more sensible to keep it around and gc it later. This would also give a much easier way to undelete branches (no hunting through <code>HEAD</code>'s reflog).</p>

<ol>
<li><p>Is this is a good idea?</p></li>
<li><p>Assuming the answer to 1 isn't ""no, it's a horrible idea"", can this be achieved by config options (I didn't find any) or by some combination of plumbing commands?</p></li>
</ol>
",<git>
57711324,Can't install octocatalog-diff,"<p>I'm trying to run:</p>

<pre><code>gem install octocatalog-diff -v 1.5.2
</code></pre>

<p>(Since later versions require ruby 2.2.0).
This is the error I'm getting:</p>

<pre><code>Building native extensions.  This could take a while...
ERROR:  Error installing octocatalog-diff:
    ERROR: Failed to build gem native extension.
.
.
.
-- Could NOT find OpenSSL, try to set the path to OpenSSL root folder in the system variable OPENSSL_ROOT_DIR (missing:  OPENSSL_LIBRARIES OPENSSL_INCLUDE_DIR)
CMake Error at src/CMakeLists.txt:167 (MESSAGE):
  Unable to autodetect a usable HTTPS backend.Please pass the backend name
  explicitly (-DUSE_HTTPS=backend)
</code></pre>

<p>Although I have openssl installed and in my user's path.
Tried installing ruby-devel, cmake,gcc</p>

<p>What am I missing?</p>
",<ruby><rubygems>
48119571,cannot open file C:\Cassandra/logs/gc.log due to No such file or directory,"<p>I am facing below issue with Cassandra while installing it in Windows. I tried searching in the forum but no luck.</p>

<p>Below are the steps that I performed while I tried to install Cassandra:</p>

<ol>
<li>Placed unzipped Cassandra files under C:\Cassandra folder.</li>
<li>Made environment variables entries for Java 1.8 as <code>JAVA_HOME</code>, Python 3.6.2 as <code>Path</code> and Cassandra 3.11.1 as <code>CASSANDRA_HOME</code> in the system variables settings.</li>
<li><p>While I tried to run Cassandra on CMD terminal, it gives me the below error:</p>

<pre class=""lang-none prettyprint-override""><code>Detected powershell execution permissions.  Running with enhanced startup
scripts.
*---------------------------------------------------------------------*
*---------------------------------------------------------------------*

    WARNING!  Automatic page file configuration detected.
    It is recommended that you disable swap when running Cassandra
    for performance and stability reasons.

*---------------------------------------------------------------------*
*---------------------------------------------------------------------*
Failed 64-bit check. Re-running to get version from 32-bit
*---------------------------------------------------------------------*
*---------------------------------------------------------------------*

    WARNING! Detected a power profile other than High Performance.
    Performance of this node will suffer.
    Modify conf\cassandra.env.ps1 to suppress this warning.

*---------------------------------------------------------------------*
*---------------------------------------------------------------------*
Java HotSpot(TM) Client VM warning: Cannot open file C:\Cassandra/logs/gc.log
due to No such file or directory

Error occurred during initialization of VM
Could not reserve enough space for 2097152KB object heap
</code></pre></li>
</ol>
",<python-3.x><cassandra><garbage-collection><powershell-3.0><cassandra-3.0>
3944536,Can Attributes be used for automatic change notification/logging?,"<p>Is there a way to do this:</p>

<pre><code>class Example {
    [ChangeNotification]
    private int field;
}
</code></pre>

<p>Such that changing the value of ""field"" would automatically get logged, generate an event, etc?</p>
",<c#><attributes>
569526,Associating logging from two or more processes,"<p>I have two processes that I have up and running and I am doing logging from. One is a client the other is a webservice. I want to setup a central log system where I can track logs and interactions between processes -- for instance I want to be able to associate calls made from the client to the webservice when I look at the logs. I guess this means that somehow the processid of the client process needs to flow over to the webservice in some way for it to be trackable?</p>

<p>Is this possible with current logging frameworks such as Enterprise Library or Log4Net?
Is there anyone that has looked into something like this?</p>

<p>Any help would be appreciated.</p>

<p>If you have a more defining term for this please feel free to change the title of the question or tags.</p>
",<.net><logging>
58853867,problem in jumping to system verilog macros `define in VIM using ctags,"<p>I checked following things, tags file path is set properly.</p>

<p>the macro tag i am looking for exist in the tags file. task/function/parameters etc works without hiccups. i have problem only with regex. </p>

<p>the expression present in ctags file are </p>

<pre><code>1. --regex-SystemVerilog=/^\s*`define\b\s*(\w+)/`\1/d,define/ 
2. --regex-systemverilog=/^[ \t]*`define[ \t]*([a-zA-Z_0-9]+)/`\1/d,define/
</code></pre>

<p>both the options does not work.</p>
",<vim><macros><verilog><system-verilog><ctags>
19225532,Is there a way to view PhantomJS console.log messages via Selenium/GhostDriver?,"<p>I'm using the Java bindings of <a href=""https://github.com/detro/ghostdriver"" rel=""noreferrer"">GhostDriver</a> to run Selenium acceptance tests against PhantomJS.</p>

<p>If one of the web pages requested by PhantomJS logs to the Javascript console via console.log, is there a way to capture or view those messages?</p>

<p>I'm guessing that the answer to this is forehead-slappingly simple but I can't work it out!</p>
",<selenium><phantomjs><ghostdriver>
71314432,Kubectl follow logs until complete or timeout,"<p>After I run a job, I'd like to follow its logs until it either completes or after a specified timeout in a bash script.</p>
<p>This can kind of be accomplished with the following:</p>
<pre class=""lang-sh prettyprint-override""><code>kubectl wait --for=condition=complete --timeout=30s job/data-job-name
kubectl logs job/data-job-name
</code></pre>
<p>The only problem with the above is that the timeout causes a failure, meaning the <code>kubectl logs</code> command never runs.</p>
<p>How can I accomplish this?</p>
",<docker><kubernetes><microservices>
59061474,Proper way to use a bus in a for loop in SystemVerilog?,"<p>I'm trying to make a module in SystemVerilog that can find the dot product between two vectors with up to 8 8-bit values. I'm trying to make it flexible for vectors of different length, so I have an input called EN that's 3 bits and determines the number of multiplications to perform.</p>

<p>So, if EN == 3'b101, the first five values of each vector will be multiplied and added together, then output as a 32-bit value. Right now, I'm trying to do that like:</p>

<pre><code>int acc = 0;

always_comb
begin
for(int i = 0; i &lt; EN; i++) begin
    acc += A[i] * B[i];
    end
end
assign OUT = acc;
</code></pre>

<p>Where A and B are the two input vectors. However, SystemVerilog is telling me there's an illegal comparison being performed between i and EN.</p>

<p>So my questions are:</p>

<p>1) Is this the proper way to have a variable vector ""length"" in SystemVerilog?</p>

<p>2) If so, what's the proper way to iterate n times where n is the value on a bus?</p>

<p>Thank you!</p>
",<verilog><system-verilog>
58924506,Different results for LOG10 in Fortran on Windows and Linux,"<p>I've been working on mixed C++/Fortran numerics code that needs to run on Windows and Linux and traced a discrepancy to the LOG10 function. I'm using gcc/gfortran on Linux and MinGW on Windows.</p>

<p>Here's an example:</p>

<pre><code>PROGRAM FP
REAL VAL1, VAL2, ARG

DATA VAR1 / 12.5663710 /
DATA VAR2 / 10.6640625 /
DATA VAR3 / 1.08791232 /

ARG = VAR1 * VAR2 / VAR3
VAL1 = LOG10 (VAR1 * VAR2 / VAR3)
VAL2 = LOG10 (ARG)

WRITE (*,""(F30.25)"") ARG
WRITE (*,""(F30.25)"") LOG10(ARG)
WRITE (*,""(F30.25)"") VAL1
WRITE (*,""(F30.25)"") VAL2

END PROGRAM FP
</code></pre>

<p>On Linux, I get:</p>

<pre><code> 123.1795578002929687500000000
   2.0905385017395019531250000
   2.0905385017395019531250000
   2.0905385017395019531250000
</code></pre>

<p>On Windows, I get</p>

<pre><code> 123.1795578002929687500000000
   2.0905387401580810546875000
   2.0905387401580810546875000
   2.0905387401580810546875000
</code></pre>

<p>The same values are going into LOG10, but 2.090538<strong>50</strong> is coming out on Linux and 2.090538<strong>74</strong> on Windows. This is enough of a difference to cause substantial problems with testing. What can I do to get the same answer on both platforms?</p>

<p>I'm using someone else's Fortran code and am not an expert in its floating-point implementation details but found the problem by tracing the code side-by-side until the values diverged. The LOG10 seems to be the culprit.</p>

<p>As for compiler versions, on Linux I get:</p>

<pre><code>$ gfortran --version
GNU Fortran (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008
</code></pre>

<p>On Windows:</p>

<pre><code>&gt; gfortran --version
GNU Fortran (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 8.1.0
</code></pre>
",<fortran><precision><gfortran>
62192489,Memory leak in rails app..creating log file,"<p>We've been dealing with a memory leak issue with our Rails app. We're using Ruby 2.5 and We're suspecting that it has to do with symbols not being garbage collectible. I'd like to implement a file where I log the symbols size (Symbol.all_symbols.size) during the life of the application. It should be updated after every request (after_action inside ApplicationController). I'm not sure how to implement this and what the file should look like. I could use some help.</p>
",<ruby-on-rails><memory><memory-management><memory-leaks>
56208458,Permission denied when opening file in Prolog,"<p>I have </p>

<pre><code>outputToFile(DATA) :-
  open('file.txt',write,Stream),
         write(Stream,DATA),
         close(Stream).
solveGame(P):-solve(P, SOL), outputToFile(SOL),write(SOL).
</code></pre>

<p><code>file.txt</code> in the same directory of prolog file , When i run it i get</p>

<blockquote>
  <p>℀ERROR: No permission to open source_sink `'file.txt'' (Permission denied)</p>
</blockquote>
",<prolog>
78142173,Logback: availability of MDCs in forks created inside a StructuredTaskScope,"<p>When using <code>StructuredTaskScope</code> from <a href=""https://openjdk.org/jeps/453"" rel=""nofollow noreferrer"">JEP 453</a> in Java 21+ and forking multiple tasks, I'd like to have MDC values propagated to the forks, so that all logs are properly correlated.</p>
<p>Extending the example from the JEP, I'd like all three logs to carry the same MDC values:</p>
<pre class=""lang-java prettyprint-override""><code>Response handle() throws ExecutionException, InterruptedException {
  try (var scope = new StructuredTaskScope.ShutdownOnFailure()) {
    // TODO: set MDC &quot;somehow&quot;

    Supplier&lt;String&gt;  user  = scope.fork(() -&gt; logger.info(&quot;1&quot;));
    Supplier&lt;Integer&gt; order = scope.fork(() -&gt; logger.info(&quot;2&quot;));

    scope.join().throwIfFailed();

    logger.info(&quot;3&quot;);
    return new Response(user.get(), order.get());
  }
}
</code></pre>
<p>The problem is that MDCs aren't inherited, which might be less of a problem in pre-virtual-threads Java. However, now that creating new threads is cheap &amp; encouraged, inheriting MDCs might be much more useful and common.</p>
<p>My initial attempts to solve this centred around using <code>ScopedValue</code>s (<a href=""https://openjdk.org/jeps/429"" rel=""nofollow noreferrer"">JEP 429</a>). Unlike <code>ThreadLocal</code>s, such values are inherited by scope's forks, so they seem good candidates to carry the MDC markers.</p>
<p>To implement this, I'd have to either directly access a <code>ScopedValue</code> from within Logback's logging components (is that possible?), or to manipulate the MDC. I tried overwriting the <code>MDCAdapter</code>, but this has failed (Logback doesn't seem to use e.g. <code>MDCAdapter.get</code> to actually read the MDC's value).</p>
",<java><logback><mdc><virtual-threads><project-loom>
41694854,WidgetAnalogClock not displayed because it is too large to fit into a software layer (or drawing cache) needs 2250000 bytes only 1639680 available,"<p>WidgetAnalogClock not displayed because it is too large to fit into a software layer (or drawing cache)  needs 2250000 bytes only 1639680 available</p>
",<widget><android-6.0-marshmallow>
77135622,How to log an unauthenticated WebAPI call,"<p>We have an ASP.NET Core MVC web application with WebAPI controllers which logs all API calls their method name, parameters and the username of the one who called it. We've done so by adding a 'DebugActionFilter' which inherits from ActionFilterAttribute. OnActionExecuting we do this logging.</p>
<p>This DebugActionFilter is setup in Startup.cs by this code;</p>
<p><a href=""https://i.stack.imgur.com/1Qc09.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Qc09.png"" alt=""enter image description here"" /></a></p>
<p>This all works well, however only when the call was successfully requested, meaning authenticated. If no authentication happened or it went wrong then the API call does not get logged.</p>
<p>What would be a good place to implement such functionality?</p>
<p>Thanks in advance!</p>
",<asp.net-core>
42092670,Log4Net fails to log on application closing event,"<p>I'm currently developing an WPF application in C#.
I now want to log the closing of the application.
Log4Net works as it should in all parts of my program. (Except for this)</p>

<p>Example: </p>

<p><code>The user clicks the default red ""X"" button every Windows Program has, the log should show ""Application Closed""</code></p>

<p>I created an behavior for the <code>Closing</code> event (this is where I want to log), BUT here Log4Net just Fails to Log. </p>

<p>I tried:</p>

<pre><code>Log.Flush();
Log.Dispose();
</code></pre>

<p>both failed to do the job.
The only thing that seems to work is the delaying of the actual closing by Opening a <code>MessageBox</code>, or doing a <code>Thread.Sleep(1000)</code></p>

<p>Is there a better Solution for this?</p>
",<c#><wpf><log4net>
59104246,How to fix WinRT originate error and holographicspace catastrophic failure exception in Hololens App?,"<p>I've recently started getting the following error periodically in my Hololens App, roughly every minute or so, without changing any of my core app functionalities (mostly UI and bugfixing changes):</p>

<pre><code>onecoreuap\analog\input\holographicdriverclientlib\lib\spatialgraphdriverclient.cpp(145)\Windows.Mirage.dll!6FDACA3F: (caller: 6FDAE477) ReturnHr(5) tid(1878) 8007001F A device attached to the system is not functioning.
onecoreuap\analog\input\holographicdriverclientlib\lib\spatialgraphdriverclient.cpp(2114)\Windows.Mirage.dll!6FDAE299: (caller: 6FDAE2F7) ReturnHr(4) tid(1920) 80070006 The handle is invalid.
..
Exception thrown at 0x7703954B (KernelBase.dll) in App.exe: WinRT originate error - 0x8000FFFF : 'You may not call WaitForNextFrameReady again until you present your oldest out-standing frame.'.
analog\input\mirage\publicapi\holographicspace.cpp(1791)\Windows.Mirage.dll!6FCA1CE9: (caller: 6FC9EF41) ReturnHr(13) tid(12c) 8000FFFF Catastrophic failure
analog\input\mirage\publicapi\holographicspace.cpp(722)\Windows.Mirage.dll!6FC9EF55: (caller: 6FF7AA25) ReturnHr(14) tid(12c) 8000FFFF Catastrophic failure
onecoreuap\windows\analog\input\mirage\stubdll\holographicspace.cpp(541)\Windows.Perception.Stub.dll!6FF7AA39: (caller: 69D25009) ReturnHr(1) tid(12c) 8000FFFF Catastrophic failure
</code></pre>

<p>This error causes the Hololens 2 to freeze for about 10-15 seconds each time it occurs.
I have not yet found a pattern yet, whether it relates to a certain user event or something happening in my environment.</p>

<p>My question would be, if any of you have seen this before and know a fix or if anyone could maybe point me in the right direction? Or is my device broken? Any help would be very much appreciated!</p>

<p>This is my tech stack:</p>

<ul>
<li>Unity3D 2019.2.12f1 </li>
<li>MRTK 2.0.0 </li>
<li>Hololens 2 8362.1234.arm64fre.19h1_release_svc_sydney.191108-1600</li>
<li>App built with ARM</li>
</ul>

<p>Best Wishes</p>
",<unity-game-engine><hololens><mrtk><il2cpp>
58932565,How to change log level in a spring boot project(in production enviroment) by change any property in application properties if I am using log4j2,"<p>I am developing a spring boot service (2.1.7 spring boot version) where I am using log4j2 to establish the logs and their pattern: </p>

<pre><code>    &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;Configuration status=""INFO"" name=""MyService""&gt;
    &lt;Properties&gt;
        &lt;Property name=""project.component""&gt;${bundle:bootstrap:project.component}&lt;/Property&gt;
        &lt;Property name=""project.version""&gt;${bundle:bootstrap:project.version}&lt;/Property&gt;
    &lt;/Properties&gt;
    &lt;Appenders&gt;
        &lt;Console name=""main"" target=""SYSTEM_OUT""&gt;
            &lt;PatternLayout
              pattern=""%d{yyyy-MM-dd HH:mm:ss,SSSZ} ${project.component} ${project.version} - %msg%n""/&gt;
        &lt;/Console&gt;
    &lt;/Appenders&gt;
    &lt;Loggers&gt;
        &lt;Logger name=""root"" level=""INFO""&gt;
            &lt;AppenderRef ref=""main"" level=""INFO""/&gt;
        &lt;/Logger&gt;
    &lt;/Loggers&gt;
&lt;/Configuration&gt;
</code></pre>

<p>I am not using log4j2.properties.
My problem is that I am only able to change the log level by log4j2.xml, I have tried with several spring boot properties in my application.properties as logging.level.root or through actuator endpoints but they did not work. When I am in a production environment and I need to change the logs level I have not a way to do it. </p>

<p>Any suggestion?</p>
",<spring><spring-boot><log4j2>
32323719,how to automatically zip logger files in ruby?,"<p>I have some logger files in my ruby on rails project and I want to zip them weekly or monthly.</p>

<pre><code>log = Logger.new(log_address, 'daily')
</code></pre>

<p>how can i do that?
In addition, my log files are not Ruby on Rails production log and i'm working on ubuntu.</p>
",<ruby-on-rails><ruby><logging><zip>
21800653,Is it possible to read logcat in native C?,"<p>I've seen a lot of different ways in Java to dump Android logcat messages to a file, but I haven't been able to find a way of doing it in C.</p>

<p>Is it possible to programmatically retrieve the messages in C and dump them to a file?</p>
",<android><c><android-ndk><logcat>
45066323,How to prevent Apache writing double backslashes into error log file?,"<p>Apache is writing strings with double slashes to the error log, like so:</p>

<pre><code>PHP Fatal error:  Uncaught Error:
Call to undefined method Selector\\Fieldset\\SelectionForm 
... thrown in module\\Selector\\src\\Selection\\SelectionDataMapper.php 
on line 26, referer: http://...c=start
</code></pre>

<p>Is there a way to make Apache write single slashes?</p>

<p>Software:</p>

<ul>
<li>Windows 10 Version 1703</li>
<li>Apache 2.4.26 (Win64)</li>
<li>PHP Version 7.1.6</li>
</ul>

<p>and I have this in my <code>VirtualHost</code> directive:</p>

<pre><code>ErrorLog ""logs/portal-error.log""
</code></pre>
",<apache><logging>
22151347,Where to close connection/file/logs with multiple threads?,"<p>Assume the following pseudo code for a simple two thread scenario:</p>

<p>I have two threads, I would like to insert data to different tables to database. On thread1, I would like to insert to some table, at same time, I want to insert other data to thread 2. <strong>My question is how/where to place connection.close(),</strong> if I place it on thread 1 and it executes while thread2 is still processing, or vice versa, if thread2 has finished and closed the connection, yet thread1 hasn't finished.</p>

<p>Note, the database is just an example, it can be anything like a file,logger..etc.</p>

<pre><code>class Thread1{
    DataBaseConnection connection;
    main(){
        threadPool = Executors.newFixedThreadPool(1);
        connection.open();
        if(ThisMightTakeSomeTime)
        threadPool.submit(new MyRunnable(connection));
        InsertDataToDataBase(Table A, Table B));
        connection.Close(); //What if thread2 isn't done yet?
    }
}

public class MyRunnable implements Runnable {
    MyRunnable(connection){}
    @override
    void Run() { ...}
    void TaskThatMayTakeWhile(){
        ...get data ...
        ...Connection.InsertToTables(table X, table Y)
    }
}
</code></pre>
",<java><multithreading><threadpool><threadpoolexecutor>
28574894,Listening on multiple UDP ports on logstash,"<p>I have a simple ELK setup to run on a single machine, to read custom-formatted log messages using Logstash and to analyse the data using Elasticsearch/Kibana.</p>

<p>Based off of the config files in one of the replies to <a href=""https://stackoverflow.com/questions/20130864/can-logstash-process-multiple-output-simultaneously"">this</a> stackoverflow post, I added multiple udp input entries in my conf file, part of which is shown here:</p>

<pre><code>input {
  udp {
    type =&gt; ""log_type_1""
    port =&gt; 9999
  }
  udp {
    type =&gt; ""log_type_2""
    port =&gt; 9998
  }
  udp {
    type =&gt; ""log_type_3""
    port =&gt; 9997
  }
}
</code></pre>

<p>When I re-start the logstash service and check the logs under <code>/var/log/logstash/logstash</code>, I see error messages with the message:</p>

<pre><code>{:timestamp=&gt;""2015-02-17T18:15:56.032000-0800"", :message=&gt;""UDP listener died"", :exception=&gt;#&lt;SocketError: bind: name or service not known&gt;, :backtrace=&gt;[""org/jruby/ext/socket/RubyUDPSocket.java:160:in `bind'"", ""/opt/logstash/lib/logstash/inputs/udp.rb:69:in `udp_listener'"", ""/opt/logstash/lib/logstash/inputs/udp.rb:50:in `run'"", ""/opt/logstash/lib/logstash/pipeline.rb:163:in `inputworker'"", ""/opt/logstash/lib/logstash/pipeline.rb:157:in `start_input'""], :level=&gt;:warn}
</code></pre>

<p>Any ideas as to what I'm doing wrong over here? I tried running logstash using the <code>--configtest</code> flag and I don't see any problems with my configuration. I'm guessing it checks only for syntax correctness.</p>

<p>Thanks!</p>
",<logstash>
19551906,Log Apache POST data,"<p>I've been running across a few articles today pertaining to this specific topic, but I'm constantly running into an error -- not sure if it's because the articles are old and default configs have changed since then or what.</p>

<p>I basically want to log POST data from my web server. I've tried following articles such as: <a href=""http://www.cyberciti.biz/faq/apache-mod_dumpio-log-post-data/"" rel=""nofollow"">http://www.cyberciti.biz/faq/apache-mod_dumpio-log-post-data/</a>, but there's no such thing as ""DumpIOInput On"" inside of my /etc/apache2/apache2.conf file. Therefore, the rest of those instructions are useless for me at this point.</p>

<p>I'm not exactly too familiar with modules in Apache, so ""use this module"" might not help much although I'll research it. Just a heads up.</p>

<p>Any feedback would be greatly appreciated.</p>

<p>PS: Is there not a way to mark a comment as answer? :\</p>
",<apache>
57781822,Catching Server Error 500 using logging in Django (Server gunicorn),"<p>I have an application deployed on Heroku and sometimes it throws the server error 500 randomly. I am trying to implement logging in my project. I am reading the docs but I am missing some critical piece of information. The docs say, Once you have configured your loggers, handlers, filters and formatters, you need to place logging calls into your code. My question is where exactly to put the logging code because I have already used try-except for all the parts, as far as I know, that may throw an error?</p>

<p>I have done a tutorial on the topic and reading the docs but that doesn't seem to convey the message to me.</p>
",<django><logging><django-logging>
24180221,Logging json posts with resteasy,"<p>I'm looking for a way to log JSON posts in a RESTEASY framework. </p>

<p>I woul like to log the POST body to log file to see what the client is sending to me.</p>

<p>Is there any interceptor or something similar that I can use, I have found an example for PreProcessInterceptor but it looks like it is deprecated.</p>

<p>I'm using resteasy 3.0.8</p>
",<json><post><logging><resteasy>
4335705,Python logging redirecting stdout from multiple processes,"<p>I am trying to capture the stderr and stdout of a number of processes and write their outputs to a log file using the python logging module. The code below seems to acheive this. Presently I poll each processes stdout and write to the logger if there is any data. Is there a better way of doing this.</p>

<p>Also I would also like to have a master log of all individual processese activity, in other words I want to automatically (without polling) write all the stdout/stderr for each process to a master logger. Is this possible?</p>

<p>Thanks</p>

<pre><code>class MyProcess:
def __init__(self, process_name , param):
    self.param = param
    self.logfile = logs_dir + ""Display_"" + str(param) + "".log""
    self.args = [process_name, str(param)]
    self.logger_name = process_name + str(param)
    self.start()
    self.logger = self.initLogger()

def start(self):
    self.process = Popen(self.args, bufsize=1, stdout=PIPE, stderr=STDOUT) #line buffered
    # make each processes stdout non-blocking
    fd = self.process.stdout
    fl = fcntl.fcntl(fd, fcntl.F_GETFL)
    fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)

def initLogger(self):
    f  = logging.Formatter(""%(levelname)s -%(name)s - %(asctime)s - %(message)s"")
    fh = logging.handlers.RotatingFileHandler(self.logfile, maxBytes=max_log_file_size, backupCount = 10)
    fh.setFormatter(f)

    logger = logging.getLogger(self.logger_name)
    logger.setLevel(logging.DEBUG)
    logger.addHandler(fh) #file handler
    return logger

def getOutput(self): #non blocking read of stdout
    try:
        return self.process.stdout.readline()
    except:
        pass

def writeLog(self):
    line = self.getOutput()
    if line:
        self.logger.debug(line.strip()) 
        #print line.strip()



process_name = 'my_prog'
num_processes = 10
processes=[]

for param in range(num_processes)
    processes.append(MyProcess(process_name,param))

while(1):
    for p in processes:
        p.writeLog()

    sleep(0.001)
</code></pre>
",<python><logging><redirect><stdout><pipe>
32455661,How to log Rails queries before they happen?,"<p>Rails logger by default will show the SQL after it's been executed. Sometimes - mainly when a query takes a long time - I want to configure the logger to output the SQL before it executes. Then it can add a follow-up log once the database has responded.</p>

<p>Basic idea is something like:</p>

<pre><code>10:01:01 POST Load Executing ""SELECT * from posts;'
10:01:03 POST Load 1712ms
</code></pre>

<p>How can Rails be configured to break the SQL logging into 2 steps like this?</p>
",<ruby-on-rails><logging><activerecord>
42720459,Why does Python/Django keep redirecting to url 'catalog'?,"<p>I'm stepping into the Python world. First I learned a little Python. Then I learned the basics of Django, and on top of that I'm learning Wagtail (framework for template managing for Django)</p>
<p>To learn Django a went through <a href=""https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django/Tutorial_local_library_website"" rel=""nofollow noreferrer"">a tutorial</a> to build a site locally and test it in 127.0.0.1:8000.</p>
<p>At some point of the tutorial I configured the settings (because the tutorial said so) to redirect to <strong>127.0.0.1:8000/catalog</strong> when browsing to <strong>127.0.0.1:8000</strong> alone.</p>
<p>Then I started the Wagtail tutorial, as a completely different project in another folder. Not sharing any code with the <a href=""https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django/Tutorial_local_library_website"" rel=""nofollow noreferrer"">tutorial Django project</a>.</p>
<p>I run the server and the console says it is now running in port 127.0.0.1:8000 and when I browse it, it redirects me to <em><strong>/catalog</strong></em> and of course shows a Page not found error since this project doesn't have one app <em>catalog</em>.</p>
<p>I workaround this by opening Chrome in Incognito Mode. But still I would like to know why this is happening and how to solve it to add to my knowledge of how Python works.</p>
<p>Some notes:</p>
<ul>
<li>I'm on Windows</li>
<li>I killed all processes related to Python and actually this is still happening after turning my PC off and on</li>
<li>I know I could use a different port, please do not give me that answer. My goal is to learn.</li>
</ul>
",<python><django><windows><wagtail>
12314399,regex for rsyslog to exclude a pattern,"<p>I need an rsyslog regex to forward all the messages containing the word ""FIREWALL"" to a remote server. The original log format is:</p>

<blockquote>
  <p>Jul 24 16:33:09 FW02 kernel: [3456825.472985] FIREWALL_DENY_IN: IN=eth2 OUT=MAC=ff:ff:ff:ff:ff:ff:00:1b:78:e4:b3:24:08:00 SRC=10.101.103.193 DST=10.101.103.255 LEN=237 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=UDP SPT=51512 DPT=694 LEN=217</p>
</blockquote>

<p>The required log format is to be without the kernel times:</p>

<blockquote>
  <p>Jul 24 16:33:09 FW02 kernel: FIREWALL_DENY_IN: IN=eth2 OUT=MAC=ff:ff:ff:ff:ff:ff:00:1b:78:e4:b3:24:08:00 SRC=10.101.103.193 DST=10.101.103.255 LEN=237 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=UDP SPT=51512 DPT=694 LEN=217</p>
</blockquote>

<p>My experience with regex is basic. I was able to match the part I need to exclude with:</p>

<blockquote>
  <p>[ *[0-9]*\.[0-9]*\]</p>
</blockquote>

<p>but that's all. The regex must be validated on <a href=""http://www.rsyslog.com/regex/"" rel=""nofollow"">http://www.rsyslog.com/regex/</a></p>
",<regex><logging><rsyslog>
613919,C logging libraries,"<p>What are the C logging API's out there?
Some of them I found are</p>

<ol>
<li><a href=""http://sourceforge.net/projects/log4c/"" rel=""noreferrer"">log4c</a></li>
<li><a href=""http://www.pantheios.org/"" rel=""noreferrer"">pantheios</a> </li>
<li><a href=""http://home.gna.org/lwl/"" rel=""noreferrer"">lwl</a></li>
</ol>

<p>Is anyone aware of other loggers.</p>

<p>Thanks.</p>
",<c><logging>
32461217,How to define global logger for whole application?,"<p>I have application with several classes each one has own logger (<code>Logger log = Logger.getLogger(this.class)</code>). Each class has methods which need to be logged.</p>

<p>Is there any way to define logger (instead ""this.class"") to make all classes  logged into one appender (one file) ?</p>

<p>It would be great if it can be done with help of VM option, like <code>-Dlog4j.configuration=...</code></p>
",<java><logging><log4j>
42539923,Sending info messages to file with log4J,"<p>I have a scala spark application where I am trying to log the start of specific events to a file.  Application looks like this:</p>

<pre><code>package com.myApp

import org.apache.logging.log4j.scala.{Logger, Logging}

object someSpark extends Logging {

  def main(args:Array[String] {
    logger.info(""The application has started"")
    //Do some Spark stuff here//
    logger.info(""The application has ended"")
  }
}
</code></pre>

<p>I have an appender set up in my log4j properties file like this:</p>

<pre><code>log4j.appender.appAppender=org.apache.log4j.DailyRollingFileAppender
log4j.appender.appAppender.File=./logs/appLog.log
log4j.appender.appAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.appAppender.layout.ConversionPattern=%d [%t] %-5p %c - %m%n
</code></pre>

<p>and also have this line:</p>

<pre><code>log4j.logger.com.myApp=ALL, appAppender
</code></pre>

<p>As I understand it, this should run any log messages written when executing code in com.myApp to the file ./logs/appLog.log, however, nothing actually gets written there, just an empty file.  The messages do show up in the mysterious file in that same location called app.log.  I have no idea what is causing that file to be generated nor how I can control what the output looks like.  Any insight into what I am doing wrong is appreciated.  Also, let me know what other info I can provide.</p>

<p>Thanks.</p>
",<scala><logging><log4j>
43771055,Trouble with Facebook Product Catalog Diagnostics,"<p>I have been trying to get the diagnostics page on my Facebook Product Catalogs page to stop reporting errors for my 'Add to Cart' and 'ViewContent' events.</p>

<p>The errors are as follows:
Missing content_ids parameter
Missing content_type parameter</p>

<p>I was fairly sure that I already had these parameters in place, so I am not sure why I am still being given error messages.</p>

<pre><code>&lt;!-- Facebook Pixel Code --&gt;
&lt;script&gt;
!function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;
n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
document,'script','https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '1516478395030244'); // Insert your pixel ID here.

    var lookup = [];
    $('#details-tabs div #details-tab div div div div div.row.sm-margin-bottom-10.xs-margin-bottom-20').each(function(index, value){ 
        var self = this;
        var lastKey = '';
         $(self).find('div').each(function(index, value){
             if(index == 0){
                lastKey = $(this).html();
             } else {
                lookup[lastKey] = $(this).html();
             }
         });
    });
    lookup['address'] = $('.property-details h1').first().html();

    if(lookup['MLS#'] != undefined){
        fbq('track', 'ViewContent', {
              content_name: lookup['address'],
              content_category: lookup['Property Type'],
              content_ids: [lookup['MLS#']],
              content_type: 'product',
              value: lookup['Price Before'],
              currency: 'USD'
         });
    }

    $('.btn-block.fancybox').click(function(){
        fbq('track', 'AddToCart', {
              content_name: lookup['address'],
              content_category: lookup['Property Type'],
              content_ids: [lookup['MLS#']],
              content_type: 'product',
              value: lookup['Price Before'],
              currency: 'USD'
        });
    });

&lt;/script&gt;
&lt;noscript&gt;&lt;img height=""1"" width=""1"" style=""display:none""
src=""https://www.facebook.com/tr?id=1516478395030244&amp;ev=PageView&amp;noscript=1""
/&gt;&lt;/noscript&gt;
&lt;!-- DO NOT MODIFY --&gt;
&lt;!-- End Facebook Pixel Code --&gt;
</code></pre>

<p>Does anyone have any thoughts on why I may be receiving these errors? The tags seem to work as they should on my site.</p>

<p>Any help would be greatly appreciated!</p>

<p>Best,</p>

<p>Eric M.</p>

<p>Update 5.4.2017:</p>

<p>Here is an example of what my Pixel Helper returns when a 'ViewContent' event occurs:
<a href=""https://i.stack.imgur.com/r9ZXE.jpg"" rel=""nofollow noreferrer"">FB Pixel Helper Results</a></p>
",<javascript><html><facebook>
58529368,How to get current user_id of logged in user,"<p>I just created a php file to update a field in mysql db, my update query is where i have an issue, i want to set 'user_id' to be the user_id of the current user that is logged in so the update will go to the appropriate user. I haven't been able to get this to work. I feel its because i haven't declared the current user earlier in the code, how can i do this?</p>

<p>Here is the line:</p>

<pre><code>$sql = ""UPDATE wp85_usermeta SET `meta_value` = `meta_value`+65000 WHERE `user_id` = user_id AND `meta_key` = 'mycred_default'""
</code></pre>

<p>Here is the full code:</p>

<pre><code>&lt;?php
    $servername = ""localhost"";
    $username = ""sparyqmr_wp324"";
    $password = ""(S8p3uV-2t"";
    $dbname = ""sparyqmr_wp324"";

    // Create connection
    $conn = new mysqli($servername, $username, $password, $dbname);
    // Check connection
    if ($conn-&gt;connect_error) {
        die(""Connection failed: "" . $conn-&gt;connect_error);
    }

    $sql = ""UPDATE wp85_usermeta SET `meta_value` = `meta_value`+65000 WHERE `user_id` = user_id AND `meta_key` = 'mycred_default'"";

    if ($conn-&gt;query($sql) === TRUE) {
        echo ""Record updated successfully"";
    } else {
        echo ""Error updating record: "" . $conn-&gt;error;
    }

    $conn-&gt;close();
?&gt;
</code></pre>
",<php><mysql><wordpress>
22104759,LoggerFactory ArrayUtils Random,"<p>this one does not fly for me:
<a href=""http://pastebin.com/Mctnidng"" rel=""nofollow"">http://pastebin.com/Mctnidng</a>
It was elaborated in this forum under a different thread. I've divided it into two files</p>

<pre><code>AlphabetHelper.java

AlphabetHelperTest.java 



java  -version
java version ""1.6.0_18""
Java(TM) SE Runtime Environment (build 1.6.0_18-b07)
Java HotSpot(TM) Server VM (build 16.0-b13, mixed mode)

javac  -version
javac 1.6.0_18
</code></pre>

<p>on attempt to compile I included some </p>

<pre><code>import java.util.Random;
import java.util.logging.Logger;
import java.util.List;
import java.math.BigInteger;
import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
</code></pre>

<p>But it does not take of. I assume there must be some other Java distribution out there, apache or android. The code however looks quite good, how can I get to run on my Java 1.6? Most oder Java sourcode works fine on my machine. </p>

<pre><code>javac  -Xlint  AlphabetHelper.java
AlphabetHelper.java:41: cannot find symbol
symbol  : variable ArrayUtils
location: class AlphabetHelper
                ArrayUtils.toObject(
                ^

javac -Xlint  AlphabetHelperTest.java
AlphabetHelperTest.java:5: cannot find symbol
symbol  : class Random
location: class AlphabetHelperTest
    private Random random;
            ^

AlphabetHelperTest.java:8: cannot find symbol
symbol  : class Logger
location: class AlphabetHelperTest
    private static final Logger LOG = LoggerFactory.getLogger(AlphabetHelperTest.class);
                         ^
</code></pre>

<p>it is all about this file   <a href=""http://pastebin.com/Mctnidng"" rel=""nofollow"">http://pastebin.com/Mctnidng</a>    to be compiled tested and deployed on Java 1.6</p>

<p>Sincerely, </p>
",<java><string><encode><utf><alphabet>
12031768,Git pre-commit hook to detect and block NSLog debug calls,"<p>How would I create a git pre-commit hook that blocks commits with</p>

<pre><code>NSLog(@""random debug stuff"");
</code></pre>

<p>but skips over</p>

<pre><code>//NSLog(@""useful to keep around"");
</code></pre>
",<iphone><objective-c><git>
43327265,log4net does not create any log files,"<p>I am trying to implement logger with Log4net. I have done all the configuration that was documented but it does not create any messages also it does not even create a log file as well. I made sure the directory specified has user 'EVERYONE' full permissions.</p>

<pre><code>&lt;configuration&gt;
  &lt;configSections&gt;
    &lt;section name=""log4net"" type=""log4net.Config.Log4NetConfigurationSectionHandler,Log4net"" requirePermission=""false""/&gt;
  &lt;/configSections&gt;

&lt;appSettings&gt;
            &lt;add key=""log4net.Internal.Debug"" value=""true""/&gt;
&lt;/appSettings&gt;
  &lt;system.webServer&gt;
        &lt;staticContent&gt;
            &lt;mimeMap fileExtension="".properties"" mimeType=""text/plain"" /&gt;
        &lt;/staticContent&gt;
    &lt;/system.webServer&gt;

  &lt;log4net&gt;

    &lt;appender name=""RollingLogFileAppender""  type=""log4net.Appender.RollingFileAppender""&gt;

      &lt;file value=""C:\\Users\\raviteja\\AppData\\Local\\Temp\\logs"" /&gt;
      &lt;appendToFile value=""true"" /&gt;
      &lt;datePattern value=""yyyyMMdd"" /&gt;

      &lt;rollingStyle value=""Date"" /&gt;


      &lt;layout type=""log4net.Layout.PatternLayout""&gt;
        &lt;conversionPattern value=""%-5p %d %5rms %-22.22c{1} %-18.18M - %m%n"" /&gt;
      &lt;/layout&gt;
    &lt;/appender&gt;
  &lt;root&gt;
      &lt;level value=""ALL"" /&gt;
      &lt;appender-ref ref=""RollingLogFileAppender"" /&gt;
    &lt;/root&gt;
  &lt;/log4net&gt;
&lt;/configuration&gt;
</code></pre>

<p>my Global.asax file has following lines</p>

<pre><code>    protected void Application_Start(object sender, EventArgs e)
    {
        log4net.Config.XmlConfigurator.Configure();
        log4net.ILog log = log4net.LogManager.GetLogger(System.Reflection.MethodBase.Ge‌​tCurrentMethod().Dec‌​laringType);
        log.Debug(""This is a DEBUG level message. Typically your most VERBOSE level."");
}
</code></pre>

<p>and My page has following code to test</p>

<pre><code>private static readonly log4net.ILog log =  LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType);
protected void Page_Load(object sender, EventArgs e)
{

    log.Debug("" log file created and tested "");

    log.Debug(DateTime.Now + "" - Page Load"");
}
</code></pre>

<p>The logs folder specified in the web.config section EVERYONE has full permissions to the folder. I can not seem to think any other reason why the log4net is not able to create log files.</p>

<p>Do you guys see anything that i am missing ?</p>
",<log4net>
62349958,How to log request and responses in spring boot,"<p>What is the best way log request and responses in spring boot for all applicable http methods (GET, POST, PUT etc) so that at a later point it can be centralized and analyzed using elastic search, log stash and kibana. Appreciate the advises.</p>
",<spring-boot><logging><elk>
63172480,Unable to prevent WARN logging when using a `WebClient` to contact a server which is not (yet) up,"<p>I have a test that needs to wait until a server is up and it uses REST calls to the health actuator to check this. However, this means that initially the application is not yet responding to any HTTP requests, because there is no listener on that port yet. With <code>RestTemplate</code> this is no problem, as long as I catch the right exceptions, but if I use a <code>WebClient</code>, I get log messages from &quot;<code>reactor.netty.http.client.HttpClientConnect</code>&quot; stating there was a premature closing of the connection BEFORE the response.</p>
<p>Now I'll accept the confusion caused by some piece of code trying to read a response when there wasn't even a valid connection yet, but I appear unable to prevent this behavior. The <code>WebClient</code> is constructed as follows:</p>
<pre><code>        HttpClient httpClient = HttpClient.create(ConnectionProvider.newConnection())
                .tcpConfiguration(tcpClient -&gt; tcpClient
                        .option(CONNECT_TIMEOUT_MILLIS, httpConnectionTimeoutMillis)
                        .doOnConnected(conn -&gt; conn
                                .addHandlerLast(new ReadTimeoutHandler(httpReadTimeoutMillis, MILLISECONDS))))
                .doOnRequestError((request, e) -&gt; { logger.warn(&quot;onRequestError: We have a request error: {}.&quot;, e.getMessage()); })
                .doOnResponseError((response, e) -&gt; { logger.warn(&quot;onResponseError: We have a response error: {}.&quot;, e.getMessage()); });
        return WebClient
                .builder()
                .baseUrl(url)
                .clientConnector(new ReactorClientHttpConnector(httpClient))
                .build();
    }
</code></pre>
<p>Now if I use this with a <code>get().retrieve()</code> or even <code>get().exchange()</code>, I immediately see in the logging:</p>
<pre><code>11:02:49.138 [reactor-http-epoll-1] WARN  r.n.http.client.HttpClientConnect - [id: 0x97015555, L:/127.0.0.1:38816 ! R:localhost/127.0.0.1:8024] The connection observed an error
reactor.netty.http.client.PrematureCloseException: Connection prematurely closed BEFORE response
11:02:49.139 [reactor-http-epoll-1] WARN  i.a.t.i.a.AbstractClusterNode - onError: We have a request error: Connection prematurely closed BEFORE response.
11:02:49.139 [reactor-http-epoll-1] WARN  i.a.t.i.a.AbstractClusterNode - onRequestError: We have a request error: Connection prematurely closed BEFORE response.
</code></pre>
<p>It appears the <code>onRequestError</code> and <code>onResponseError</code> log messages were created <em>after</em> the internal one. I found the text of this &quot;The connection observed an error&quot; in a handler for uncaught exceptions, but appear unable to catch it beforehand. I appear unable to detect the failed connection in any other way, even though I <em>am</em> able to let it result in a default value.</p>
<p>Anyone have an idea how to do this correctly and provide some kind of result without seeing this logs? Setting the log filter is kind of &quot;evading the issue&quot;...</p>
<p>Cheers,
Bert Laverman</p>
",<rest><spring-webflux><reactor-netty>
30351854,Postgres from unix shell out put not appear in Log,"<p>I am writing a batch job for Postgres for first time. I have return "".sh"" file, which has a command with out any out put in the log or console.</p>

<p>Code </p>

<pre><code>export PGPASSWORD=&lt;password&gt;
psql -h &lt;host&gt; -p &lt;port&gt; -U &lt;user&gt; -d &lt;database&gt; --file cleardata.sql &gt; log\cleardata.log 2&gt;&amp;1
</code></pre>

<p>What I did at cammond line</p>

<p>su postgres</p>

<p>and run ./cleardatasetup.sh</p>

<p>Nothing is happening.</p>

<p>Please note : When I try psql command in Unix command line, I am getting message as some SQL exception which is valid.</p>

<p>Can any one please help me in this regard.</p>
",<postgresql><shell><unix>
39164167,"Serilog, Loggly-csharp, FullNetFx","<p>I've got a .net 4.5.2 application where I'm trying to integrate with Serilog and Loggly. </p>

<p>Unfortunately I'm getting the following error:</p>

<blockquote>
  <p>Additional information: The configuration is invalid. Creating the
  instance for type IApplicationLog failed. Could not load file or
  assembly 'Serilog.FullNetFx, Version=1.5.0.0, Culture=neutral,
  PublicKeyToken=24c2f752a8e58a10' or one of its dependencies. The
  system cannot find the file specified.</p>
</blockquote>

<p>I've tried with the latest version of Loggly-csharp (4.6.0.2) and 4.5.1.11 but still get the same error. The Serilog version is 2.2.0.</p>

<p>Any suggestions on how to fix this? I'm setting up serilog and loggly through appsettings.</p>

<ul>
<li>Serilog 2.2.0 </li>
<li>Serilog.Settings.AppSettings 2.0.0 </li>
<li>Serilog.Sinks.Loggly 2.0.11 </li>
<li>Loggly-csharp 4.5.1.11 </li>
<li>Loggly-csharp-config 4.5.1.11</li>
</ul>
",<.net><serilog><loggly>
41047939,ggplot barplot : How to display small positive numbers with log scaled y-axis,"<p>Main issue:  I want to display the data from 0 to 1.0 as an upward bar (starting from 0) but do not want the intervals to be equally spaced but log spaced.</p>

<p>I am trying to display the column labeled ""mean"" in the dataset below as a bar plot in ggplot but as the numbers are very small, I would like to show the y-axis on a log scale rather than log transform the data itself. In other words, I want to have upright bars with y-axis labels as 0, 1e-8, 1e-6 1e-4 1e-2 and 1e-0 (i.e. from 0 to 1.0 but the intervals are log scaled).</p>

<p>The solution below does not work as the bars are inverted. </p>

<pre><code>&gt; print(df)
        type         mean           sd           se snp
V7    outer 1.596946e-07 2.967432e-06 1.009740e-08   A
V8    outer 7.472417e-07 6.598652e-06 2.245349e-08   B
V9    outer 1.352327e-07 2.515771e-06 8.560512e-09   C
V10   outer 2.307726e-07 3.235821e-06 1.101065e-08   D
V11   outer 4.598375e-06 1.653457e-05 5.626284e-08   E
V12   outer 5.963164e-07 5.372226e-06 1.828028e-08   F
V71  middle 2.035414e-07 3.246161e-06 1.104584e-08   A
V81  middle 9.000131e-07 7.261463e-06 2.470886e-08   B
V91  middle 1.647716e-07 2.875840e-06 9.785733e-09   C
V101 middle 3.290817e-07 3.886779e-06 1.322569e-08   D
V111 middle 6.371170e-06 1.986268e-05 6.758752e-08   E
V121 middle 8.312429e-07 6.329386e-06 2.153725e-08   F
</code></pre>

<p>The code below properly generates the grouped barplot with error bars</p>

<pre><code>ggplot(data=df, aes(x=snp,y=mean,fill=type))+
  geom_bar(stat=""identity"",position=position_dodge(),width=0.5) + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se),width=.3, position=position_dodge(.45)) 
</code></pre>

<p>However, I want to make the y-axis log scaled and so I add in scale_y_log10() as follows:</p>

<pre><code> ggplot(data=df, aes(x=snp,y=mean,fill=type))+
  geom_bar(stat=""identity"",position=position_dodge(),width=0.5) + scale_y_log10() +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se),width=.3, position=position_dodge(.45)) 
</code></pre>

<p>But strangely the bars are falling from above but I simply want them to be going up (as normally) and don't know what I am doing wrong. </p>

<p>Thank you</p>
",<r><ggplot2><logarithm><geom-bar>
5956700,Prolog file manipulation problem,"<p>I use swi prolog and my code like this.
 I read data predicate from file and its arity count can change. How can I generalize it. For example, If data(a1,b1,c1) writes in the file, how can I find solution? Do you have any idea? </p>

<pre><code>&gt;    basla:-consult('test.pl'),
&gt;          answer(L1,L2,L3,L4,L5),
&gt;          list_to_set(L1, X),
&gt;        
&gt;          write(X).
&gt;     answer(L1,L2,L3,L4,L5):-
&gt;       findall(First, data(First,_,_,_,_),L1),
&gt;       findall(Second, data(_,Second,_,_,_),L2),
&gt;       findall(Third, data(_,_,Third,_,_),L3).
</code></pre>
",<list><file><prolog>
21973613,Eclipse Error Log is gone crazy,"<p>the other day i was editing a layout when suddendly eclipse freeze for a long time and when it came back I couldn't run the application nor edit the layout anymore. I reboot my PC and I was able again to run the app but the LogCat doesn't work anymore.</p>

<p>This are some screens:</p>

<p><img src=""https://i.stack.imgur.com/MzeyG.png"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/DUwKO.png"" alt=""enter image description here""></p>

<p>Can somebody tell me what is happening ?</p>
",<android><eclipse><logcat><error-log>
71405044,How to patch log4j on Mac for ActiveMQ?,"<p>I have got installed ActiveMQ on Mac using brew but have been identified as having a critical vulnerability related to the log4j security issue, and so it requires a patch.</p>
<p>In this case, how can I do patching log4j?</p>
<blockquote>
<p>/System/Volumes/Data/usr/local/Cellar/activemq/5.16.3/libexec/lib/optional/log4j-1.2.17.jar</p>
</blockquote>
<blockquote>
<p>/usr/local/Cellar/activemq/5.16.3/libexec/lib/optional/log4j-1.2.17.jar</p>
</blockquote>
",<log4j><activemq-classic>
39838318,"Area under log curves in Octave, array of coordinate points from image of line","<p>I have image files of curved black lines on a white background. All the lines are different, but here is one example. The actual image is copyrighted; I cannot upload it. I have traced the line in MS Paint.</p>

<p><a href=""https://i.stack.imgur.com/mXQns.png"" rel=""nofollow noreferrer"">red line</a></p>

<p>My end objective is to calculate the area under these curves using trapz, but first I must convert the y-coordinates to their 10th power, since they are in log scale. I see the first step as getting an array of coordinates that represent the lines. </p>

<p>This is my first time using Octave. I used imread to upload my image. It shows a matrix of 255s and 0s corresponding to my image. I tried</p>

<pre><code>[yy xx] = find(img);
</code></pre>

<p>which I saw on another question (<a href=""https://stackoverflow.com/questions/2641809/calculate-area-under-fft-graph-in-matlab"">Calculate area under FFT graph in MATLAB</a>), but when I entered</p>

<pre><code>figure;plot(xx,yy,'.');
</code></pre>

<p>I got an image of two histogram-looking bars.</p>

<p>For my second try, I tried the top answer at</p>

<p><a href=""https://stackoverflow.com/questions/2973973/how-do-i-calculate-the-area-under-a-curve-in-an-image-with-matlab"">How do I calculate the area under a curve in an image with MATLAB?</a></p>

<p>However, the first line</p>

<pre><code>[img,map] = imread('file.png')
</code></pre>

<p>returned img as uint8 of 178x373x3 and map as a double of 0x0. </p>

<p>Alternately, if there is a smarter way to solve my problem in R or Python, please point me in that direction.</p>

<p>Thanks for any help!</p>
",<matlab><image-processing><octave>
4363825,i want to read a call log history,"<p>I want to read call log history in j2me. Is it possible?
If yes, how to do it ?</p>
",<java-me><nokia>
51882652,How to log reading from a(any) table in Entity Framework,"<p>In my project we want the ability to log who has viewed a particular table(or any table). Now I am not looking to log SQL queries, rather I am looking for the most generic way to log (much like logging updating and deleting) who has read (viewing) data. I execute either something builtin to Entity Framework or I execute custom code I write. I am not sure which is best or considered best practice. </p>

<p>Here is an example of a normal get</p>

<pre><code>public List&lt;DataModel.Table1&gt; GetTable1(int Id1, int Id2)
{
    using (var context = new MyContext(base.GetContext))
    {
        var x = (from s in context.Table1
                 where s.Id1 == Id1 &amp;&amp; s.Id2 == Id2
                 select s).ToList();
        return x;
    }
}
</code></pre>

<p>I am looking for a way to log who has done this. Either in say the BL(or in this call) I then pass down another call to the data access layer with another model or is there a built in way to log the table name, the primary key that were retrieved and the user who did it that is built into Entity Framework. I know there is for updating and such. But I'm not sure about reading (or viewing).</p>

<p>Here is a little something I cooked up as an example. Below, is this how I would do it? If so can I set it up a little bit nicer or cleaner. Any help would be greatly appreciated.</p>

<pre><code>    public List&lt;DataModel.Table1&gt; GetTable1(int Id1, int Id2)
            {
string y =  context.Database.Log.Target.ToString();
                using (var context = new MyContext(base.GetContext))
                {
                    var x = (from s in context.Table1
                             where s.Id1 == Id1 &amp;&amp; s.Id2 == Id2
                             select s).ToList();
List&lt;DataModel.ViewLog&gt; views = new List&lt;DataModel.ViewLog&gt;();
                foreach (DataModel.Table1 f in  x)
                {
                    DataModel.ViewLog v = new DataModel.ViewLog
                    {
                        TableName = y,
                        CreatedDate = DateTime.Now,
                        ViewedByEmployee = """",//ill get this somewhere else or pass it down
                        PkIdViewed = f.Id1
                    };
                    views.Add(v);
                }
                DataAccess.ViewLog viewLog = new                 DataAccess.ViewLog();
                viewLog.LogView(views);//saves everything in the list
                    return x;
                }
            }
</code></pre>

<p>Edit. Note I am looking for a centralized solution so that I don't have to copy paste the little blurb of code in every single get method I have and second it should allow for any table to be logged not just one.</p>
",<c#><entity-framework-6>
5389137,Get a dummy slf4j logger?,"<p>Can I get a dummy logger from slf4j? (Think the null object design pattern.) If so, can someone provide an example? Or will I have to implement a custom logger if I want to do that?</p>

<p>I'm hoping to write a function along the lines of</p>

<pre><code>private Logger logger;
static Logger nullLogger;

static {
    nullLogger = getMeADummyLogger();
}

public Logger getLogger() {
    return this.logger == null ? nullLogger : this.logger;
}

// then, elsewhere:
this.getLogger().info(""something just happened"");
</code></pre>

<p>and not get a <code>NullPointerException</code> on that last line if no logger has been set.</p>
",<java><slf4j><null-object-pattern>
26158898,JBoss EAP 5 leaves a lot of TCP connections open in CLOSE_WAIT status. How can this be traced in logs?,"<p>So I see a lot of TCP connections being left open in CLOSE_WAIT status from our application, running on JBoss EAP 5. This happens only in one test environment, all other environments are fine. The end result is that the JVM crashes due to not enough memory.</p>

<p>I need to trace where in the application the threads are being left open. How can I debug this? Can I configure this in jboss-log4j.xml? </p>
",<java><jboss><threadpool><jboss5.x>
22142751,"FQL returning empty response when querying privacy table, probably permissions error","<p>I am doing this query:</p>

<pre><code>SELECT value FROM privacy WHERE id=10203382033336176
</code></pre>

<p>Unfortunately Facebook is giving me an empty array as a response. Which permission setting should I request so I can see a current logged user's privacy setting on a specific post?</p>

<p>Edit:
Ok, I tried the FQL Tool on Facebook's developers page and I got this reponse using the same query, same access token:</p>

<pre><code>{
  ""data"": [
  ]
}
</code></pre>

<p>There may be a problem if the post has it's privacy setting set as ""Only me""? The FQL shouldn't at least return that ? :D</p>

<p>Scopes requested from the Access Token Debugger:</p>

<pre><code>    basic_info, export_stream, public_profile, read_stream, user_friends
</code></pre>
",<facebook-javascript-sdk><facebook-fql>
58826121,Question about what shows up in my git log,"<p>I had a branch in git that got a little too off track, so I decided to made a new branch from the current master and instead cherry-pick the commits one-by-one to have more control over how it developed. I thought the best way to do this would be to use</p>

<pre><code>git log current_master..off_track_branch --reverse
</code></pre>

<p>to get the list of commits, and then use those hashes to cherry-pick to my liking. I would have expected that once I did cherry-pick a commit it wouldn't anymore show up in my git log (since that commit was no longer a difference between them).</p>

<p>Much to my surprise no matter how many commits I cherry picked the log looks the same. Why is this so, and is there a way to adjust the settings so that I only see the commits I haven't cherry picked yet?</p>
",<git>
56262575,Logging user activity in a web browser using python,"<p>I want to log user web driver actions such as navigating through sites and clicking on buttons.</p>

<p>iv'e been using the python module Selenium for web automation and was looking to find a solution using the Selenium EventFiringWebDriver AbstractEventListener but I have only been able to log actions done from the script itself.</p>

<pre><code>from selenium.webdriver import Chrome
from selenium.webdriver.support.events import EventFiringWebDriver, AbstractEventListener
from time import sleep
class MyListener(AbstractEventListener):
    def before_navigate_to(self, url, driver):
        print(""Before navigate to %s"" % url)
    def after_navigate_to(self, url, driver):
        print(""After navigate to %s"" % url)
    def before_click(self, element, driver):
        print(""clicked on %s"" %element)
def main():
    driver = Chrome(executable_path=r""C:\Users\user1\Downloads\chromedriver_win32\chromedriver.exe"")
    ef_driver = EventFiringWebDriver(driver, MyListener())
    ef_driver.get(""http://www.google.co.in/"")
    ef_driver.get(""http://www.facebook.com/"")

    sleep(20)

if __name__ == ""__main__"":
    main()
</code></pre>
",<python><events>
12102879,HttpRequestMessage.Content is lost when it is read in a logging DelegatingHandler in ASP.Net Web API,"<p>When trying to an object in an Action in a Controller it sporadically seems to be null. I discovered that it is due to the <code>ReadAsStringAsync()</code> in the <code>SendAsync()</code> override of the <code>DelegatingHandler</code>. The issue is with the content. When my client sends a content body and it is read in the logger it is never read by the Controller Action Invoker (or may be somewhere in the <code>JsonFormatter</code>). I suspect the subsequent call to <code>Content.ReadAsStringAsync()</code> doesnt throw an exception but also doesnt not return the expected content body (some info is returned stating that the async read is completed).</p>

<p>But my problem remains since I want to read a <code>[FromBody]</code> parameter in an action and it is null when the RaceCondition of <code>Content.ReadStringAsync</code> is won by the <code>DelegatingHandler</code>. When <code>JsonFormatter</code> wins it though, I get the object but that is rare (only at service startup).</p>

<p>Here is my <code>DelegatingHandler</code> code:</p>

<pre><code>public class LogHandler : DelegatingHandler
{

protected override Task&lt;HttpResponseMessage&gt; SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)
    {
        var apiRequest = new WebApiUsageRequest(request);
        WriteLog(apiRequest);
        request.Content.ReadAsStringAsync().ContinueWith(t =&gt;
        {
            apiRequest.Content = t.Result;
            WriteLog(apiRequest);
        });

        return base.SendAsync(request, cancellationToken).ContinueWith(task =&gt;
        {
            var apiResponse = new WebApiUsageResponse(task.Result);
            apiResponse.Content = task.Result.Content != null ? task.Result.Content.ReadAsStringAsync().Result : null;
            WriteLog(apiResponse);
            return task.Result;
        });
    }
}
</code></pre>

<p>Does anyone have a clue to the solution of this issue?</p>
",<c#><web-services><rest><asp.net-web-api>
56150859,Can i do custom logging in spring boot application?,"<p>In my enterprise application, i have several background jobs to fulfill various business requirement.</p>
<p>eg :-  Bill generation job,Activate package job etc.</p>
<p>Here i need to specific custom logging to validate the job status,job input,if fails then reason etc.</p>
<p>How can i achieve above requirement , i don't need other application logs, just need logs related to jobs.</p>
<h1>I need something like this in code.</h1>
<p>For eg.</p>
<p>log.info (&quot;Job inputs&quot;)</p>
<p>log.info(Job success status)</p>
<h1>In log file output should be like:-</h1>
<p>Info : Job inputs</p>
<p>Info : Job success</p>
",<spring-boot><logging>
57519477,API response showing in console.log but not on react page,"<p>I ma trying to show part of an APi response but it keeps giving me undefined when i try to parse it. </p>

<p>I have tried doing 2 parts of the API response but neither work. </p>

<pre><code>class App extends Component {
  constructor() {
    super();
    this.state = {
      head: 0,
      data: [],
      firstName: ""Brad"",
      lastName: ""Marchand"",
      err: null
    };
  }

  componentDidMount() {
    axios
      .get(""http://localhost:3001/api/player"", {
        params: {
          firstName: this.state.firstName,
          lastName: this.state.lastName
        }
      })
      .then(response =&gt; {
        this.setState({
          data: response.data
        });
        console.log(this.state.data);
      })
      .catch(err =&gt; {
        //this.err = err;
      });
  }

  render() {
    return (
      &lt;&gt;
        &lt;p&gt;{this.state.data.players[0].player.firstName}&lt;/p&gt;
        &lt;p&gt;Hello&lt;/p&gt;
      &lt;/&gt;
    );
  }
}
</code></pre>

<p>backend</p>

<pre><code> request(options, (err, response, body) =&gt; {
    if (err) {
      signale.error(err);
    }
    var data = JSON.parse(body);
    //var data = JSON.stringify(data.players);
    //var data = JSON.parse(data);

    signale.success(data);
    res.send(data);
  });
</code></pre>

<pre><code>{ lastUpdatedOn: '2019-08-15T15:20:13.791Z',
[0]   players: [ { player: [Object], teamAsOfDate: [Object] } ],
[0]   references: { teamReferences: [ [Object] ], venueReferences: [ [Object] ] } }
</code></pre>

<p>Another expected response
<a href=""https://i.stack.imgur.com/6zIMR.png"" rel=""nofollow noreferrer"">Another response</a></p>

<p>Trying to just output what i want from  the response but always get undefined past this.state.data</p>
",<javascript><node.js><reactjs>
57451246,How to set up multiple loggers with different settings using logging.config.dictConfig(),"<p>I'm trying to set up three different loggers using dictConfig and for some reason the last logger always seems to overwrite the configuration of the two loggers created before it.  Here is the code I'm using:</p>

<pre><code>import logging
import logging.config

def setup_logger(name, level, ContentFormat='%(asctime)s %(levelname)s %(message)s', DateTimeFormat='%Y-%m-%d %H:%M:%S'):
    logging.config.dictConfig({
        'version': 1,
        'disable_existing_loggers': True,
        'formatters': {
            'default': {'format': ContentFormat, 'datefmt': DateTimeFormat},
        },
        'handlers': {
            'console': {
                'class': 'logging.StreamHandler',
                'level': level,
                'formatter': 'default',
                'stream': 'ext://sys.stdout'
            }
        },
        'loggers': {
            'a': {
                'level': level,
                'handlers': ['console']
            },
            'b': {
                'level': level,
                'handlers': ['console']
            },
            'c': {
                'level': level,
                'handlers': ['console']
            }
        }
    })
    return logging.getLogger(name)

logger_a = setup_logger(name='a', level=logging.INFO, ContentFormat='A: %(message)s')
logger_b = setup_logger(name='b', level=logging.INFO, ContentFormat='B: %(message)s')
logger_c = setup_logger(name='c', level=logging.INFO, ContentFormat='C: %(message)s')

logger_a.info('logger_a')
logger_b.info('logger_b')
logger_b.info('logger_c')
</code></pre>

<p>And this is the output:</p>

<pre><code>C: logger_a
C: logger_b
C: logger_c
</code></pre>

<p>Instead what I'd like to see is:</p>

<pre><code>A: logger_a
B: logger_b
C: logger_c
</code></pre>

<p>Any ideas what I'm doing wrong?  I've even tried making multiple handlers and I still run into the same problem.</p>

<p>I have another version of this function that uses the following code and I'm able to call it multiple times to create multiple separate loggers with different settings, but I really wanted to figure out how to do this with dictConfig instead, or at least understand where I'm going wrong:</p>

<pre><code>logger = logging.getLogger(name)
logger.setLevel(level)

# create console handler for printing logging output to the screen as well
formatter = logging.Formatter(ContentFormat, DateTimeFormat)
handler = logging.StreamHandler()
handler.setLevel(level)
handler.setFormatter(formatter)
logger.addHandler(handler)
return logger
</code></pre>
",<python-3.x><logging>
20693108,VB.net log accessed websites?,"<p>I've been searching around for a protocol or for something I can use possibly at the network layer that can monitor websites that are being accessed and log them.</p>

<p>For example a user loads google.com in a browser of their choice and my software sits in the background and records this.</p>

<p>To clarify I am not looking to monitor for passwords, nor is this of malicious intent, I'm looking at a way to establish a local internet filter, without using the hosts file that is.</p>

<p>Any suggestions or where to look?</p>
",<vb.net><filter>
67785985,How to use monolog ElasticSearchHandler for logging in a Laravel application,"<p>Monolog contains elastic search handler and formatter, but it's implementation to laravel as a custom channel is not as straightforward as described on Laravel documentation web site.</p>
",<php><laravel><elasticsearch><logging><monolog>
51016469,configure a custom variant in HijrahChronology for date correction jdk 8,"<p>I have used DatePicker in javafx - JDK 8 and used HijrahChronology.INSTANCE - so that the date picker shows both the calendar - everything work good enough but I am having a difference of 1 day between gregorian calendar and hijri calendar. Hijri Calendar is 1 day backward.</p>

<p>I am trying to change the variant as per the following link 
<a href=""https://bugs.openjdk.java.net/browse/JDK-8187987"" rel=""nofollow noreferrer"">https://bugs.openjdk.java.net/browse/JDK-8187987</a></p>

<p>but unable to succeed in it. Kindly explain or refer a better or a clear solution to this issue.</p>

<p>Code:</p>

<pre><code>HijrahChronology hijriChronology = HijrahChronology.INSTANCE;
    dateOfTransaction.setChronology(hijriChronology);
</code></pre>

<p>dateOfTransaction is the instance of DatePicker in JavaFx
I have not used Joda Time, neither I wish to, unless that is the only solution.</p>
",<java><javafx><java-8><javafx-8><java-time>
26142232,Is there a way to programmatically change the default logging level of the log crate?,"<p>I'm developing a project in Rust that is meant to be used by systems administrators, via CLI.
In this program, I would like to have lines like these:</p>

<pre><code>warn!(""File {} not found, proceeding to next file"", file_path);
</code></pre>

<p>Which I don't consider errors in the context of the software, but I still would want my users to be aware of.</p>

<p>However, Rust's logging system, by default, only prints messages on the <code>ERROR</code> log level, and the only way I found to change this default is to set the <code>RUST_LOG</code> environment variable - which I don't want my users to have to do. I guess I could create a wrapper script that just sets the variable and <code>exec</code>s the program, but I would rather not.</p>

<p>Is there a way to change the default level programmatically, from inside the program?</p>
",<logging><environment-variables><rust>
22295431,This API is not allowed for users who have logged in to the app anonymously,"<p>When i was trying to connect to Facebook with my app, I received this error today, is there any change in Facebook API?, this scenario has worked since today.
error text:
(#200) This API is not allowed for users who have logged in to the app anonymously.</p>
",<facebook><facebook-php-sdk>
58398863,Liquibase cannot find changelog file,"<p>I have following error with our spring boot 2 application:</p>

<blockquote>
  <p>Caused by: liquibase.exception.ChangeLogParseException: Error Reading Migration File: class path resource [src/main/resources/changelogs/changelog-1.0.xml] cannot be resolved to URL because it does not exist
      at liquibase.parser.core.xml.XMLChangeLogSAXParser.parseToNode(XMLChangeLogSAXParser.java:118)
      at liquibase.parser.core.xml.AbstractChangeLogParser.parse(AbstractChangeLogParser.java:15)
      at liquibase.changelog.DatabaseChangeLog.include(DatabaseChangeLog.java:525)
      at liquibase.changelog.DatabaseChangeLog.handleChildNode(DatabaseChangeLog.java:334)
      ... 190 common frames omitted</p>
</blockquote>

<p>in application properties we have: <code>spring.liquibase.change-log=classpath:/changelogs/changelog-master.xml</code></p>

<p>All scripts are structured in spring boot's resource folder <code>/src/main/resources/changelogs</code></p>

<p>In <code>changelogs</code> fodler is master xml and changelog with changesets as well. </p>

<p>reference to changelog of changesets in master xml is like this:</p>

<p><code>&lt;include file=""src/main/resources/changelogs/changelog-1-0.xml""/&gt;</code></p>

<p>I cannot find reason why this isn't work.</p>

<p>I tried <code>relativeToChangelogFile=""true""</code> and in file use only <code>file=""changelog-1-0.xml""</code> and this works, why ?</p>
",<java><spring><spring-boot><liquibase>
5137535,"In a function call, the number of Entrance logs are much lesser than the number of logs at the exit. Why is that?","<p>The piece of function is like this:</p>

<pre><code>JNIEXPORT jint JNICALL functionCall() {
     // Entrance
     printf(""Time: %d\tFile: %s\tFunc: %s\tLine: %d\n"", clock(), __FILE__, __FUNCTION__, __LINE);

    // other codes
    ...

    // Exit
    printf(""Time: %d\tFile: %s\tFunc: %s\tLine: %d\n"", clock(), __FILE__, __FUNCTION__, __LINE);
}
</code></pre>

<p>The total project is compiled to xxx.so file, called by java code at some Android app.
Now I am debugging the app, it will crash in the end. According to the logs, I find that the log number print at the entrance is only 14, but the log number print at the exit is more than 200.
How can this come out?</p>
",<java><c++><android><c><java-native-interface>
13549958,SWI Prolog use :-lib(ic),"<p>I am new to prolog and i am trying an example from web, but there is an error about the lib</p>

<pre><code>:-lib(ic).

:-use_module(library(ic)).
</code></pre>

<p>The error is</p>

<p><i>Goal (directive) failed: user:lib(ic) </i></p>

<p><i>source_sink `library(ic)' does not exist</i></p>

<p>how to use this in prolog?
I am using SWI Prolog IDE.</p>
",<swi-prolog>
28603159,python intercept logging to email or sms,"<p>I'm wondering whether it's possible to intercept a logging call to send an email or sms based on the level.</p>

<p>Bearing in mind that under email and sms, there is also <code>logging.error</code> which could cause a loop</p>

<pre><code>import logging, smtplib, urllib2

LOGGER = 'log.out'
FORMAT = '%(asctime)s %(levelname)s %(message)s'
LEVEL = logging.INFO

logging.basicConfig(filename=LOGGER, format=FORMAT, maxBytes=2048, level=LEVEL)

def email(_msg):
    try:
        email_mesg = ""Subject:{0}\n\n{1}"".format(email_subj, _msg)
        s = smtplib.SMTP(email_host)
        s.sendmail(email_from, email_recv, email_mesg)
        s.quit()
    except smtplib.SMTPException as e:
        logging.error(e)

def sms(_msg):
    try:
        sms_mesg = urllib2.quote(_msg)
        url = ""https://smsapi/?username={0}&amp;password={1}&amp;message={2}&amp;orig={3}&amp;number={4}"".format(sms_user, sms_pass, sms_mesg, sms_orig, sms_numb)
        req = urllib2.Request(url)
        res = urllib2.urlopen(req)
    except urllib2.URLError as e:
        logging.error(e)

if __name__ == ""__main__"":
    """"""
    The following line should log and trigger email
    """"""
    logging.warning(""Something you should know about"")

    """"""
    The following line should log and trigger sms
    """"""
    logging.error(""Something you should know about"")
</code></pre>
",<python><logging>
11128209,Common datetime formats in log files,"<p>I'm looking for a list of common datetime formats used in logs (e.g. webserver, database, etc).</p>

<p>Even better would be a (java) library that can extract date and time from a given string ( &lt; 10KB).</p>

<p>Does anyone know a good one?</p>
",<java><datetime><date><extract>
58538583,Update LogLevel from code without using log4j-core,"<p>I want to update log level programmatically without using log4j-core. Can it be done using log4j-api.</p>
",<java><log4j2>
59028053,Need to ship logs to elastic from EKS,"<p>We have an EKS cluster running and we are looking for best practices to ship application logs from pods to Elastic.
In the EKS workshop there is an option to ship the logs to cloudwatch and then to Elastic.</p>

<p>Wondered if there is an option to ship the logs directly to Elastic, or to understand best practices.</p>

<p>Additional requirement: 
We need the logs to determine from which namespace the logs is coming from and to deliver a dedicated index</p>
",<elasticsearch><kubernetes><fluentd><amazon-eks>
22264893,Storm topology failure while running on production,"<p>Hi I'm having a issue with running storm cluster. It is similar to </p>

<p>My Topology is defined as :</p>

<pre><code>            package com.abc.newsclassification;

            import StormBase.KnowledgeGraph.ClassifierBolt;
            import StormBase.KnowledgeGraph.ClientSpecificTwitterSpout;
            import StormBase.KnowledgeGraph.LiveTwitterSpout;
            import StormBase.KnowledgeGraph.NewsTwitterSpout;
            import StormBase.KnowledgeGraph.TwitterTrainingBolt;
            import StormBase.KnowledgeGraph.UrlExtractorBolt;
            import backtype.storm.Config;
            import backtype.storm.LocalCluster;
            import backtype.storm.StormSubmitter;
            import backtype.storm.generated.AlreadyAliveException;
            import backtype.storm.generated.InvalidTopologyException;
            import backtype.storm.topology.TopologyBuilder;
            import backtype.storm.tuple.Fields;

            public class ClassifierTopology {

                public static void main(String[] args) throws Exception {
                    TopologyBuilder builder = new TopologyBuilder();

        // add a spout
                    builder.setSpout(""spout"", new NewsTwitterSpout(), 1);
                // configure 
                    Config conf = new Config();
                    conf.setDebug(false);

                    // submit it to the cluster, or submit it locally
                        conf.setMaxTaskParallelism(10);
                        LocalCluster cluster = new LocalCluster();
                                    System.out.println(conf.entrySet());
                        cluster.submitTopology(""testTopology"", conf,
                                builder.createTopology());

                }
            }

     ------------------------------------------------------------------------------------------------------
   ** END OF FILE **
     ------------------------------------------------------------------------------------------------------
</code></pre>

<p>pom.xml:</p>

<pre><code>            &lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
                xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;
                &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

                &lt;groupId&gt;StormBase&lt;/groupId&gt;
                &lt;artifactId&gt;KnowledgeGraph&lt;/artifactId&gt;
                &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
                &lt;packaging&gt;jar&lt;/packaging&gt;

                &lt;name&gt;KnowledgeGraph&lt;/name&gt;
                &lt;url&gt;http://maven.apache.org&lt;/url&gt;

                &lt;properties&gt;
                    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
                &lt;/properties&gt;

                &lt;repositories&gt;
                    &lt;repository&gt;
                        &lt;id&gt;clojars.org&lt;/id&gt;
                        &lt;url&gt;http://clojars.org/repo&lt;/url&gt;
                    &lt;/repository&gt;
                &lt;/repositories&gt;
                &lt;build&gt;
                    &lt;plugins&gt;
                        &lt;plugin&gt;
                            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                            &lt;configuration&gt;
                                &lt;source&gt;1.6&lt;/source&gt;
                                &lt;target&gt;1.6&lt;/target&gt;
                            &lt;/configuration&gt;
                        &lt;/plugin&gt;
                        &lt;plugin&gt;
                            &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                            &lt;configuration&gt;
                                &lt;archive&gt;
                                    &lt;manifest&gt;
                                        &lt;mainClass&gt;com.abc.newsclassification.ClassifierTopology&lt;/mainClass&gt;
                                    &lt;/manifest&gt;
                                &lt;/archive&gt;
                                &lt;descriptorRefs&gt;
                                    &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                                &lt;/descriptorRefs&gt;
                            &lt;/configuration&gt;
                            &lt;executions&gt;
                                &lt;execution&gt;
                                    &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt;
                                    &lt;phase&gt;package&lt;/phase&gt; &lt;!-- bind to the packaging phase --&gt;
                                    &lt;goals&gt;
                                        &lt;goal&gt;single&lt;/goal&gt;
                                    &lt;/goals&gt;
                                &lt;/execution&gt;
                            &lt;/executions&gt;
                        &lt;/plugin&gt;
                    &lt;/plugins&gt;
                &lt;/build&gt;

                &lt;dependencies&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;junit&lt;/groupId&gt;
                        &lt;artifactId&gt;junit&lt;/artifactId&gt;
                        &lt;version&gt;3.8.1&lt;/version&gt;
                        &lt;scope&gt;test&lt;/scope&gt;
                    &lt;/dependency&gt;


                    &lt;dependency&gt;
                        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
                        &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt;
                        &lt;version&gt;1.6.1&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
                        &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt;
                        &lt;version&gt;1.6.0&lt;/version&gt;
                        &lt;exclusions&gt;
                            &lt;exclusion&gt;
                                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
                                &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
                            &lt;/exclusion&gt;
                        &lt;/exclusions&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;storm&lt;/groupId&gt;
                        &lt;artifactId&gt;storm&lt;/artifactId&gt;
                        &lt;version&gt;0.8.2&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;
                        &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;
                        &lt;version&gt;3.3.3&lt;/version&gt;
                        &lt;exclusions&gt;
                            &lt;exclusion&gt;
                                &lt;groupId&gt;com.sun.jmx&lt;/groupId&gt;
                                &lt;artifactId&gt;jmxri&lt;/artifactId&gt;
                            &lt;/exclusion&gt;

                            &lt;exclusion&gt;
                                &lt;groupId&gt;com.sun.jdmk&lt;/groupId&gt;
                                &lt;artifactId&gt;jmxtools&lt;/artifactId&gt;
                            &lt;/exclusion&gt;

                            &lt;exclusion&gt;
                                &lt;groupId&gt;javax.jms&lt;/groupId&gt;
                                &lt;artifactId&gt;jms&lt;/artifactId&gt;
                            &lt;/exclusion&gt;

                        &lt;/exclusions&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;com.yammer.metrics&lt;/groupId&gt;
                        &lt;artifactId&gt;metrics-core&lt;/artifactId&gt;
                        &lt;version&gt;2.2.0&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;com.101tec&lt;/groupId&gt;
                        &lt;artifactId&gt;zkclient&lt;/artifactId&gt;
                        &lt;version&gt;0.3&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;net.sf.jopt-simple&lt;/groupId&gt;
                        &lt;artifactId&gt;jopt-simple&lt;/artifactId&gt;
                        &lt;version&gt;4.5&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt;
                        &lt;artifactId&gt;jackson-core-asl&lt;/artifactId&gt;
                        &lt;version&gt;1.9.2&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt;
                        &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt;
                        &lt;version&gt;1.9.2&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;com.netflix.curator&lt;/groupId&gt;
                        &lt;artifactId&gt;curator-test&lt;/artifactId&gt;
                        &lt;version&gt;1.2.5&lt;/version&gt;

                        &lt;exclusions&gt;
                            &lt;exclusion&gt;
                                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
                                &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
                            &lt;/exclusion&gt;
                            &lt;exclusion&gt;
                                &lt;groupId&gt;log4j&lt;/groupId&gt;
                                &lt;artifactId&gt;log4j&lt;/artifactId&gt;
                            &lt;/exclusion&gt;
                        &lt;/exclusions&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;org.twitter4j&lt;/groupId&gt;
                        &lt;artifactId&gt;twitter4j-stream&lt;/artifactId&gt;
                        &lt;version&gt;3.0.5&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;redis.clients&lt;/groupId&gt;
                        &lt;artifactId&gt;jedis&lt;/artifactId&gt;
                        &lt;version&gt;2.2.1&lt;/version&gt;
                        &lt;type&gt;jar&lt;/type&gt;
                        &lt;scope&gt;compile&lt;/scope&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.languagetool&lt;/groupId&gt;
                        &lt;artifactId&gt;language-en&lt;/artifactId&gt;
                        &lt;version&gt;2.3.1&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.twitter4j&lt;/groupId&gt;
                        &lt;artifactId&gt;twitter4j-core&lt;/artifactId&gt;
                        &lt;version&gt;3.0.5&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
                        &lt;artifactId&gt;lucene-core&lt;/artifactId&gt;
                        &lt;version&gt;4.6.0&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
                        &lt;artifactId&gt;lucene-analyzers&lt;/artifactId&gt;
                        &lt;version&gt;3.6.2&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
                        &lt;artifactId&gt;lucene-snowball&lt;/artifactId&gt;
                        &lt;version&gt;3.0.3&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
                        &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt;
                        &lt;version&gt;4.6.0&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;com.gravity&lt;/groupId&gt;
                        &lt;artifactId&gt;goose&lt;/artifactId&gt;
                        &lt;version&gt;2.1.23&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;nz.ac.waikato.cms.weka&lt;/groupId&gt;
                        &lt;artifactId&gt;weka-dev&lt;/artifactId&gt;
                        &lt;version&gt;3.7.9&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.directory.studio&lt;/groupId&gt;
                        &lt;artifactId&gt;org.apache.commons.io&lt;/artifactId&gt;
                        &lt;version&gt;2.4&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
                        &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;
                        &lt;version&gt;3.1&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;mysql&lt;/groupId&gt;
                        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                        &lt;version&gt;5.0.8&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.javatuples&lt;/groupId&gt;
                        &lt;artifactId&gt;javatuples&lt;/artifactId&gt;
                        &lt;version&gt;1.2&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.opennlp&lt;/groupId&gt;
                        &lt;artifactId&gt;opennlp-tools&lt;/artifactId&gt;
                        &lt;version&gt;1.5.3&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
                        &lt;artifactId&gt;commons-io&lt;/artifactId&gt;
                        &lt;version&gt;1.3.2&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.apache.directory.studio&lt;/groupId&gt;
                        &lt;artifactId&gt;org.apache.commons.lang&lt;/artifactId&gt;
                        &lt;version&gt;2.6&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt;
                        &lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt;
                        &lt;version&gt;3.3.0&lt;/version&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt;
                        &lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt;
                        &lt;version&gt;3.3.0&lt;/version&gt;
                        &lt;classifier&gt;models&lt;/classifier&gt;
                    &lt;/dependency&gt;
                    &lt;dependency&gt;
                        &lt;groupId&gt;edu.washington.cs.knowitall.stanford-corenlp&lt;/groupId&gt;
                        &lt;artifactId&gt;stanford-postag-models&lt;/artifactId&gt;
                        &lt;version&gt;1.3.5&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;com.google.code.google-collections&lt;/groupId&gt;
                        &lt;artifactId&gt;google-collect&lt;/artifactId&gt;
                        &lt;version&gt;snapshot-20071022&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;com.googlecode.concurrent-trees&lt;/groupId&gt;
                        &lt;artifactId&gt;concurrent-trees&lt;/artifactId&gt;
                        &lt;version&gt;1.0.0&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;log4j&lt;/groupId&gt;
                        &lt;artifactId&gt;log4j&lt;/artifactId&gt;
                        &lt;version&gt;1.2.16&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;
                        &lt;artifactId&gt;cassandra-driver-core&lt;/artifactId&gt;
                        &lt;version&gt;1.0.3&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;org.hectorclient&lt;/groupId&gt;
                        &lt;artifactId&gt;hector-core&lt;/artifactId&gt;
                        &lt;version&gt;1.1-0&lt;/version&gt;
                        &lt;exclusions&gt;
                            &lt;exclusion&gt;
                                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
                                &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
                            &lt;/exclusion&gt;
                        &lt;/exclusions&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;me.prettyprint&lt;/groupId&gt;
                        &lt;artifactId&gt;hector-test&lt;/artifactId&gt;
                        &lt;version&gt;1.0-5&lt;/version&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;FBKeyWords&lt;/groupId&gt;
                        &lt;artifactId&gt;FBKeyWords&lt;/artifactId&gt;
                        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
                        &lt;classifier&gt;jar-with-dependencies&lt;/classifier&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;KeyWordExtractor&lt;/groupId&gt;
                        &lt;artifactId&gt;KeyWordExtractor&lt;/artifactId&gt;
                        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
                        &lt;classifier&gt;jar-with-dependencies&lt;/classifier&gt;
                    &lt;/dependency&gt;

                    &lt;dependency&gt;
                        &lt;groupId&gt;mysql&lt;/groupId&gt;
                        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                        &lt;version&gt;5.1.6&lt;/version&gt;
                    &lt;/dependency&gt;

                &lt;/dependencies&gt;
            &lt;/project&gt;



            ---------------------------------------------------------------

            ** END OF pom.xml **
            ---------------------------------------------------------------
</code></pre>

<p>The following is the error I'm getting:</p>

<pre><code>-----------------------------------------------------------------------------------------
 [topology.workers=3, topology.debug=false]
                Exception in thread ""main"" java.lang.RuntimeException: org.apache.thrift7.transport.TTransportException: java.net.ConnectException: Connection refused
                    at backtype.storm.utils.NimbusClient.getConfiguredClient(NimbusClient.java:21)
                    at backtype.storm.StormSubmitter.submitTopology(StormSubmitter.java:70)
                    at backtype.storm.StormSubmitter.submitTopology(StormSubmitter.java:41)
                    at com.tookitaki.newsclassification.ClassifierTopology.main(ClassifierTopology.java:92)
                Caused by: org.apache.thrift7.transport.TTransportException: java.net.ConnectException: Connection refused
                    at org.apache.thrift7.transport.TSocket.open(TSocket.java:183)
                    at org.apache.thrift7.transport.TFramedTransport.open(TFramedTransport.java:81)
                    at backtype.storm.security.auth.SimpleTransportPlugin.connect(SimpleTransportPlugin.java:66)
                    at backtype.storm.security.auth.ThriftClient.&lt;init&gt;(ThriftClient.java:46)
                    at backtype.storm.utils.NimbusClient.&lt;init&gt;(NimbusClient.java:30)
                    at backtype.storm.utils.NimbusClient.&lt;init&gt;(NimbusClient.java:26)
                    at backtype.storm.utils.NimbusClient.getConfiguredClient(NimbusClient.java:19)
                    ... 3 more
                Caused by: java.net.ConnectException: Connection refused
                    at java.net.PlainSocketImpl.socketConnect(Native Method)
                    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
                    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
                    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
                    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
                    at java.net.Socket.connect(Socket.java:579)
                    at org.apache.thrift7.transport.TSocket.open(TSocket.java:178)
                    ... 9 more    
</code></pre>

<p>Please let me know which version of storm/other packages should I use, or if there are any other problem causing this Error. Any sugesstion is welcome.</p>
",<java><runtime-error><thrift><apache-storm>
71345413,Django logging errors into seperate files by timestamp,"<p>I have set up a Django log successfully with the following code:</p>
<pre><code>LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'file': {
            'level': 'ERROR',
            'class': 'logging.FileHandler',
            'filename': 'debug.log',
        },
    },
    'loggers': {
        'django': {
            'handlers': ['file'],
            'level': 'ERROR',
            'propagate': True,
        },
    },
}
</code></pre>
<p>And from this, I'm able to find errors logged in the <em>'debug.log'</em> file that's define above.</p>
<p>However what I'd like to achieve is that any Django error is sent to an individual and timestamped log file. For example, if a ValueError is encountered, it would save it to a file named something like: <em>debug_2022-03-04_1143.log</em></p>
<p>I searched some other answers on this, but most seemed to be talking about timestamping at logged intervals, and I couldn't find a solution to the objective I listed above. Any help is appreciated.</p>
",<python><django><logging>
77037347,Missing random Log4J2 entries in log file,"<p>I've noticed strange behavior in how Log4j logs messages and exceptions. SOme highlights of my application: SAP Hybris 6.0.0 (aka SAP Commerce), openJDK 8, Apache Tomcat, Log4j2 2.4.1 (slf4j as facade), CentOS 7.</p>
<p>I utilize Log4j logger in a common way:</p>
<pre><code>Logger LOGGER = LoggerFactory.getLogger(SomeClass.class);
try
{
   //some code throwing exception
} catch (Exception e) {
   LOGGER.error(&quot;Some exception occured.&quot;);
}
</code></pre>
<p>The log4j2 xml config is as following:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!--
  ~ [y] hybris Platform
  ~ 
  ~ Copyright (c) 2000-2016 SAP SE
  ~ All rights reserved.
  ~ 
  ~ This software is the confidential and proprietary information of SAP 
  ~ Hybris (&quot;Confidential Information&quot;). You shall not disclose such 
  ~ Confidential Information and shall use it only in accordance with the 
  ~ terms of the license agreement you entered into with SAP Hybris.
  --&gt;

&lt;!-- Platform-only xml configuration for Log4j2. Not used by default, can be treated as an example --&gt;
&lt;!-- To enable set in local.properties: log4j2.config.xml=hybris-log4j2.xml --&gt;
&lt;!-- Keep in mind that xml configurations cannot be merged together unlike ones set via hybris properties. --&gt;
&lt;!-- shutdownHook is disabled because we invoke it programatically after shutting down hybris registry --&gt;
&lt;Configuration status=&quot;WARN&quot; shutdownHook=&quot;disable&quot; packages=&quot;de.hybris.platform.util.logging&quot;&gt;
    &lt;Appenders&gt;
        &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;
            &lt;ThresholdFilter level=&quot;DEBUG&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt;
            &lt;PatternLayout pattern=&quot;%highlight{%-5p [%t] %X{RemoteAddr}%X{Tenant}%X{CronJob}[%c{1}] %m%n}&quot;/&gt;
        &lt;/Console&gt;
    &lt;/Appenders&gt;
    &lt;Loggers&gt;
        &lt;Logger name=&quot;de.hybris.platform.servicelayer.hmc&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;

        &lt;Logger name=&quot;de.hybris.platform.spring.ctx.TenantIgnoreXmlWebApplicationContext&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;
        &lt;Logger name=&quot;de.hybris.platform.spring.ctx.CloseAwareApplicationContext&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;

        &lt;Logger name=&quot;org.apache.ddlutils.alteration.ModelComparator&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;
        &lt;Logger name=&quot;hsqldb.db&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;
        &lt;Logger name=&quot;de.hybris.platform.spring.IgnoreTenantScopeMetadataResolver&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;
        &lt;Logger name=&quot;de.hybris.platform.spring.ctx.ScopeTenantIgnoreDocReader&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;

        &lt;Logger name=&quot;de.hybris.platform.util.logging.LoggingFrameworksBridgeTest&quot; level=&quot;ALL&quot; additivity=&quot;false&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;

        &lt;Logger name=&quot;de.hybris.cronjobtutorial.MyJobPerformable&quot; level=&quot;ALL&quot; additivity=&quot;false&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;

        &lt;Logger name=&quot;org.springframework.aop.framework.Cglib2AopProxy&quot; level=&quot;error&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;
        &lt;Logger name=&quot;org.springframework&quot; level=&quot;warn&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Logger&gt;
        &lt;Root level=&quot;info&quot;&gt;
            &lt;AppenderRef ref=&quot;Console&quot;/&gt;
        &lt;/Root&gt;
    &lt;/Loggers&gt;
&lt;/Configuration&gt;
</code></pre>
<p>But what I see in logs is quite unsual (see screenshot of some log entry).</p>
<p><a href=""https://i.stack.imgur.com/MaPy3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MaPy3.png"" alt=""enter image description here"" /></a>
This is how error message should look like
<a href=""https://i.stack.imgur.com/ETvgm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ETvgm.png"" alt=""enter image description here"" /></a>
Looks like log event is fired, but no log message is being written (only ansi colors symbols because of enabled highlighting in log4j config). It's worth to mention that only few loggers work in this way, the majority amount of loggers work as expected.
The following construction logs only stackstrace (custom message is ommited)</p>
<pre><code>Logger LOGGER = LoggerFactory.getLogger(SomeClass.class);
try
{
   //some code throwing exception
} catch (Exception exception) {
   LOGGER.error(&quot;Some exception occured.&quot;, exception);
}
</code></pre>
<p>And even more these lines of code in some classes lead to the same result:</p>
<pre><code>Logger LOGGER = LoggerFactory.getLogger(SomeClass.class);
try
{
   //some code throwing exception
} catch (Exception exception) {
   System.out.println(&quot;Some exception occured.&quot;);
}
</code></pre>
<p>As I understand, this is not about log levels either wrong log4j configuration. I tried to omit highlighting in log4j formatter, but the result is the same - log entry is empty (and coloring symbols are gone as expected). But the stacktrace is printed. I didn't noticed, that this is environment-specific propblem, because all our environments are the same (os, configuration, etc). I suspect that something wrong with log buffers or/and communication between log4j and underlying subsystems.</p>
<p><strong>UPD</strong></p>
<p>This is how HAC Logging panel looks like</p>
<p><a href=""https://i.stack.imgur.com/X9vtM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/X9vtM.png"" alt=""enter image description here"" /></a></p>
<p><strong>UPD 2</strong></p>
<p>The issue seems to be hidden somewhere in tomcat logging. I've tried to update log4j configuration to utilize RollingFile type instead of SYSTEM_OUT and everything went fine, all log entries are printed correctly in rolling file. I will proceed investigation of the issue in terms of tomcat logging.</p>
",<log4j><log4j2><slf4j><sap-commerce-cloud>
47710367,Node JS - Discord js - Chat logging with winston to quick-db,"<p>So, I want to add a chat logging system with sql with quick-db, currently I have this as a temporary fix, but its just to ugly how it logs.</p>

<pre><code>yumi.on('ready', () =&gt; {
 winston.add(winston.transports.File, { filename: 'yumi.log', level: 'info' });
});

yumi.on('message', msg =&gt; {
  winston.log('info', msg.guild + ' - ' + msg.channel.name + ' - ' + ""@ "" + msg.author.username + '#' + msg.author.disscriminator + msg.author + ' | ' + msg.content)
});
</code></pre>

<p>How would I go about storing username with client id into sqlite or by using this fancy tool called <a href=""https://www.npmjs.com/package/quick.db"" rel=""nofollow noreferrer"">quick.db</a></p>

<p>any idea or how to start by doing this?</p>
",<javascript><node.js><sqlite><quick.db>
39151132,"Serilog ""Maximum destructuring depth reached""","<p>I've enabled SeriLog (latest version) Self-Logging and am seeing hundreds of messages that say</p>

<blockquote>
  <p>Maximum destructuring depth reached</p>
</blockquote>

<p>No idea what that means and whether it's a problem I need to worry about or not. </p>

<p>Does anyone know what triggers this message and whether I'm doing something wrong?</p>
",<serilog>
68446419,Use RegEx in Python to extract URL and optional query string from web server log data,"<p>Disclosure: very much a regex newbie, so I'm trying to tweak some example code I found which parses web server log data into named groups.  The snippet of my modified regex thus far that deals with the URL and query string groups:</p>
<pre><code>(?P&lt;url&gt;.+)(?P&lt;querystr&gt;\?.*)
</code></pre>
<p>This works just fine when the string against which it's applied actually does have a query string on the URL (each group gets the expected bit of the string) but fails to match if there is none.  So I tried adding a '?' after the &quot;querystr&quot; group to indicate that it was optional, i.e. <code>(?P&lt;querystr&gt;\?.*)?</code> ... if there's no query string then it works as expected (nothing is extracted into querystr), but when there is one, it is still extracted as part of url rather than separately into querystr.</p>
<p>What's the best way to identify optional groups (assuming that's even the right approach in this case)?  Thanks in advance.</p>
",<python-3.x><regex>
59171638,how can I use console.log for number division,"<p>I try multiple times, but it keeps saying error. Please help</p>

<p>Prompt the user for a number.
Use console.log to display either</p>

<p>This number is divisible by 3 </p>

<p>or </p>

<p>This number isn't divisible by 3 </p>

<p>whichever is correct. </p>
",<javascript>
73338764,Print file path from repository root - Rust logger,"<p>I am trying to figure out how to print file path from repository root.</p>
<p><a href=""https://docs.rs/env_logger/latest/env_logger/"" rel=""nofollow noreferrer"">https://docs.rs/env_logger/latest/env_logger/</a> - example here only talks about <code>record.file()</code> which prints absolute file path.</p>
<p>Is there a native way to print it from repository root (and not from the modules' Cargo.toml path).</p>
<p>My project is organized like:</p>
<pre><code>root
|- module_A
           |- Cargo.toml
           |- src/&lt;rest of code&gt; 
|- module_B
           |- Cargo.toml
           |- src/&lt;rest of code&gt; 
</code></pre>
<p>So, while logging, I'd to print the path as: <code>root/module_A/src/&lt;file_path&gt;</code></p>
",<logging><rust>
19854393,what is mysql binlog dump in show processlist,"<p>When I did <code>show processlist</code> in mysql I got list of process. One of the process with <strong>binlog dump</strong> running from quit long time.<br>
What is <strong>binlog dump</strong>? do I need to kill this. what happen if i kill this process?</p>
",<mysql><processlist>
3878138,Does Transact-SQL have a similar function to MS Logparser Quantize?,"<p>If you are familiar with Microsoft Log Parser you probably recognize the Quantize function which will truncate a value to the nearest multiple of another value. It is quite handy for grouping date-time fields into increments.</p>

<pre><code>Date-Time              Count
1/1/2010 00:00         100
1/1/2010 00:15         134
1/1/2010 00:30         56
....
</code></pre>

<p>I'm trying to find a similar function in Transaction-SQL (specifically SQL Server 2005 or 2008) that will allow me to do a similar grouping on date-time.</p>
",<sql><sql-server><logparser>
31829696,Is it possible to select the logged in email account in MFMailcomposeViewController swift?,"<p>My question may be a mere foolishness. MFmailComposeViewController automatically selects the logged in email account in the device as the sender e-mail.  I just want to know whether it is possible to select the email account (if there are multiple accounts logged in (yahoo, google, iCloud etc.))? I am using a simple mailComposer, and there is no complex codes. 
Thanks in Advance</p>
",<swift><email><mfmailcomposer>
67440672,Filebeat: How to export logs of specific pods,"<p>This is my filebeat config map.</p>
<pre><code>apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
  namespace: kube-system
  labels:
    k8s-app: filebeat
data:
  filebeat.yml: |-
    filebeat.inputs:
    - type: container
      paths:
        - /var/log/containers/*.log
      processors:
        - add_kubernetes_metadata:
            host: $${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: &quot;/var/log/containers/&quot;

    setup.ilm.enabled: false
    processors:
      - add_cloud_metadata:
      - add_host_metadata:

    output.elasticsearch:
      hosts: ['${ELASTICSEARCH_HOST:elasticsearch}:${ELASTICSEARCH_PORT:9200}']
      username: ${ELASTICSEARCH_USERNAME}
      password: ${ELASTICSEARCH_PASSWORD}
</code></pre>
<p>This sends logs from every pod to AWS ElasticSearch. How I can restrict it to send logs from specific pods by name and/or by the label?</p>
",<elasticsearch><kibana><filebeat>
58991422,How to configure AWS cloudWatchAgent to collect logs recursively from a folder on an EC2 instance?,"<p>I have a <code>logs</code> directory on a EC2 instance and cloud watch agent running over there. In the CloudWatch agent configuration file I have given log file details as below</p>

<pre><code>""logs"": {
    ""logs_collected"": {
      ""files"": {
        ""collect_list"": [
          {
            ""file_path"": ""/home/ec2-user/logs/**/*"",
            ""log_group_name"": ""test0"",
            ""log_stream_name"": ""{instance_id}""
          }
        ]
      }
    }
  }
</code></pre>

<p>but this is not collecting logs recursively. I want cloud agent to send all the logs present under one directory(having nested directories as well) to cloud watch logs.
How is that possible?</p>
",<amazon-web-services><amazon-cloudwatch><amazon-cloudwatchlogs><aws-cloudwatch-log-insights>
43552424,Where does Atom (or it's installed packages) store debug log files?,"<p>I just opened <a href=""https://github.com/ditinc/linter-cflint/issues/24"" rel=""noreferrer"">this bug report</a> on github.  Obviously it would be nice to add some detail from the log file.</p>

<p>Where does Atom store them?  Is this error referring to perhaps a log file generated by the package itself?  If so, is there a conventional directory location for package log files, or would a package write to a main/shared Atom log file?</p>
",<debugging><atom-editor><logfile>
58941377,Is it possible to clear an Android application RAM content when the user logs off/closes the app?,"<p>As an example, take an Android app that manages sensitive information such as credit card details. Is it possible from a code level to effectively erase the sensitive data the app might store in RAM when the user logs off or closes the application? How can this be done?</p>
",<android>
181537,Exporting SharePoint usage log files into a database using LogParser,"<p>So basically we have lots of SharePoint usage log files generated by our SharePoint 2007 site and we would like to make sense of them. For that we're thinking of reading the log files and dumping into a database with the appropriate columns and all. Now I was going to make an SSIS package to read all the text files and extract the data when I came across LogParser. Is there a way to use LogParser to dump data into an Sql Server database or the SSIS way is better? Or is there any other better way to use the SharePoint usage logs?</p>
",<sql-server><sharepoint><moss><logparser>
12958324,syslog-ng install finished without the needed files,"<p>I downloaded syslog-ng OSE from the site (version 3.4.0alpha3)
successfully run</p>

<pre><code>./configure
make
make install
</code></pre>

<p>but I've got no /etc/syslog-ng.conf
nor /etc/init.d/syslog-ng</p>

<p>What might be the  reason?</p>

<p>env is centos 6.3</p>
",<syslog><syslog-ng>
39321843,Log words that start with a letter query with js,"<p>Trying to log all the words that start with a ""b"".
I am receiving the following error:
Uncaught TypeError: query[i].charAt is not a function.
Not sure what I'm doing wrong.</p>

<pre><code>    var query= [34,""beer"",""bbq"",""bees"",""aa"",""cc"", ""bb""];


   for(var i=0;i&lt;=query.length;i++){
       if(query[i].charAt(0)==""b""){
           console.log(query[i]);
       }
   }
</code></pre>
",<javascript>
71492272,php SQLSTATE[3D000]: Invalid catalog name: 1046 No database selected,"<p>I have the following error when I go to view.php: {&quot;success&quot;:0,&quot;message&quot;:&quot;SQLSTATE[3D000]: Invalid catalog name: 1046 No database selected&quot;}, can someone help to solve this issue?</p>
<p>My code is this:</p>
<p>db_connect.php</p>
<pre><code>&lt;?php
class Operations{
    private $db_host = &quot;localhost&quot;;
    private $db_name = &quot;supplierInquiry&quot;;

        public function dbConnection()
        {
            try {
                $conn = new PDO('mysql:host=' . $this-&gt;db_host . ';dbName=' . $this-&gt;db_name);
                    $conn-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
                return $conn;
            } catch (PDOException $e) {
                echo &quot;Connection error &quot; . $e-&gt;getMessage();
                exit;
            }
        }
}
?&gt;
</code></pre>
<p>in the view.php the code is:</p>
<pre><code>&lt;?php
error_reporting(E_ERROR);
header(&quot;Access-Control-Allow-Origin: *&quot;);
header(&quot;Access-Control-Allow-Headers: access&quot;);
header(&quot;Access-Control-Allow-Methods: GET&quot;);
header(&quot;Content-Type: application/json; charset=UTF-8&quot;);

if ($_SERVER['REQUEST_METHOD'] !== 'GET') :
    http_response_code(405);
    echo json_encode([
        'success'=&gt;0,
        'message'=&gt;'Bad Request Detected! Only get method is allowed',
    ]);
    exit;
endif;

require 'db_connect.php';
$database = new Operations();
$conn = $database-&gt;dbConnection();

if (isset($_GET['id'])) {
    $suppliers_id = filter_var($_GET['id'], FILTER_VALIDATE_INT, [
        'options' =&gt; [
            'default' =&gt; 'all_suppliers',
            'min_range' =&gt; 1
        ]
    ]);
}

try {
    $sql = is_numeric($suppliers_id) ? &quot;SELECT * FROM `supplier` WHERE id='$suppliers_id'&quot; : &quot;SELECT * FROM `supplier`&quot;;
    $stmt = $conn-&gt;prepare($sql);

    $stmt-&gt;execute();

    if ($stmt-&gt;rowCount() &gt; 0) : 

        $data = null;

        if (is_numeric($suppliers_id)) {
            $data = $stmt-&gt;fetch(PDO::FETCH_ASSOC);
        } else { 
            $data = $stmt-&gt;fetchAll(PDO::FETCH_ASSOC);
        }

        echo json_encode([
            'success' =&gt; 1,
            'data' =&gt; $data,
        ]);

        else : 
        echo json_encode([
            'success' =&gt; 0,
            'message' =&gt; 'No Record Found!',
        ]);
    endif;
    }
// The error is from this catch 
catch (PDOException $e) {
    http_response_code(500);
    echo json_encode([     
        'success' =&gt; 0,
        'message' =&gt; $e-&gt;getMessage()
    ]);
    exit;
    }

?&gt;
</code></pre>
<p><a href=""https://i.stack.imgur.com/uovq1.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uovq1.jpg"" alt=""An this is my database"" /></a></p>
<p>This is the video tutorial from where I'm learning <a href=""https://www.youtube.com/watch?v=5huuXugiVNU"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=5huuXugiVNU</a>.</p>
",<php><mysql>
13484084,EXC_CRASH (SIGABRT) Cannot track it down - please see crash log attached - GADObjectPrivate.m,"<p>I am having trouble with one of my apps, apple rejected it due to it crashing on launch - however I cannot replicate this. I have even provided an adhoc build to another device to test and it works fine.
Anyway, they sent the crash log, and I opened it in Organiser to symbolicate.</p>

<p>Exception Type:  EXC_CRASH (SIGABRT)
Exception Codes: 0x0000000000000000, 0x0000000000000000
Crashed Thread:  0</p>

<pre><code>Last Exception Backtrace:
0   CoreFoundation                  0x3311d29e __exceptionPreprocess + 158
1   libobjc.A.dylib                 0x39dff97a objc_exception_throw + 26
2   CoreFoundation                  0x33120e02 -[NSObject(NSObject) doesNotRecognizeSelector:] + 166
3   CoreFoundation                  0x3311f52c ___forwarding___ + 388
4   CoreFoundation                  0x33076f64 _CF_forwarding_prep_0 + 20
5   diamondlite                 0x00065aec -[GADObjectPrivate loadPrivateRequest:autoRefresh:] (GADObjectPrivate.m:402)
6   diamondlite                 0x00067540 -[GADObjectPrivate loadRequest:] (GADObjectPrivate.m:827)
7   diamondlite                 0x0006501c -[GADBannerView loadRequest:] (GADBannerView.m:271)
8   diamondlite                 0x00012f40 -[GalleryViewControllerViewController viewWillAppear:] (GalleryViewControllerViewController.m:94)
9   UIKit                           0x38e94314 -[UIViewController _setViewAppearState:isAnimating:] + 132
10  UIKit                           0x38ea08bc -[UINavigationController _startTransition:fromViewController:toViewController:] + 828
11  UIKit                           0x38ea04a4 -[UINavigationController _startDeferredTransitionIfNeeded:] + 320
12  UIKit                           0x38e714dc -[UILayoutContainerView layoutSubviews] + 176
13  UIKit                           0x38e307fe -[UIView(CALayerDelegate) layoutSublayersOfLayer:] + 254
14  QuartzCore                      0x3ab04d5e -[CALayer layoutSublayers] + 210
15  QuartzCore                      0x3ab048fc CA::Layer::layout_if_needed(CA::Transaction*) + 456
16  QuartzCore                      0x3ab337a2 -[CALayer layoutIfNeeded] + 138
17  UIKit                           0x38eda0c4 -[UIViewController window:setupWithInterfaceOrientation:] + 204
18  UIKit                           0x38ed92b0 -[UIWindow _setRotatableClient:toOrientation:updateStatusBar:duration:force:isRotating:] + 3616
19  UIKit                           0x38ed8482 -[UIWindow _setRotatableClient:toOrientation:updateStatusBar:duration:force:] + 42
20  UIKit                           0x38ed840c -[UIWindow _setRotatableViewOrientation:duration:force:] + 64
21  UIKit                           0x3900e17c __57-[UIWindow _updateToInterfaceOrientation:duration:force:]_block_invoke_0 + 100
22  UIKit                           0x38e96674 -[UIWindow _updateToInterfaceOrientation:duration:force:] + 212
23  UIKit                           0x38e963b8 -[UIWindow setAutorotates:forceUpdateInterfaceOrientation:] + 688
24  UIKit                           0x38e95d26 -[UIViewController _tryBecomeRootViewControllerInWindow:] + 154
25  UIKit                           0x38e8ce9e -[UIWindow addRootViewControllerViewIfPossible] + 366
26  UIKit                           0x38e88ae0 -[UIWindow _setHidden:forced:] + 360
27  UIKit                           0x38eca1c4 -[UIWindow makeKeyAndVisible] + 56
28  diamondlite                 0x000112fc -[AppDelegate application:didFinishLaunchingWithOptions:] (AppDelegate.m:96)
29  UIKit                           0x38e8dacc -[UIApplication _handleDelegateCallbacksWithOptions:isSuspended:restoreState:] + 248
30  UIKit                           0x38e8d656 -[UIApplication _callInitializationDelegatesForURL:payload:suspended:] + 1186
31  UIKit                           0x38e8583e -[UIApplication _runWithURL:payload:launchOrientation:statusBarStyle:statusBarHidden:] + 694
32  UIKit                           0x38e2dc34 -[UIApplication handleEvent:withNewEvent:] + 1000
33  UIKit                           0x38e2d6c8 -[UIApplication sendEvent:] + 68
34  UIKit                           0x38e2d116 _UIApplicationHandleEvent + 6150
35  GraphicsServices                0x365a959e _PurpleEventCallback + 586
36  GraphicsServices                0x365a91ce PurpleEventCallback + 30
37  CoreFoundation                  0x330f216e __CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE1_PERFORM_FUNCTION__ + 30
38  CoreFoundation                  0x330f2112 __CFRunLoopDoSource1 + 134
39  CoreFoundation                  0x330f0f94 __CFRunLoopRun + 1380
40  CoreFoundation                  0x33063eb8 0x3305b000 + 36536
41  CoreFoundation                  0x33063d44 0x3305b000 + 36164
42  UIKit                           0x38e84478 0x38e2a000 + 369784
43  UIKit                           0x38e812f4 UIApplicationMain + 1116
44  diamondlite                 0x00010dc2 main (main.m:16)
45  diamondlite                 0x00010d5c start + 36


Thread 0 name:  Dispatch queue: com.apple.main-thread
Thread 0 Crashed:
0   libsystem_kernel.dylib          0x32047350 __pthread_kill + 8
1   libsystem_c.dylib               0x39d9e11e pthread_kill + 54
2   libsystem_c.dylib               0x39dda96e abort + 90
3   libc++abi.dylib                 0x37fa7d4a abort_message + 70
4   libc++abi.dylib                 0x37fa4ff4 default_terminate() + 20
5   libobjc.A.dylib                 0x39dffa74 _objc_terminate() + 144
6   libc++abi.dylib                 0x37fa5078 safe_handler_caller(void (*)()) + 76
7   libc++abi.dylib                 0x37fa5110 std::terminate() + 16
8   libc++abi.dylib                 0x37fa6594 __cxa_rethrow + 84
9   libobjc.A.dylib                 0x39dff9cc objc_exception_rethrow + 8
10  CoreFoundation                  0x33063f1c CFRunLoopRunSpecific + 452
11  CoreFoundation                  0x33063d44 CFRunLoopRunInMode + 100
12  UIKit                           0x38e84478 -[UIApplication _run] + 664
13  UIKit                           0x38e812f4 UIApplicationMain + 1116
14  diamondlite                 0x00010dc2 main (main.m:16)
15  diamondlite                 0x00010d5c start + 36
</code></pre>

<p>At the end it also says;</p>

<pre><code>Thread 0 crashed with ARM Thread State (32-bit):
    r0: 0x00000000    r1: 0x00000000      r2: 0x00000000      r3: 0x3cbef534
    r4: 0x00000006    r5: 0x3cbefb88      r6: 0x1dd82414      r7: 0x2fdf2a14
    r8: 0x1dd823f0    r9: 0x00000300     r10: 0x00000000     r11: 0x000b55de
    ip: 0x00000148    sp: 0x2fdf2a08      lr: 0x39d9e123      pc: 0x32047350
  cpsr: 0x00000010
</code></pre>

<p>I just have no idea what is causing the problem? Because I cannot replicate it on my devices which makes it even harder - I hope someone can help?</p>

<p>Thanks,</p>

<p>Chris</p>
",<iphone><xcode><ipad><crash><sigabrt>
78213345,Can't log JSON data from nodejs + express when serving static files with express use but can see it when I call only get JSON data and not the statics,"<p>I'm trying to learn how to send data from nodejs + express server to front-end static files, where javascript (allScripts.js) will be used to process it. Currently I'm trying to at least log it to console to see if I'm correctly sending it to the front-end.</p>
<p>Initially I wanted to send data from sqlite database to front-end, however due to lack of knowledge I reduced it to sending a simple array of objects as JSON using nodejs and displaying it in browser console for now. Unfortunately, it's resulting in</p>
<pre><code>Uncaught (in promise) SyntaxError: JSON.parse: unexpected character at line 1 column 1 of the JSON data
</code></pre>
<p>Here is the server code:</p>
<pre><code>const express = require('express');
const app = express();
const PORT = 3000;

app.use(express.static('public'));

app.get('/', (req,res) =&gt; {
    const users = [
        {id:'123',
        name:'Shaun'},
        {id:'234',
        name:'Bob'},
        {id:'345',
        name:'John'},
        {id:'456',
        name:'Oliver'},
    ]
    res.json(users);
});

app.listen(PORT, () =&gt; {
    console.log(&quot;Server running on port &quot;,PORT)
});
</code></pre>
<p>Removing app.use, however, is allowing me to see the users table like this:</p>
<p><a href=""https://i.stack.imgur.com/n109d.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>Here is the static javascript (allScripts.js) snippet to print the data:</p>
<pre><code>fetch('../').then(response =&gt; response.json())
        .then(users =&gt; console.log(users));
</code></pre>
<p>Here is the directory structure:</p>
<p>/ ----nodejs server file</p>
<p>----public ---- index.html</p>
<pre><code>           ----style.css

           ----allScripts.js
</code></pre>
<p>I will edit the question to provide any further details if required.</p>
",<javascript><node.js><express>
39605746,Logistic regression on Spark,"<p>I need to run a logistic regression on Spark. After a little investigation, seems it is included in MLlib. However, it does not give many details of the regression results, such as p-value, confidence interval of the coefficient such as the outputs from R package. Is there any library on Spark that can do that?</p>
",<apache-spark><logistic-regression>
47656677,How to find out the name of the user logged on the machine?,"<p>Is possible find out the name of the user logged on the windows machine on a ChatBot? i am using ""userName = context.Activity.From.Name"", but it is not need it.</p>

<p>Thanks in advance.</p>
",<c#><botframework><formflow>
71443326,"Using R8 and proguard to remove logging, but turn off everything else","<p>I am trying to use R8 and proguard to remove logging from the release build.  The catch is that I need to this be minimally invasive at the moment, so I would like to enable R8/proguard to remove logs, but turn off everything else.  IE minifcation, obfuscation, etc.</p>
<p>build.gradle:</p>
<pre><code>release {
    minifyEnabled true
    proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
}
</code></pre>
<p>proguard-rules.pro:</p>
<pre><code>-dontobfuscate
-dontoptimize
-dontshrink

-assumenosideeffects class android.util.Log {
    public static boolean isLoggable(java.lang.String, int);
    public static int v(...);
    public static int w(...);
    public static int e(...);
    public static int d(...);
    public static int i(...);
}
</code></pre>
<p>However when building and deploying a release build the logs are not removed.  I imagine that this is because assumenosideeffects runs as part of one of the options that I turned off.</p>
<p>I have also tried this:</p>
<pre><code>-keep class ** { *; }

-assumenosideeffects class android.util.Log {
    public static boolean isLoggable(java.lang.String, int);
    public static int v(...);
    public static int w(...);
    public static int e(...);
    public static int d(...);
    public static int i(...);
}
</code></pre>
<p>However that also still leaves logging.</p>
<p>Without moving to a different logging library or modifying code, is is possible to to remove logging with R8/proguard and not run anything else?</p>
<p><strong>EDIT:</strong></p>
<p>I an effort to figure out why proguard/r8 is not removing logs I created a brand new project.  I added one line of logging with the following config:</p>
<pre><code>release {
    debuggable true
    minifyEnabled true
    proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
}
</code></pre>
<p>However when I build the release version and install the APK I am still seeing logging, which means my log statement was not removed.</p>
<p>EDIT:</p>
<pre><code>debuggable true 
</code></pre>
<p>Does skip r8 optimization.  So this is not a good way to verify logs have been removed by proguard.  Using a dex to jar application to verify is the way to go. dex2jar worked for me.</p>
",<android><proguard><android-r8>
47292379,"Upgrade Android Studio 3, and logcat screen was modified","<p>Upgrade Android Studio 3, and logcat screen was modified, now i can't see the log filter. Does't enter in the width screen: </p>

<p>Old Version, in two lines, because have ""logcat"" and ""monitors""</p>

<p>link Image:</p>

<p><a href=""https://i.stack.imgur.com/iahLL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iahLL.png"" alt=""enter image description here""></a></p>

<p>New Version, not have ""logcat"" and ""monitors"", so don't enter in widht (""verbose, search, regex, no filters"")</p>

<p>link Image:</p>

<p><a href=""https://i.stack.imgur.com/1MsIS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1MsIS.png"" alt=""enter image description here""></a></p>

<p>I do not know if something similar happens to someone,thanks.</p>
",<android><android-studio-3.0>
48269556,Dancer2 not writing anything to a log file or maybe not reading config file,"<p>Here's the Dancer2 mini-app:</p>

<pre><code>#!/usr/bin/env perl

use v5.14;

use Dancer2;
use File::Slurper qw(read_text);

set content_type =&gt; 'application/json';

my $path;
for my $p ( qw( hitos.json /data/hitos.json ./data/hitos.json ../data/hitos.json) ) {
  if ( -r $p ) {
    $path = $p;
  }
}

my $hitos = from_json read_text($path);

get '/status' =&gt; sub {
  return to_json { status =&gt; 'OK' };
};

get '/all' =&gt; sub {
  return to_json $hitos;
};

start;
</code></pre>

<p>with this configuration file:</p>

<pre><code>logger : ""File""
engines:
  logger:
    File:
      log_level: core
      log_dir: ""/tmp""
      file_name: ""p5hitos.log""
</code></pre>

<p>I have named it <code>config.yml</code> and <code>config.yaml</code>, and also tried to use the JSON configuration option. I have tried to set the port from it, and it does not ""catch"" the port setting, so could the problem be the configuration file failing silently? I have also tried to set the configuration on the same file:</p>

<pre><code>set content_type =&gt; 'application/json';
set logger =&gt; ""File"";
set port =&gt; 31415;
set engines =&gt; { logger =&gt; { File =&gt; { log_level =&gt; ""core"",
                       log_dir =&gt; ""."",
                       file_name =&gt; ""p5hitos.log"" }}};
</code></pre>

<p>In this case, the port and content-type are set correctly, but still no go, either with this log_dir or with <code>/tmp</code>. I have also tried code from <a href=""https://github.com/PerlDancer/Dancer2/blob/703d5826177657e756f67b7ef0121ebe1923e5ff/t/issues/gh-634.t"" rel=""nofollow noreferrer"">this test</a> and copied it verbatim (set logger after set engines and low-case <code>file</code> were the only differences). It does not change. <code>config</code> is still the same:</p>

<pre><code>0  HASH(0x2a3d070)
   'appdir' =&gt; '/home/jmerelo/'
   'apphandler' =&gt; 'Standalone'
   'behind_proxy' =&gt; 0
   'charset' =&gt; ''
   'content_type' =&gt; 'application/json'
   'engines' =&gt; HASH(0x2947a58)
      'logger' =&gt; HASH(0x2947008)
         'File' =&gt; HASH(0xa438b0)
            'file_name' =&gt; 'p5hitos.log'
            'log_dir' =&gt; '/tmp'
   'environment' =&gt; 'development'
   'host' =&gt; '0.0.0.0'
   'logger' =&gt; Dancer2::Logger::File=HASH(0x2a7ef58)
      'app_name' =&gt; 'main'
      'config' =&gt; HASH(0x2a7f1b0)
           empty hash
      'environment' =&gt; 'development'
      'file_name' =&gt; 'p5hitos.log'
      'location' =&gt; '/home/jmerelo/'
      'log_dir' =&gt; '/tmp'
      'log_format' =&gt; '[%a:%P] %L @%T&gt; %m in %f l. %l'
      'log_level' =&gt; 'debug'
   'no_server_tokens' =&gt; 0
   'port' =&gt; 31415
   'public_dir' =&gt; '/home/jmerelo/public'
   'route_handlers' =&gt; ARRAY(0x2779490)
      0  ARRAY(0x27791d8)
         0  'AutoPage'
         1  1
   'startup_info' =&gt; 1
   'static_handler' =&gt; undef
   'template' =&gt; 'Tiny'
   'traces' =&gt; 0
   'views' =&gt; '/home/jmerelo/views'
</code></pre>

<p>It starts up and returns the two routes correctly, but the log file is not created and obviously nothing is written on it. There's no error either on the console, and it's not logging to it either. It just shows the startup message: <code>&gt;&gt; Dancer2 v0.204001 server 16427 listening on http://0.0.0.0:3000</code>. The Log file object seems to have been created correctly, but it does not respond. Any idea?</p>
",<perl><web-services><logging><dancer>
13339265,nginx log http status what is 404 187,"<p>Hi I got nginx access log file like the follows:</p>

<pre><code>192.168.1.1 - - [06/Nov/2012:22:13:46 +1100] ""GET /?i=a HTTP/1.1"" 404 187 ""-"" ""Mozilla/5.0 (Windows NT 6.1; WOW64; rv:14.0) Gecko/20100101 Firefox/14.0.1""
192.168.1.2 - - [06/Nov/2012:22:13:50 +1100] ""GET /?i=b HTTP/1.1"" 200 0 ""http://abc.com/545512565475443/"" ""Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.4 (KHTML, like Gecko) Chrome/22.0.1229.94 Safari/537.4""
</code></pre>

<p>So that <code>404</code> in the first line should be not found and <code>200</code> in the second line means success. That's okay, but what is the <code>187</code> behind <code>404</code> in the first line and <code>0</code> behind <code>200</code> in the second line?</p>

<p>thanks,
Green</p>
",<http><logging><nginx>
22275633,Photologue thumbnails not cached (displayed as broken image links),"<p>Both my admin and site pages do not display thumbnails of my images correctly:
<img src=""https://i.stack.imgur.com/TuUFp.png"" alt=""admin view of photos showing broken thumbnails on right""></p>

<p>My project is completely borrowed from the following photologue tutorial:
<a href=""https://github.com/jdriscoll/django-photologue/tree/master/example_project"" rel=""nofollow noreferrer"">https://github.com/jdriscoll/django-photologue/tree/master/example_project</a></p>

<p>I am using Django 1.6.2 and Photologue 2.7. All requirements were installed according to the tutorial.</p>

<p>I made absolutely no changes to the tutorial source code, successfully added a gallery and photos (from admin page) to the database and successfully did a <code>synchdb</code>, <code>migrate</code>, and <code>plinit</code> command.</p>

<p>My ""cache"" directory is empty however, as if the thumbnails simply aren't being generated even though I manually force pre-cache images to be cached using <code>plcache</code> command taken from the docs: <a href=""https://code.google.com/p/django-photologue/wiki/ManagementCommands"" rel=""nofollow noreferrer"">https://code.google.com/p/django-photologue/wiki/ManagementCommands</a>
<img src=""https://i.stack.imgur.com/CPx7Y.png"" alt=""project view in eclipse pydev showing empty cache""></p>

<p>And, all of my images are pre-cache so I'm really not sure why they aren't getting cached...:
<img src=""https://i.stack.imgur.com/qK7pb.png"" alt=""photo sizes, all of which are pre-cache though they aren&#39;t getting cached""></p>

<p>The debugger in eclipse pydev tells me it is attempting to locate the thumbnails, but like I mentioned before they are not being cached so it prints:</p>

<pre><code>[08/Mar/2014 16:51:42] ""GET /media/photologue/photos/cache/pic3_thumbnail.jpg HTTP/1.1"" 404 1780
</code></pre>

<p>According to this post this error might be caused by an incorrect MEDIA_URL or MEDIA_ROOT setting:
<a href=""https://stackoverflow.com/questions/12605974/sorl-thumbnail-not-creating-thumbnails"">sorl-thumbnail not creating thumbnails</a></p>

<p>However, my media root and url were set by the tutorial I'm borrowing from which I assume to be set correctly.</p>

<p>This problem is identical to the one reported on this google group forum:
<a href=""https://groups.google.com/forum/#!topic/django-photologue/tu4IVekLJJo"" rel=""nofollow noreferrer"">https://groups.google.com/forum/#!topic/django-photologue/tu4IVekLJJo</a></p>

<p>Has anyone had a similar issue to this before? How might I get the thumbnails to cache and be displayed?</p>
",<python><django><gallery><thumbnails><photologue>
77052232,"In the AWS codePipeline , while the script is running in the log , its showing the following error . fix this","<p><strong>this is the buildspec.yml:</strong></p>
<pre><code>version: 0.2

phases:
  install:
    commands:
      - npm install -g typescript
  pre_build:
    commands:
      - echo Installing source NPM dependencies...
      - npm install
  build:
    commands:
      - echo Build started on `date`
      - npm run build
  post_build:
    commands:
      - echo Build completed on `date`
artifacts:
  files:
    - public/**/*
    - package.json
    - package-lock.json
    - node_modules/**/*
    - swagger.yaml
    - appspec.yaml
</code></pre>
<p><strong>this is the tsconfig.json:</strong></p>
<pre><code>{
  &quot;compilerOptions&quot;: {
    &quot;experimentalDecorators&quot;: true,
    &quot;emitDecoratorMetadata&quot;: true,
    /* Visit https://aka.ms/tsconfig.json to read more about this file */
    /* Basic Options */
    // &quot;incremental&quot;: true,                         /* Enable incremental compilation */
    &quot;target&quot;: &quot;es6&quot; /* Specify ECMAScript target version: 'ES3' (default), 'ES5', 'ES2015', 'ES2016', 'ES2017', 'ES2018', 'ES2019', 'ES2020', 'ES2021', or 'ESNEXT'. */,
    &quot;module&quot;: &quot;commonjs&quot; /* Specify module code generation: 'none', 'commonjs', 'amd', 'system', 'umd', 'es2015', 'es2020', or 'ESNext'. */,
    &quot;lib&quot;: [
      &quot;DOM&quot;,
      &quot;ES2017&quot;
    ] /* Specify library files to be included in the compilation. */,
    // &quot;allowJs&quot;: true,                             /* Allow javascript files to be compiled. */
    // &quot;checkJs&quot;: true,                             /* Report errors in .js files. */
    // &quot;jsx&quot;: &quot;preserve&quot;,                           /* Specify JSX code generation: 'preserve', 'react-native', 'react', 'react-jsx' or 'react-jsxdev'. */
    // &quot;declaration&quot;: true,                         /* Generates corresponding '.d.ts' file. */
    // &quot;declarationMap&quot;: true,                      /* Generates a sourcemap for each corresponding '.d.ts' file. */
    // &quot;sourceMap&quot;: true,                           /* Generates corresponding '.map' file. */
    // &quot;outFile&quot;: &quot;./&quot;,                             /* Concatenate and emit output to single file. */
    &quot;outDir&quot;: &quot;public&quot; /* Redirect output structure to the directory. */,
    &quot;rootDir&quot;: &quot;src&quot; /* Specify the root directory of input files. Use to control the output directory structure with --outDir. */,
    // &quot;composite&quot;: true,                           /* Enable project compilation */
    // &quot;tsBuildInfoFile&quot;: &quot;./&quot;,                     /* Specify file to store incremental compilation information */
    // &quot;removeComments&quot;: true,                      /* Do not emit comments to output. */
    // &quot;noEmit&quot;: true,                              /* Do not emit outputs. */
    // &quot;importHelpers&quot;: true,                       /* Import emit helpers from 'tslib'. */
    // &quot;downlevelIteration&quot;: true,                  /* Provide full support for iterables in 'for-of', spread, and destructuring when targeting 'ES5' or 'ES3'. */
    // &quot;isolatedModules&quot;: true,                     /* Transpile each file as a separate module (similar to 'ts.transpileModule'). */
    /* Strict Type-Checking Options */
    &quot;strict&quot;: true /* Enable all strict type-checking options. */,
    // &quot;noImplicitAny&quot;: true,                       /* Raise error on expressions and declarations with an implied 'any' type. */
    // &quot;strictNullChecks&quot;: true,                    /* Enable strict null checks. */
    // &quot;strictFunctionTypes&quot;: true,                 /* Enable strict checking of function types. */
    // &quot;strictBindCallApply&quot;: true,                 /* Enable strict 'bind', 'call', and 'apply' methods on functions. */
    // &quot;strictPropertyInitialization&quot;: true,        /* Enable strict checking of property initialization in classes. */
    // &quot;noImplicitThis&quot;: true,                      /* Raise error on 'this' expressions with an implied 'any' type. */
    // &quot;alwaysStrict&quot;: true,                        /* Parse in strict mode and emit &quot;use strict&quot; for each source file. */
    /* Additional Checks */
    // &quot;noUnusedLocals&quot;: true,                      /* Report errors on unused locals. */
    // &quot;noUnusedParameters&quot;: true,                  /* Report errors on unused parameters. */
    // &quot;noImplicitReturns&quot;: true,                   /* Report error when not all code paths in function return a value. */
    // &quot;noFallthroughCasesInSwitch&quot;: true,          /* Report errors for fallthrough cases in switch statement. */
    // &quot;noUncheckedIndexedAccess&quot;: true,            /* Include 'undefined' in index signature results */
    // &quot;noImplicitOverride&quot;: true,                  /* Ensure overriding members in derived classes are marked with an 'override' modifier. */
    // &quot;noPropertyAccessFromIndexSignature&quot;: true,  /* Require undeclared properties from index signatures to use element accesses. */
    /* Module Resolution Options */
    // &quot;moduleResolution&quot;: &quot;node&quot;,                  /* Specify module resolution strategy: 'node' (Node.js) or 'classic' (TypeScript pre-1.6). */
    // &quot;baseUrl&quot;: &quot;./&quot;,                             /* Base directory to resolve non-absolute module names. */
    // &quot;paths&quot;: {},                                 /* A series of entries which re-map imports to lookup locations relative to the 'baseUrl'. */
    // &quot;rootDirs&quot;: [],                              /* List of root folders whose combined content represents the structure of the project at runtime. */
    // &quot;typeRoots&quot;: [],                             /* List of folders to include type definitions from. */
    // &quot;types&quot;: [],                                 /* Type declaration files to be included in compilation. */
    // &quot;allowSyntheticDefaultImports&quot;: true,        /* Allow default imports from modules with no default export. This does not affect code emit, just typechecking. */
    &quot;esModuleInterop&quot;: true /* Enables emit interoperability between CommonJS and ES Modules via creation of namespace objects for all imports. Implies 'allowSyntheticDefaultImports'. */,
    // &quot;preserveSymlinks&quot;: true,                    /* Do not resolve the real path of symlinks. */
    // &quot;allowUmdGlobalAccess&quot;: true,                /* Allow accessing UMD globals from modules. */
    /* Source Map Options */
    // &quot;sourceRoot&quot;: &quot;&quot;,                            /* Specify the location where debugger should locate TypeScript files instead of source locations. */
    // &quot;mapRoot&quot;: &quot;&quot;,                               /* Specify the location where debugger should locate map files instead of generated locations. */
    // &quot;inlineSourceMap&quot;: true,                     /* Emit a single file with source maps instead of having a separate file. */
    // &quot;inlineSources&quot;: true,                       /* Emit the source alongside the sourcemaps within a single file; requires '--inlineSourceMap' or '--sourceMap' to be set. */
    /* Experimental Options */
    // &quot;experimentalDecorators&quot;: true,              /* Enables experimental support for ES7 decorators. */
    // &quot;emitDecoratorMetadata&quot;: true,               /* Enables experimental support for emitting type metadata for decorators. */
    /* Advanced Options */
    &quot;skipLibCheck&quot;: true /* Skip type checking of declaration files. */,
    &quot;forceConsistentCasingInFileNames&quot;: true /* Disallow inconsistently-cased references to the same file. */
  }
}
</code></pre>
<p><strong>in the AWS codePipeline , while the script is running in the log , its showing the following error . how to fix this :</strong></p>
<pre><code>&gt; justpoll-server@1.0.0 build
&gt; tsc -p .

error TS2688: Cannot find type definition file for 'cron'.
  The file is in the program because:
    Entry point for implicit type library 'cron'

[Container] 2023/09/06 11:49:49 Command did not exit successfully npm run build exit status 2
[Container] 2023/09/06 11:49:49 Phase complete: BUILD State: FAILED
[Container] 2023/09/06 11:49:49 Phase context status code: COMMAND_EXECUTION_ERROR Message: Error while executing command: npm run build. Reason: exit status 2
[Container] 2023/09/06 11:49:49 Entering phase POST_BUILD
[Container] 2023/09/06 11:49:49 Running command echo Build completed on `date`
Build completed on Wed Sep 6 11:49:49 UTC 2023
</code></pre>
<p>I am encountering an error during the build phase of their AWS CodePipeline, which is part of their software development and deployment process. The error message they provided is related to TypeScript, a programming language that adds static typing to JavaScript.</p>
",<node.js><typescript><amazon-ec2><aws-codepipeline>
56181791,"How can i change ""oe_chatter"" log comments in Odoo 10?","<p>I've created a custom module for uploading some documents against an employee in <code>Odoo 10</code>. And now i am trying to use ""oe_chatter"" for logs purpose. </p>

<p>When i click on save, log is coming as : </p>

<blockquote>
  <p>Note by Administrator - 2 minutes ago</p>
  
  <p>hr.documents created</p>
</blockquote>

<p>How can i change this to ""Employee Document is created"" ?</p>

<p>This is my code :</p>

<pre><code>class HrDocuments(models.Model):
    _name = 'hr.documents'
    _inherit = ['mail.thread', 'ir.needaction_mixin']



&lt;div class=""oe_chatter""&gt;
                        &lt;field name=""message_follower_ids"" widget=""mail_followers"" groups=""base.group_user""/&gt;
                        &lt;field name=""message_ids"" widget=""mail_thread""/&gt;
&lt;/div&gt;
</code></pre>
",<python><odoo-10>
32368758,log4j2 java.lang.NoClassDefFoundError: org/apache/logging/log4j/LogManager,"<p>I am using log4j 2.3 in my java application. I added the dependency via maven.<br>
When running the program in eclipse everything work fine, but when I package it with maven and try to run the jar I get the following error:  </p>

<pre><code>Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache logging/log4j/LogManager
    at main.myclass.&lt;clinit&gt;(myclass.java:11)
Caused by: java.lang.ClassNotFoundException: org.apache.logging.log4j.LogManager 


    at java.net.URLClassLoader.findClass(Unknown Source)
    at java.lang.ClassLoader.loadClass(Unknown Source)
    at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
    at java.lang.ClassLoader.loadClass(Unknown Source)
    ... 1 more
</code></pre>

<p>Why is it not able to find the class while running it from a jar?</p>

<p>Adding <code>log4j 1.2</code> did not work either. The program is running fine in eclipse so there should be no missing dependency.</p>
",<java><eclipse><maven><log4j2>
11631753,How to use log4j in the way/format I want?,"<p>I want to understand how log4j works.
I've read a lot of tutorials and all the answers from this site, but I still didn't get a concrete example which works.</p>

<p>I've tried this:</p>

<pre><code>import org.apache.log4j.*;

public class Exercise {
    private static Logger logger = Logger.getLogger(SimpleLogger.class);

    public static void main(String args[]) {

        BasicConfigurator.configure();

        // ConsoleAppender myAppender = new ConsoleAppender(null, ""System.out"");
        // myAppender.setLayout(new SimpleLayout());
        // logger.addAppender(myAppender);

        for (int i = 0; i &lt; 5; i++) {
            logger.info(""You are here!"");
        }

        logger.info(""End of program"");
    }
}
</code></pre>

<p>With this class:</p>

<pre><code>import org.apache.log4j.spi.LoggingEvent;

public class SimpleLogger extends org.apache.log4j.Layout {

    @Override
    public void activateOptions() {

    }

    @Override
    public String format(LoggingEvent event) {
        return ""log message = "" + event.getMessage().toString() + ""/n"";
    }

    @Override
    public boolean ignoresThrowable() {
        return true;
    }
}
</code></pre>

<p>But my output is:</p>

<pre><code>0 [main] INFO SimpleLogger  - You are here!
1 [main] INFO SimpleLogger  - You are here!
1 [main] INFO SimpleLogger  - You are here!
1 [main] INFO SimpleLogger  - You are here!
1 [main] INFO SimpleLogger  - You are here!
1 [main] INFO SimpleLogger  - End of program
</code></pre>

<p>I've tried also, with the code not commented but all I got is the output in double form or something.</p>

<p>Question:
How can I make the output (Console or File) be in the format that I want?
Do I need to modify an external file like (log4j.properties)?</p>
",<java><logging><log4j>
24189432,Aggregate multiple log tables into one table; Outer Join?,"<p>I have multiple tables in SQL Server 2008. They are various logging tables. Each table will have a <code>PersonID_FK</code> and a <code>Create</code> timestamp</p>

<p>I need to aggregate all of these tables for a particular <code>PersonID</code> key, such that I grab all record from any off the log tables where that person_ID key exists, and then sort all of the resulting rows by the <code>create timestamp</code>. I'm using LINQ to entities, and Entity Framework, but creating a view in the db seems like the best approach</p>

<p>See my SQL code below. </p>

<pre><code>SELECT 
    * 
FROM 
    dbo.person 
LEFT OUTER JOIN
    dbo.log_items ON dbo.person.Id = dbo.log_items.personID 
LEFT OUTER JOIN
    dbo.Interactions ON dbo.person.Id = dbo.Interactions.personID
WHERE     
    (dbo.person.Id = 'a733ecf6-f414-4bcd-8b07-d6e12d313b95')
</code></pre>

<p>My resulting data from this query is only returning 2 rows, when I should have somewhere around 8 result rows. </p>
",<sql><linq><entity-framework><sql-server-2008>
39409221,Why line number is not printed in exception logs generally for proxys?,"<p>Why line number is not printed for spring proxys?</p>

<p>Sometimes i get the excpetion in logs i see line number is not printed. I have seen mainly for spring CGLIB proxies. For example
in below stack trace i see line number is not printed for CustomerServiceBean proxy managed by spring .</p>

<pre><code>at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:622)
at com.xeb.customer.account.CustomerServiceBean$$EnhancerByCGLIB$$5a0112c7.getCustomerDetails(&lt;generated&gt;)
at com.xeb.customer.account.CustomerUtil.getCustomerDetails(CustomerUtil.java:142)
</code></pre>

<p>Any idea why ? Is there a configuration to print line number in proxies too ?</p>

<p><strong>Update :-</strong>  I understand proxies are genertaed at run time, so it does not makes sense to print their line(if printed does not matter). But my question
how can i get the line no of exception in <code>CustomerServiceBean.java</code> which is actual class behind proxy <code>CustomerServiceBean$$EnhancerByCGLIB$$5a0112c7.getCustomerDetails</code>?</p>
",<java><spring><exception><proxy>
4378817,MEF container auto-update using a directory-catalog,"<p>This is possible if we manually create a <code>FileSystemWatcher</code> and watch the 'parts' directory (here some dlls inside the folder) and track any changes, then we reflect the changes into a container which allows for recomposition.</p>

<p>Does <code>MEF</code> support auto-updating when the <code>Container</code> is using a <code>DirectoryCatalog</code> and it automatically for us ?</p>
",<directory><containers><mef><catalog><auto-update>
12094728,Write a SQL Log procedure,"<p>I need to write a simple SQL log procedure, that could be called like this:</p>

<pre><code>Log(""This is my param1 = {0}, param2 = {1} and param3('{2}')"", 
     @param1, @param2, @param3)
</code></pre>

<p>the output should be redirected to the file on SQL Server ""C:\output.txt""</p>

<p>is it possible using such a procedure with <strong><em>variable</em></strong> number of params and how?</p>

<p>perhaps I could use</p>

<pre><code>exec master..xp_cmdshell 'echo created &gt; c:\output.txt'
exec master..xp_cmdshell 'echo appended data &gt;&gt; c:\output.txt'
exec master..xp_cmdshell 'echo more data &gt;&gt; c:\output.txt'
</code></pre>
",<sql><sql-server><sql-server-2005>
13040574,C# Increasing Console Log Size,"<p>i have a basic C# Console application, it retrives logs from a website, but after like 100 lines, the old logs are deleted and the user cant scroll up and see them anymore, is there any way to increase the size it will save?</p>
",<c#>
26538131,Best approach to send Scribe centralized logging output to elasticsearch,"<p>We're currently building a centralized logging platform for our multitude of services. The plan is to install a scribe client on every application server, which will forward the logs to a central scribe server.</p>

<p>The central scribe server is currently logging all the aggregated logs to disk. But now we want to index them on ElasticSearch for visualization. </p>

<p>My exact question is: What's the best (most robust, fault-tolerant, less computationally expensive &amp; memory efficient) way to forward logs from a central scribe server's output to ElasticSearch for indexing?</p>

<p>Few ideas worth exploring: </p>

<ol>
<li>Scribe Server -> File -> Logstash -> ElasticSearch</li>
<li>Scribe Server -> File -> [X] -> RabbitMQ -> Logstash -> ElasticSearch</li>
<li>Scribe Server -> File -> [Y] -> ElasticSearch</li>
<li>Scriber Server -> [Z] -> Elastic Search</li>
</ol>

<p>Any good options for X, Y or Z? Which one's the best approach? Please suggest. </p>

<p>Thanks.</p>
",<logging><elasticsearch><logstash><scribe>
43542042,Forwarding docker GELF logs to Logstash with Filebeat (or alternative?),"<p>Gelf messages are a subset of all Json Strings. How can I use filebeat (or an alternative) as a lightweight solution to forward docker gelf logs reliably to logstash?</p>

<p>Further info:</p>

<p>I have a cluster (docker swarm for now) of machines in the same network running docker containers. I want to use --log-driver=gelf because I like the gelf format and want the fields that docker adds to each GELF log entry.</p>

<p>Unfortunately docker sends GELF logs with UDP and I fear loosing log entries. Either because packages are lost, logstash is down, or there is too much load for logstash. I don't want to run logstash on each host because it is a heavyweight.</p>
",<logging><docker><microservices><elastic-stack><filebeat>
20242349,Windows Phone Marketplace App Update Changelog,"<p>When there is an update available in store. If you click on the app it opens an information page where you can see the changelog for the current version of app. Some developers provide this information some doesn't. I wonder where is this information is written in app code. Is it app manifest file ?</p>

<p>To remind again, i don't mean in store description.</p>
",<windows-phone-8><marketplace>
9454298,Retrieve all product IDs associated with a Catalog Price Rule in Magento,"<p>I need a way to retrieve product IDs associated with a Catalog Price Rule promotion (ex. 50% the price of all items in the BICYCLES category).  I'd like to do this without having to iterate through the entire product database.</p>

<p>I know there is a function called <code>getRuleProductIds($ruleID)</code>, which should return an array of product IDs by rule ID, but I have no idea where to use it, which collection to associate it with, etc.</p>

<p>I have the following code in a <code>products_in_promotion.phtml</code> template:</p>

<pre><code>&lt;?php 
  $rules = Mage::getModel('catalogrule/rule');
  $collection = $rules-&gt;getCollection();
  $sale_items = $collection-&gt;getRuleProductIds(1); # ??????? this throws an error
?&gt;
</code></pre>

<p><code>$collection</code> properly stores an array of all the Catalog Price rules, but that's as close as I can get.  No product list is in sight.</p>

<p>Any ideas what I'm doing wrong here?</p>
",<magento>
22974466,Matlab's fill doesn't work in semilog or log scales,"<p>I'm having a problem with the fill() command using semilog or loglog scaling, let me show you with an example, the code:  </p>

<pre><code>Rjbs=0.1:0.1:10;
PGAvsr360=[sin(Rjbs)-1; sin(Rjbs) ; sin(Rjbs)+1]';
PGAvsr760=[sin(Rjbs)-1.5; sin(Rjbs)-0.5 ; sin(Rjbs)+0.5]';
figure
plot(Rjbs,PGAvsr360(:,2),'Color', 'b', 'LineWidth', 2)
hold on
plot(Rjbs,PGAvsr760(:,2),'Color', [0 0.6 0], 'LineWidth', 2)
X=[Rjbs,fliplr(Rjbs)];
Y=[PGAvsr360(:,1)',fliplr(PGAvsr360(:,3)')];
fill(X,Y,[0.5 0.5 1], 'FaceAlpha', 0.4)
Y=[PGAvsr760(:,1)',fliplr(PGAvsr760(:,3)')];
fill(X,Y,[0.3 1 0.3], 'FaceAlpha', 0.4)
</code></pre>

<p>produces this nice figure, with the FaceAlpha feature working
<img src=""https://i.stack.imgur.com/dbuRs.png"" alt=""nice""></p>

<p>The same code but changing plot with semilogx in both commands produces 
<img src=""https://i.stack.imgur.com/M9J5J.png"" alt=""fail""></p>

<p>with the FaceAlpha feature not working. </p>

<p>Is there a way to make it work?</p>
",<matlab><plot><fill>
29165968,Parse docker logs with logstash,"<p>I have a docker container that log to stdout/stderr. Docker save it's output into /var/lib/docker/containers//-logs.json</p>

<p>The log has lines with the following structure</p>

<pre><code>{""log"":""This is a message"",""stream"":""stderr"",""time"":""2015-03-12T19:27:27.310818102Z""}
</code></pre>

<p>which input/codec/filter should I use to get only the <code>log</code> field as the <code>message</code> ?</p>

<p>Thanks!</p>
",<docker><logstash>
28971249,Xcode / Objective-C - log which class you're in,"<p>Is there a way, using Xcode in Objective-C, to log which the class and method you're in?</p>

<p>I'm aware you can add a <code>%B</code> to a breakpoint to show the method and class but the problem with that is you're having to guess which class you're in, add the breakpoints, then disable them. </p>

<p>What I'd like to do is add a breakpoint in Xcode with some command that echoes the current class/object and method to the console.</p>
",<objective-c><class><debugging><methods><lldb>
19649932,JavaScriptCore console.log,"<p>I've put together a very simple program that uses JavaScriptCore to evaluate JS:</p>

<pre><code>#import &lt;CoreFoundation/CoreFoundation.h&gt;
#import &lt;JavaScriptCore/JavaScriptCore.h&gt;

int main(int argc, const char * argv[])
{
    JSGlobalContextRef ctx = JSGlobalContextCreate(NULL);

    FILE *f = fopen(argv[1],""r"");
    char * buffer = malloc(10000000);
    fread(buffer,1,10000000,f);

    CFStringRef strs = CFStringCreateWithCString(NULL, buffer, kCFStringEncodingASCII);

    JSStringRef jsstr = JSStringCreateWithCFString(strs);
    JSValueRef result = JSEvaluateScript(ctx, jsstr, NULL, NULL, 0, NULL);

    double res  = JSValueToNumber(ctx, result, NULL);
    JSGlobalContextRelease(ctx);

    printf(""%lf\n"", res);
    return 0;
}
</code></pre>

<p>The idea here is that the last value is expected to be a <code>Number</code>, and that value is printed.  This works for valid javascript code, such as</p>

<pre><code>var square = function(x) { return x*x; }; square(4)
</code></pre>

<p>However, if the code tries to perform a <code>console.log</code>, the program segfaults.  Is there a log function available in JSC or do I have to roll my own?</p>
",<javascript><objective-c><xcode><macos><core-foundation>
76966584,Understanding Log analytics from Synapse Azure SQL Auditing,"<p>I would like to get some understanding on the result set of the logs that are logged to log analytics from the Synapse dedicated SQL pool auditing.</p>
<p>What does it mean when 'Application name' column value says 'Data Integration-8330100a-8ee8-XXXX-XXXX-c326e88f7d94'.</p>
<p>Not sure what it means, initially I thought its a managed identity or something.</p>
",<azure-log-analytics><azure-synapse-analytics>
42352092,Tomcat logs rotating with 2 or more dates in file names and many 0KB files,"<p>The Tomcat instances for one of the servers where I operate have logs that are rotating in a weird pattern, with 2 or more dates in file names and many 0KB files, as seen here (/opt/tomcat/instancename/logs folder for one of the instances): <a href=""https://i.stack.imgur.com/fH8co.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/fH8co.png</a></p>

<p>The current catalina.out file, for example, isn't even the one without any dates, as you can see by the timestamps in the Changed column.</p>

<p>Can you guys tell me how can I fix this?</p>

<p>---EDIT---<br>
I went to check the logrotate files and noticed only one of the instances has the logs configured for rotation in the /etc/logrotate.d/ folder; this instance happens to be the only one who has the crazy file names, contrary to what I thought. As asked in the comments, here's the logrotate config file for the instance:</p>

<pre><code>/opt/tomcat/apigold/logs/* {  
    daily  
    missingok  
    rotate 4  
    size 10M  
}
</code></pre>
",<tomcat>
47888823,Opencart 2 - For guests price with tax for logged in without tax,"<p>I need your help, now in Store settings prices with tax!
So it is okey.
But when customer logged in, i need it without tax only on product page and in category.
How can i do this?
Thank you! </p>
",<opencart><price><tax>
32434684,HTML5 slogan as heading in eshop,"<p>How do I make a document outline like this using HTML5 semantic tags, when I need the first two headings in one block?</p>

<pre class=""lang-none prettyprint-override""><code>-MySite
--Books for children
---Book1
---Book2
</code></pre>

<p>When I use</p>

<pre class=""lang-html prettyprint-override""><code>&lt;body&gt;
 &lt;header class=""INeedThisInOneBox""&gt;
  &lt;h1&gt;MySite&lt;/h1&gt;
   &lt;h2 class=""slogan""&gt;Books for children&lt;/h2&gt;
 &lt;/header&gt;
  &lt;article&gt;
   &lt;h1&gt;Book1&lt;/h1&gt;
  &lt;/article&gt;
  &lt;article&gt;
   &lt;h1&gt;Book2&lt;/h1&gt;
  &lt;/article&gt;
&lt;/body&gt;
</code></pre>

<p>the outline goes:</p>

<pre class=""lang-none prettyprint-override""><code>-MySite
--Books for children
--Book1
--Book2
</code></pre>

<p>I would like to use semantic tags, but need to have SEO importance granted for the slogan.</p>
",<html><seo><semantic-markup><outline><heading>
43325145,Supress Warnings from Windows Event Logs with Source MySQL,"<p>Is there a way to suppress the warnings arising from MySQL on Windows Event Logs?
I tried suppressing the warnings from mysql error log - it worked but it's continuing to write to event logs.</p>

<p>My version of MySQL : 5.6.24</p>

<p>Any help is appreciated.</p>
",<mysql><windows>
12361128,More Eclipse ADT Insanity! Logcat become completely disconnected,"<p>For no known reason (to me).  The logcat just stops running.  I've tried adb kill-server adb start-server etc, and nothing works except closing eclipse and restarting it.  This is not efficient at all. And its a waste of time.  Does anyone know how to prevent losing logcat data feed, and or how to quickly restore it? And this is about the 100th time at least that this has happened to me. I really cannot see this happening in xCode. Not in this way.  I mean where on earth is the click to reconnect?</p>
",<android><eclipse><adt>
11587270,Logistic regression in R,"<p>I have two matrix one X with all the feature values with 300000 rows and 14 columns, where columns represent the feature ids. for each I have another variable which defines labels Y which is of dimension 300000 x 1 either 0 or 1. </p>

<p>How do I calculate logistic regression from this matrix ? </p>
",<r><regression>
13085885,Get notification to the currently logged users,"<p>I want to add a notifications to my asp.net application. when place an order to order table,automatically popup should come to the currently logged users such as facebook notification. 
please help with sample codes 
Thanks. </p>
",<asp.net><ajax><web-services>
76964397,Could not determine the dependencies of task ':logrocket_react-native:compileDebugAidl',"<p>I installed</p>
<pre><code>logrocket/react-native 
</code></pre>
<p>and add to android/build.gradle</p>
<pre><code>maven { url &quot;https://storage.googleapis.com/logrocket-maven/&quot; }
</code></pre>
<p>once all that is done i run my react native project on android but it keeps failing with this error</p>
<pre><code>BUILD FAILED in 34s

error Failed to install the app. Make sure you have the Android development environment set up: https://reactnative.dev/docs/environment-setup.
Error: Command failed: gradlew.bat app:installDebug -PreactNativeDevServerPort=8081

FAILURE: Build failed with an exception.

* What went wrong:
Could not determine the dependencies of task ':logrocket_react-native:compileDebugAidl'.
&gt; Could not resolve all task dependencies for configuration ':logrocket_react-native:debugCompileClasspath'.
   &gt; Could not find com.logrocket:logrocket:1.18.0.
     Required by:
         project :logrocket_react-native
</code></pre>
<ul>
<li>tried to uninstall the nodemodule</li>
<li>tried to clear gradlew</li>
<li>increasing the logrocket/react-native version to 1.18.0, 1.19.0,1.19.2</li>
</ul>
<p>this should have built and could yarn android built my app.</p>
",<react-native><package><build.gradle><logrocket>
58025873,Logging dependencies still included in lib folder despite exlusion being configured in spring-boot-maven-plugin,"<p>EDIT: It turns out I am just bad at looking for stuff. The war before the changes did not have these libraries, and the original .war (before repackage) already contains them. So the issue lies somewhere else, spring-boot-maven-plugin has nothing to do with it. Still don't know where they are coming from since I've also tried simply deleting the dependency whereever I find it, but oh well, see my first sentence.</p>

<p>I am working on making my firms software run as a spring boot application. Since our war may be deployed in various different environments like the SAP Cloud Platform, logging libraries should not be included in the lib folder to prevent conflicts. However, some logging libraries (specifically jul-to-slf4j, log4j-api and log4j-to-self4j) are always in my lib folder no matter how specific my exclusions get. Other libraries (two of ours that are needed for tests or have to be included in the classes file) are excluded properly.</p>

<p>I have tried setting the  tag to the specific libraries as well as  to just exclude the whole group. After this, I tried to simply exclude the dependencies themselves, but they still somehow show up after mvn dependency:tree tells me they are no longer present. </p>

<p>This is the plugin configuration:</p>

<pre class=""lang-xml prettyprint-override""><code>&lt;plugin&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
    &lt;executions&gt;
        &lt;execution&gt;
            &lt;goals&gt;
                &lt;goal&gt;
                    repackage
                &lt;/goal&gt;
            &lt;/goals&gt;
        &lt;/execution&gt;
    &lt;/executions&gt;
    &lt;configuration&gt;
        &lt;mainClass&gt;de.firm.integration.BaseSpringConfiguration&lt;/mainClass&gt;
        &lt;excludes&gt;
            &lt;exclude&gt;
                &lt;groupId&gt;de.firm.integration&lt;/groupId&gt;
                &lt;artifactId&gt;eis-generator-odata-api&lt;/artifactId&gt;
            &lt;/exclude&gt;
            &lt;exclude&gt;
                &lt;groupId&gt;de.firm.integration&lt;/groupId&gt;
                &lt;artifactId&gt;eis-admin-ui&lt;/artifactId&gt;
            &lt;/exclude&gt;
            &lt;exclude&gt;
                &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
                &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt;
            &lt;/exclude&gt;
            &lt;exclude&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;
            &lt;/exclude&gt;
            &lt;exclude&gt;
                &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
                &lt;artifactId&gt;log4j-jul&lt;/artifactId&gt;
            &lt;/exclude&gt;
            &lt;exclude&gt;
                &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
                &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
            &lt;/exclude&gt;
            &lt;exclude&gt;
                &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
                &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt;
            &lt;/exclude&gt;
        &lt;/excludes&gt;
    &lt;/configuration&gt;
&lt;/plugin&gt;
</code></pre>

<p>I expect the war that I build to no longer include these logging libraries in my WEB-INF/lib folder. Instead, they keep being included.</p>
",<java><spring><spring-boot><log4j><slf4j>
43288929,Angular2 provide common logger to imported modules,"<p>I want to make a module A which depends on a module B, but let the user provide a logger to both through A.</p>

<p>In other words</p>

<pre class=""lang-js prettyprint-override""><code>@NgModule({
  imports: [
    ModuleB.forRoot( /* use loggerLikeConsole from below */ )
  ],
  declarations: [
  ],
  exports: [
  ]
})
export class ModuleA {
  static forRoot(loggerLikeConsole: Console): ModuleWithProviders {
    //...
  }
}
</code></pre>

<p>Can this be done? It seems like it should be possible. Maybe I am missing something simple.</p>
",<angular><typescript><module>
56096617,How to copy Log4J output to a string?,"<p>I am using IntelliJ and Java.
I want to copy the output of the running program to a string.
This solution must work both locally in IntelliJ and in a Jenkins job.</p>

<p>For example, my running console output looks like this:</p>

<pre><code>log4j:ERROR Could not find value for key log4j.appender.stdot

log4j:ERROR Could not instantiate appender named ""stdot"". log4j:ERROR

Could not find value for key log4j.appender.stdout log4j:ERROR Could
not instantiate appender named ""stdout"". [1;34m2019-05-12 08:17:38
Property file env/application.properties parsed successfully[0m
</code></pre>

<p>I want to copy all of this log to a string.
I've tried numerous solutions but none of them have worked.</p>
",<java><logging><log4j>
62327700,System is computationally singular using mlogit in R,"<p>I am conducting multinomial logistic regressions. They seem to work for all variables except for the price variable, where I get the following error:</p>

<pre><code>reg.M &lt;- mlogit::mlogit(formula = value ~ 1 | price, data = listDatasets[[2]])

Error in solve.default(H, g[!fixed]) : 
  system is computationally singular: reciprocal condition number = 7.4671e-18
</code></pre>

<p>That is my the head of the dataset used (I have 15 like these, with different prices):</p>

<pre><code>&gt; head(listDatasets[[2]])
             index Age ScoreEnvAtt MoneyInvested Gender Beliefs_eff_Green Beliefs_eff_ESG Beliefs_eff_Comp Beliefs_perf_ESG Beliefs_perf_Green Beliefs_perf_Comp Guilt Social.Altruistic Biospheric Egoistic DummyMedium
1.SS_Green_1     1  26         4.2            13      2                 4               3                3                2                  3                 2    71          6.000000   6.000000        5           1
1.SS_Green_2     1  26         4.2            13      2                 4               3                3                2                  3                 2    71          6.000000   6.000000        5           1
1.SS_Green_3     1  26         4.2            13      2                 4               3                3                2                  3                 2    71          6.000000   6.000000        5           1
1.SS_Green_4     1  26         4.2            13      2                 4               3                3                2                  3                 2    71          6.000000   6.000000        5           1
2.SS_Green_1     2  30         4.8             2      2                 4               3                4                2                  3                 3    26          6.666667   5.333333        5           1
2.SS_Green_2     2  30         4.8             2      2                 4               3                4                2                  3                 3    26          6.666667   5.333333        5           1
             DummyHigh CompensationGroup Past_compensation Knowledge_CO2   variable value price
1.SS_Green_1         0            Group1                 2             1 SS_Green_1 FALSE   1.5
1.SS_Green_2         0            Group1                 2             1 SS_Green_2 FALSE   1.5
1.SS_Green_3         0            Group1                 2             1 SS_Green_3 FALSE   1.5
1.SS_Green_4         0            Group1                 2             1 SS_Green_4  TRUE   1.3
2.SS_Green_1         0            Group2                 2             2 SS_Green_1 FALSE   1.5
2.SS_Green_2         0            Group2                 2             2 SS_Green_2 FALSE   1.5
</code></pre>

<p>I checked the other threads on this error already but can not find a solution to my problem. Any suggestions? Thanks!</p>

<p>Edit: I tried to do it with <code>multinom</code> instead of <code>mlogit</code>. It does not seem to recognize the levels of the dependent variable.</p>

<pre><code>test &lt;- multinom(value ~ price, listDatasets[[2]])
</code></pre>

<p>summary(test)</p>

<pre><code>    &gt; summary(test)
Call:
multinom(formula = value ~ price, data = listDatasets[[2]])

Coefficients:
               Values Std. Err.
(Intercept)  25.77925  1.464741
price       -18.86853  1.037180

Residual Deviance: 653.8391 
AIC: 657.8391
</code></pre>

<p>Edit 2: </p>

<pre><code>dput(head(data_long))
structure(list(Pride = c(17, 71, 1, 50, 0, 13), Guilt = c(71, 
26, 89, 50, 100, 13), Shame = c(36, 77, 5, 50, 67, 8), Joy = c(12, 
50, 0, 50, 30, 37), Attitudes1 = c(6, 5, 7, 5, 7, 5), Attitudes2 = c(5, 
7, 3, 4, 5, 3), Attitudes3 = c(6, 6, 7, 6, 7, 6), Attitudes4 = c(5, 
3, 5, 5, 6, 6), Attitudes5 = c(4, 7, 6, 6, 5, 6), Attitudes6 = c(5, 
7, 3, 7, 7, 6), Attitudes7 = c(3, 4, 1, 3, 1, 6), Attitudes8 = c(3, 
4, 5, 6, 7, 2), Attitudes9 = c(2, 3, 7, 4, 7, 6), Attitudes10 = c(3, 
2, 5, 4, 7, 6), Concern1 = c(6, 4, 7, 6, 7, 6), Concern2 = c(6, 
6, 7, 6, 7, 6), Concern3 = c(5, 5, 7, 6, 4, 6), Concern4 = c(6, 
6, 5, 6, 4, 5), Concern5 = c(6, 7, 7, 6, 4, 5), Concern6 = c(6, 
6, 7, 6, 5, 6), Concern7 = c(6, 6, 7, 6, 7, 6), Concern8 = c(4, 
4, 5, 6, 3, 6), Concern9 = c(6, 7, 6, 6, 7, 7), Beliefs_perf_ESG = c(2, 
2, 3, 2, 3, 2), Beliefs_perf_Comp = c(2, 3, 2, 3, 3, 2), Beliefs_perf_Green = c(3, 
3, 3, NA, 3, 2), Beliefs_eff_ESG = c(3, 3, 4, 3, 4, 3), Beliefs_eff_Comp = c(3, 
4, 2, 4, 2, 3), Beliefs_eff_Green = c(4, 4, 5, 5, 5, 3), Eval_Ego = c(3, 
2, 3, 4, 2, 3), Eval_Nature1 = c(3, 3, 3, 4, 2, 2), Eval_Nature2 = c(4, 
4, 4, 4, 2, 3), Eval_Social = c(3, 2, 4, 4, 2, 3), Reforestation = c(2, 
1, 1, 2, 2, 3), Renewable_Energy = c(1, 2, 3, 1, 1, 1), Efficient_Energy = c(3, 
4, 4, 3, 3, 2), Methane = c(4, 3, 2, 4, 4, 4), France = c(3, 
3, 1, 1, 3, 2), Europe = c(2, 2, 3, 3, 2, 3), Development = c(1, 
1, 2, 2, 1, 1), Co_benefits = c(5, 4, 5, 3, 4, 4), Poverty = c(1, 
1, 2, 2, 1, 1), Health = c(4, 2, 4, 1, 3, 3), Biodiversity = c(2, 
4, 1, 3, 2, 2), Equality = c(3, 5, 5, 5, 5, 5), Economic_Growth = c(5, 
3, 3, 4, 4, 4), Knowledge_CO2 = c(1, 2, 3, 2, 2, 2), Past_compensation = c(2, 
2, 1, 2, 1, 2), Age = c(26, 30, 30, 30, 21, 40), Gender = c(2, 
2, 2, 2, 2, 2), MoneyInvested = c(13, 2, 1, 3, 13, 1), Investment_Experience = c(2, 
1, 1, 1, 2, 1), Participant_s_ID = c(""1234asdf"", ""Password04"", 
""hiquet8350"", ""masmas2121"", ""1712flju"", ""Lemurien4555""), Compensationproject1 = c(1, 
NA, NA, 1, NA, 1), Compensationproject2 = c(NA, 1, 1, NA, NA, 
NA), Compensationproject3 = c(NA, NA, NA, NA, 1, NA), FL_42_DO_ChoiceExperiment1 = c(6, 
14, 3, 13, 10, 7), FL_42_DO_ChoiceExperiment2 = c(3, 1, 4, 6, 
13, 2), FL_42_DO_ChoiceExperiment3 = c(7, 10, 1, 7, 11, 13), 
    FL_42_DO_ChoiceExperiment4 = c(11, 15, 5, 2, 4, 11), FL_42_DO_ChoiceExperiment5 = c(14, 
    7, 2, 11, 2, 10), FL_42_DO_ChoiceExperiment6 = c(2, 11, 8, 
    15, 5, 6), FL_42_DO_ChoiceExperiment7 = c(1, 6, 6, 12, 14, 
    1), FL_42_DO_ChoiceExperiment8 = c(10, 2, 14, 5, 9, 5), FL_42_DO_ChoiceExperiment9 = c(4, 
    8, 13, 1, 1, 8), FL_42_DO_ChoiceExperiment10 = c(12, 5, 7, 
    14, 6, 3), FL_42_DO_ChoiceExperiment11 = c(15, 13, 10, 10, 
    12, 14), FL_42_DO_ChoiceExperiment12 = c(13, 3, 12, 8, 7, 
    9), FL_42_DO_ChoiceExperiment13 = c(9, 9, 11, 9, 8, 15), 
    FL_42_DO_ChoiceExperiment14 = c(8, 12, 9, 3, 3, 12), FL_42_DO_ChoiceExperiment15 = c(5, 
    4, 15, 4, 15, 4), ScoreEnvAtt = c(4.2, 4.8, 4.9, 5, 5.9, 
    5.2), Eval_NatureScore = c(3.5, 3.5, 3.5, 4, 2, 2.5), Social.Altruistic = c(6, 
    6.66666666666667, 6, 6, 5, 5.66666666666667), Biospheric = c(6, 
    5.33333333333333, 7, 6, 7, 6), Egoistic = c(5, 5, 6.33333333333333, 
    6, 4, 6), GroupEnvAtt = structure(c(2L, 2L, 2L, 2L, 2L, 2L
    ), .Label = c(""low"", ""medium"", ""high""), class = ""factor""), 
    DummyMedium = structure(c(2L, 2L, 2L, 2L, 2L, 2L), .Label = c(""0"", 
    ""1""), class = ""factor""), CompensationGroup = structure(c(1L, 
    2L, 2L, 1L, 3L, 1L), .Label = c(""Group1"", ""Group2"", ""Group3""
    ), class = ""factor""), ID = structure(1:6, .Label = c(""1"", 
    ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11"", ""12"", 
    ""13"", ""14"", ""15"", ""16"", ""17"", ""18"", ""19"", ""20"", ""21"", ""22"", 
    ""23"", ""24"", ""25"", ""26"", ""27"", ""28"", ""29"", ""30"", ""31"", ""32"", 
    ""33"", ""34"", ""35"", ""36"", ""37"", ""38"", ""39"", ""40"", ""41"", ""42"", 
    ""43"", ""44"", ""45"", ""46"", ""47"", ""48"", ""49"", ""50"", ""51"", ""52"", 
    ""53"", ""54"", ""55"", ""56"", ""57"", ""58"", ""59"", ""60"", ""61"", ""62"", 
    ""63"", ""64"", ""65"", ""66"", ""67"", ""68"", ""69"", ""70"", ""71"", ""72"", 
    ""73"", ""74"", ""75"", ""76"", ""77"", ""78"", ""79"", ""80"", ""81"", ""82"", 
    ""83"", ""84"", ""85"", ""86"", ""87"", ""88"", ""89"", ""90"", ""91"", ""92"", 
    ""93"", ""94"", ""95"", ""96"", ""97"", ""98"", ""99"", ""100"", ""101"", ""102"", 
    ""103"", ""104"", ""105"", ""106"", ""107"", ""108"", ""109"", ""110"", ""111"", 
    ""112"", ""113"", ""114"", ""115"", ""116"", ""117"", ""118"", ""119"", ""120"", 
    ""121"", ""122"", ""123"", ""124"", ""125"", ""126"", ""127"", ""128"", ""129"", 
    ""130"", ""131"", ""132"", ""133"", ""134"", ""135"", ""136"", ""137"", ""138"", 
    ""139"", ""140"", ""141"", ""142"", ""143"", ""144"", ""145"", ""146"", ""147"", 
    ""148"", ""149"", ""150"", ""151"", ""152"", ""153"", ""154"", ""155"", ""156"", 
    ""157"", ""158"", ""159"", ""160"", ""161"", ""162"", ""163"", ""164"", ""165"", 
    ""166"", ""167"", ""168"", ""169"", ""170"", ""171"", ""172"", ""173"", ""174"", 
    ""175"", ""176"", ""177"", ""178"", ""179"", ""180"", ""181"", ""182"", ""183"", 
    ""184"", ""185"", ""186"", ""187"", ""188"", ""189"", ""190"", ""191"", ""192"", 
    ""193"", ""194"", ""195"", ""196"", ""197"", ""198"", ""199"", ""200"", ""201"", 
    ""202"", ""203"", ""204"", ""205"", ""206"", ""207"", ""208"", ""209"", ""210"", 
    ""211"", ""212"", ""213"", ""214"", ""215"", ""216"", ""217"", ""218"", ""219"", 
    ""220"", ""221"", ""222"", ""223"", ""224"", ""225"", ""226"", ""227"", ""228"", 
    ""229"", ""230"", ""231"", ""232"", ""233"", ""234"", ""235"", ""236"", ""237"", 
    ""238"", ""239"", ""240"", ""241"", ""242"", ""243"", ""244"", ""245"", ""246"", 
    ""247""), class = ""factor""), ChoiceSet = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c(""Baseline_Choice_1"", ""Baseline_Choice_2"", 
    ""Baseline_Choice_3"", ""Baseline_Choice_4"", ""SS_Green_1"", ""SS_Green_2"", 
    ""SS_Green_3"", ""SS_Green_4"", ""SS_Green_ESG_1"", ""SS_Green_ESG_2"", 
    ""SS_Green_ESG_3"", ""SS_Green_ESG_4"", ""SS_ESG_1"", ""SS_ESG_2"", 
    ""SS_ESG_3"", ""SS_ESG_4"", ""SS_Comp_Green_1"", ""SS_Comp_Green_2"", 
    ""SS_Comp_Green_3"", ""SS_Comp_Green_4"", ""SS_Comp_ESG_1"", ""SS_Comp_ESG_2"", 
    ""SS_Comp_ESG_3"", ""SS_Comp_ESG_4"", ""SS_Comp_1"", ""SS_Comp_2"", 
    ""SS_Comp_3"", ""SS_Comp_4"", ""SS_All_1"", ""SS_All_2"", ""SS_All_3"", 
    ""SS_All_4"", ""WTP_All_1"", ""WTP_All_2"", ""WTP_All_3"", ""WTP_All_4"", 
    ""WTP_Comp_1"", ""WTP_Comp_2"", ""WTP_Comp_3"", ""WTP_Comp_4"", ""WTP_Comp_ESG_1"", 
    ""WTP_Comp_ESG_2"", ""WTP_Comp_ESG_3"", ""WTP_Comp_ESG_4"", ""WTP_Comp_Green_1"", 
    ""WTP_Comp_Green_2"", ""WTP_Comp_Green_3"", ""WTP_Comp_Green_4"", 
    ""WTP_ESG_1"", ""WTP_ESG_2"", ""WTP_ESG_3"", ""WTP_ESG_4"", ""WTP_ESG_Green_1"", 
    ""WTP_ESG_Green_2"", ""WTP_ESG_Green_3"", ""WTP_ESG_Green_4"", 
    ""WTP_Green_1"", ""WTP_Green_2"", ""WTP_Green_3"", ""WTP_Green_4""
    ), class = ""factor""), value = c(""Off"", ""Off"", ""Off"", ""Off"", 
    ""Off"", ""Off""), Choice = c(""Conventional"", ""Conventional"", 
    ""Conventional"", ""Conventional"", ""Conventional"", ""Conventional""
    ), price = c(1.5, 1.5, 1.5, 1.5, 1.5, 1.5)), row.names = c(NA, 
-6L), class = c(""tbl_df"", ""tbl"", ""data.frame""))
</code></pre>
",<r><mlogit>
47291089,"Error: no ""view"" mailcap rules found for type ""application/pdf"" pythonanywhere server log","<p>I'm trying to Use lolviz and graphviz to visualize data structures, but there is no output. This is the error I get in server logs: groupn.pythonanywhere.com.server.log</p>

<pre class=""lang-none prettyprint-override""><code>Warning: 2017-11-14 16:32:24 Illegal attribute sides in &lt;TD&gt; - ignored 2017-11-14 16:32:24   
Warning: 2017-11-14 16:32:24 Illegal attribute sides in &lt;TD&gt; - ignored 2017-11-14 16:32:24 in label of node node140165832004944 2017-11-14 16:32:24   
Warning: 2017-11-14 16:32:24 Illegal attribute sides in &lt;TD&gt; - ignored 2017-11-14 16:32:24 in label of node node140165832024136 2017-11-14 16:32:24   
Error: no ""view"" mailcap rules found for type ""application/pdf"" 2017-11-14 16:32:24 /usr/bin/xdg-open: 461: /usr/bin/xdg-open: 2017-11-14 16:32:24   
 links2: not found
</code></pre>

<p>This is where the function is in my views.py</p>

<pre><code>elif 'show' in request.POST:
                data = callviz(s).view(filename=None, directory=None, cleanup=True)
                return render(request, 'file/stacks.html', {'form': form, 'data': data})
</code></pre>
",<python><html><django><pythonanywhere>
9745105,Where my log messages?,"<p>I have source file like this:</p>

<pre><code>...
import android.util.Log;
...
public class MyActivity extends Activity
{
    public static Activity activity = null;
    private static final String TAG = ""WorldDetermine"";
    private Camera mCamera;
    private CameraPreview mPreview;
    public final int cameraId = 0;

    @Override
    public void onCreate(Bundle savedInstanceState) {
    Log.d(""myTag"", ""onCreate started!"");
    Log.v(""blah"", ""blah blah"");
        super.onCreate(savedInstanceState);
        setContentView(R.layout.main); ...
</code></pre>

<p>and trying to get log messages by <code>logcat</code>. Something like this:</p>

<pre><code>adb -s emulator-5554 logcat myTag:D blah:v *:S
</code></pre>

<p>but have only blank output(grep isn't find this too). My project compiled by <code>ant debug</code> properly but I have problem on last step(Can the problem be caused indirectly by this?):</p>

<pre><code>debug:

BUILD FAILED
/home/psct/development/android-sdk-linux/tools/ant/build.xml:887: The following error occurred while executing this line:
/home/psct/development/android-sdk-linux/tools/ant/build.xml:342: The following error occurred while executing this line:
/home/psct/development/android-sdk-linux/tools/ant/build.xml:334: Problem: failed to create task or type propertyfile
Cause: the class org.apache.tools.ant.taskdefs.optional.PropertyFile was not found.
        This looks like one of Ant's optional components.
Action: Check that the appropriate optional JAR exists in
        -/usr/share/ant-core/lib
        -/root/.ant/lib
        -a directory added on the command line with the -lib argument

Do not panic, this is a common problem.
The commonest cause is a missing JAR.

This is not a bug; it is a configuration problem


Total time: 4 seconds
</code></pre>
",<android><logging>
22972810,SWI-Prolog Editor for OS X,"<p>I was searching for a SWI-Prolog editor for Mac OS X but i could not find one, so is there one or do I have to use another editor to build Prolog files?</p>

<p>Thanks</p>
",<macos><prolog><swi-prolog>
61347742,pino loses log entries on process.exit(),"<p>When my program shuts down via <code>process.exit()</code> (maybe also by some signal), <a href=""https://www.npmjs.com/package/pino"" rel=""nofollow noreferrer"">pino</a> loses some log entries because it is not properly flushing them.</p>

<p>Triggering a manual flush does not help.</p>

<p>I am using pino 6.2.0.</p>

<p><strong>How can I prevent log entries from getting lost?</strong></p>

<pre class=""lang-js prettyprint-override""><code>const pino = require(""pino"");

const p = pino();

process.on(""exit"", () =&gt; {
    console.log(""FLUSH"");
    p.flush();
});

p.info(""A""); // logged
p.info(""B""); // NOT logged

process.exit(1);
</code></pre>

<p><strong>Back story:</strong><br />
I was missing some dependencies in my NestJS module and configured NestJS to use my pino logger wrapper like this:</p>

<pre class=""lang-js prettyprint-override""><code>const app = await NestFactory.create&lt;NestExpressApplication&gt;(AppModule, {
    logger: new PinoLoggerService(),
});
</code></pre>

<p>NestJS was just exiting (using <code>process.exit()</code>) without telling me what was wrong.
Removing the <code>logger</code> option made NestJS print the offending module in all details.</p>
",<javascript><node.js><logging><flush><pinojs>
969085,Which log4j facade to choose?,"<p>Essentially I'm looking for something with the same behavior, configuration, logging levels as log4j, but with some of the missing functionality (e.g. formatted logging — see <a href=""https://stackoverflow.com/questions/920458/"">here</a> and <a href=""https://stackoverflow.com/questions/946730/"">here</a> for related SO threads.)</p>

<p>Current nominees are <a href=""http://www.slf4j.org/"" rel=""nofollow noreferrer"">slf4j</a> and <a href=""http://code.google.com/p/log5j/"" rel=""nofollow noreferrer"">log5j</a>.</p>
",<java><logging><log4j><string-formatting>
71250698,"log(1000, 100) does not return 1.5","<p>When I run this code:</p>
<pre class=""lang-php prettyprint-override""><code>$value = log(1000, 100);

echo $value;

if ($value == 1.5) {
    echo 'Equal';
} else {
    echo 'Not Equal';
}
</code></pre>
<p>I see <code>1.5Not Equal</code>. This is very strange because <code>log(1000, 100)</code> does return <code>1.5</code>, but it does not match the if statement.</p>
<p>Why does PHP do this?</p>
",<php><logarithm>
77147386,"Mongoose+NestJS - query values showing as null in mongoose logs, unable to filter anything because of this","<p>I've run into a strange scenario after updating mongoose version, no find or where queries are working.
I ran mongoose in debug mode to check the logs and found that all the filter values passed are going as null in mongoose logs.</p>
<p><a href=""https://i.stack.imgur.com/JsplH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JsplH.png"" alt=""Highlighted the query written in code and the one picked by Mongoose"" /></a></p>
<p>Did anyone face a similar situation before? Please help.</p>
",<node.js><mongodb><mongoose><nestjs>
277857,How to write something to .txt log file from .aspx page (c#),"<p>This code does not seem to compile, I just need to write something to a small log text file (a new row to end of file).</p>

<pre><code>&lt;%@ Import Namespace=""System.IO"" %&gt;

void Page_Load( object sender, EventArgs e ){

    FileSystem myFileSystem = new FileSystem();
    myFileSystem.WriteAllText(logFile, hash, false);
</code></pre>
",<c#><.net><logging><asp.net>
66745417,HBase logcleaner does not delete the oldWALs files,"<p>In my lab, HBase archive Write Ahead Logs i.e. oldWALs files are not deleted and oldWALs directory is growing quickly in terabyte.</p>
<pre><code>8.1 K    24.4 K  /hbase/.hbase-snapshot
0        0       /hbase/.hbck
0        0       /hbase/.tmp
3.6 K    10.7 K  /hbase/MasterProcWALs
900.3 M  7.1 G   /hbase/WALs
3.4 G    10.3 G  /hbase/archive
0        0       /hbase/corrupt
938.7 G  2.8 T   /hbase/data
42       84      /hbase/hbase.id
7        14      /hbase/hbase.version
4.9 T    4.9 T   /hbase/oldWALs
0        0       /hbase/staging

</code></pre>
<p>Tried below options to clean up; but no luck.</p>
<ol>
<li>Updated replication is false at hbase master and restarted</li>
<li>Decrease ttl to 1sec</li>
<li>No peers</li>
<li>Multiple times restarted the HBase component.</li>
</ol>
",<hdfs><hbase><hadoop2><cloudera-cdh>
46079877,How to download Sony Lifelog Sleep data?,"<p>Now that the Sony LifeLog API is <a href=""https://stackoverflow.com/questions/44604451/regarding-sony-s-lifelog-api-close-down/44817499#44817499"">shut down</a>, I'm trying to figure out how to get access to my sleep data (e.g. daily hours slept, wake up time, bedtime).</p>

<hr>

<p>In the <a href=""https://developers.google.com/oauthplayground"" rel=""nofollow noreferrer"">OAuth playground</a>, I tried sending queries to Google Fit for Sony Data, but I'm getting back an empty <code>point</code> array no matter what I try.</p>

<pre><code>https://www.googleapis.com/fitness/v1/users/me/dataSources/raw:com.google.activity.segment:com.sonymobile.hostapp.everest:Sony Mobile Communications Inc.:SWR12:24234b96:/datasets/1397513334728708316-1504711909728708316
</code></pre>

<p>(This date range should be from <a href=""https://www.wolframalpha.com/input/?i=1397513334728708316%20ns%20%2B%20january%201%201970"" rel=""nofollow noreferrer"">April 14, 2014</a> until today.)</p>

<hr>

<p>I tried with the other datasources I found, <code>raw:com.google.heart_rate.bpm:com.sonymobile.hostapp.everest:Sony Mobile Communications Inc.:SWR12:24234b96:</code> or <code>raw:com.google.step_count.delta:com.sonymobile.hostapp.everest:Sony Mobile Communications Inc.:SWR12:24234b96:</code>, but those both returned empty data as well.</p>

<p>Even though these <code>sonymobile</code> datasources are return from <code>https://developers.google.com/fit/rest/v1/reference/users/dataSources/list</code>, when I query them directly I get a 404:</p>

<pre><code>https://www.googleapis.com/fitness/v1/users/me/dataSources/raw:com.google.activity.segment:com.sonymobile.hostapp.everest:Sony Mobile Communications Inc.:SWR12:24234b96:
</code></pre>

<p>(I can see other dataSources are valid though by requesting e.g. <code>https://www.googleapis.com/fitness/v1/users/me/dataSources/derived:com.google.step_count.delta:com.google.android.gms:estimated_steps</code>)</p>

<hr>

<p>How can I get download my sleep data for the last year?</p>
",<google-fit><sony-lifelog-api>
58934222,RequestLogger - Waiting for requests[0].response,"<p>When logging requests using the RequestLogger, the requests array records the immediate response which isn't always present if the response takes more than a few seconds to return.</p>

<p>Is there a way to wait for the statusCode to return before the request gets logged, or a way to get the statusCode for the specified request when it has been returned?</p>

<p>Using <code>await t.expect(logger.contains(r =&gt; r.response.statusCode === 200)).ok();</code> didn't work for me.</p>
",<testing><xmlhttprequest><automated-tests><e2e-testing><testcafe>
32352208,spring restful web service logging,"<p>I implemented Spring RESTful Web Service using this tutorial: <a href=""https://spring.io/guides/gs/rest-service/"" rel=""nofollow"">https://spring.io/guides/gs/rest-service/</a>. I added dependencies for log4j in pom.xml and log4j.properties file in src/main/resources folder. Now I expect logging to be done into log file as stated inthe log4j.properties file instead of to STDOUT. However, logging goes only to STDOUT. How can I fix tis to print log messages to log file?  </p>
",<spring><rest><logging>
19651337,what is error id 220 while validating topology in ArcGis10.2?,"<p><strong>I am getting ""validate topology failed"" while validating in ArcGis 10.2(Trial Version)</strong></p>

<p><img src=""https://i.stack.imgur.com/dUxsl.png"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/0FvrF.png"" alt=""enter image description here""></p>

<p><strong>Please tell me what this error is and how to rectify it ?</strong></p>
",<topology><validating>
10640539,How to get Rails Heroku log backtrace from Heroku error,"<p>I using rails 3.2.3 on Heroku Bamboo stack. I got this error last night from my logs but can't diagnose exactly where and why its occurring. How can I get the entire backtrace of the error from my heroku logs?</p>

<pre><code>app[web.2]: !! Unexpected error while processing request: can't modify frozen array
heroku[router]: Error H13 (Connection closed without response) -&gt; GET
</code></pre>
",<ruby-on-rails><ruby><ruby-on-rails-3><heroku><rubygems>
57458163,Kubernetes - Filebeat stops sending/picking up logs. FIlebeat works after restarting the filebeat pods,"<p>I am running one filebeat (version - 6.4.1) per node in kubernetes cluster with 1 master node and 3 worker nodes.</p>

<p>And a single logstash, elastic and Kibana for the entire cluster.</p>

<p>While the pods are up and running successfully, filebeat is unable to pull/send the logs to the logstash.</p>

<p>If I restart the filebeat pods then the logs can be seen from Kibana.</p>

<p>The error I see from filebeat logs are:</p>

<pre><code>ERROR kubernetes/watcher.go:154 kubernetes: Watching API error EOF
</code></pre>

<p>Found a similar issue in ELK forums</p>

<p><a href=""https://discuss.elastic.co/t/kubernetes-filebeat-stops-sending-picking-up-logs/128578"" rel=""nofollow noreferrer"">https://discuss.elastic.co/t/kubernetes-filebeat-stops-sending-picking-up-logs/128578</a>. It is said that filebeat of version 6.3.0 has a fix for this.</p>

<p>Component Versions:</p>

<p>cluster - 4 nodes (1 master &amp; 3 workers)</p>

<p>master - 4 core &amp; 8 GB RAM</p>

<p>worker - 16 core &amp; 32 GB RAM</p>

<p>host OS - Centos: 7</p>

<p>container OS - alpine: 3.9.4</p>

<p>k8s - v1.13.1</p>

<p>docker - 18.09.0</p>

<p>filebeat - 6.4.1</p>

<p>logstash - 6.3.1</p>

<p>elasticsearch - 6.5.4</p>

<p>kibana - 6.5.4</p>

<p>I am facing the same issue in filebeat 6.4.1 > 6.3.0</p>

<p>Please suggest me if I need to make any changes in the ELK configurations.</p>
",<kubernetes><logstash><filebeat>
19198421,Android - LogCat gives a android.os.NetworkOnMainThreadException,"<p>I've tried to create a program which allows users to send an HTTP POST to a PHP script using the following code. I get a android.os.NetworkOnMainThreadException when I click on the send button. (btnSend).</p>

<pre><code>package com.naveed.post;

import java.io.IOException;
import java.io.UnsupportedEncodingException;
import java.util.ArrayList;
import java.util.List;

import org.apache.http.HttpResponse;
import org.apache.http.NameValuePair;
import org.apache.http.client.ClientProtocolException;
import org.apache.http.client.HttpClient;
import org.apache.http.client.entity.UrlEncodedFormEntity;
import org.apache.http.client.methods.HttpPost;
import org.apache.http.impl.client.DefaultHttpClient;
import org.apache.http.message.BasicNameValuePair;

import android.app.Activity;
import android.os.Bundle;
import android.util.Log;
import android.view.View;
import android.widget.Button;
import android.widget.EditText;
import android.widget.TextView;

public class MainActivity extends Activity {

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        // Creating HTTP client
        final HttpClient httpClient = new DefaultHttpClient();
        // Creating HTTP Post
        final HttpPost httpPost = new HttpPost(""http://10.0.2.2/android_post/test.php"");
        Button send = (Button)findViewById(R.id.btnSend);
        send.setOnClickListener(new View.OnClickListener() {

            @Override
            public void onClick(View v) {
                // TODO Auto-generated method stub
                EditText message = (EditText)findViewById(R.id.textMessage);

                String msg = message.getText().toString();

                   // Building post parameters
                // key and value pair
                List&lt;NameValuePair&gt; nameValuePair = new ArrayList&lt;NameValuePair&gt;(2);
                nameValuePair.add(new BasicNameValuePair(""message"", msg));

                // Url Encoding the POST parameters
                try {
                    httpPost.setEntity(new UrlEncodedFormEntity(nameValuePair));
                } catch (UnsupportedEncodingException e) {
                    // writing error to Log
                    e.printStackTrace();
                }

                // Making HTTP Request
                try {
                    HttpResponse response = httpClient.execute(httpPost);

                    // writing response to log
                    Log.d(""Http Response:"", response.toString());
                } catch (ClientProtocolException e) {
                    // writing exception to log
                    e.printStackTrace();
                } catch (IOException e) {
                    // writing exception to log
                    e.printStackTrace();

                }
            }
        });

    }
}
</code></pre>

<p>I know I have to use AsyncTask, so i tried. But I know I am doing it wrong. Any suggestions. My code is below:</p>

<pre><code>package com.naveed.post;

import java.io.IOException;
import java.io.UnsupportedEncodingException;
import java.util.ArrayList;
import java.util.List;

import org.apache.http.HttpResponse;
import org.apache.http.NameValuePair;
import org.apache.http.client.ClientProtocolException;
import org.apache.http.client.HttpClient;
import org.apache.http.client.entity.UrlEncodedFormEntity;
import org.apache.http.client.methods.HttpPost;
import org.apache.http.impl.client.DefaultHttpClient;
import org.apache.http.message.BasicNameValuePair;

import android.app.Activity;
import android.os.AsyncTask;
import android.os.Bundle;
import android.util.Log;
import android.view.View;
import android.widget.Button;
import android.widget.EditText;
import android.widget.TextView;

public class MainActivity extends Activity {


    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);


        Button send = (Button)findViewById(R.id.btnSend);
        send.setOnClickListener(new View.OnClickListener() {

            @Override
            public void onClick(View v) {
                // TODO Auto-generated method stub

                 ArrayList&lt;NameValuePair&gt; nameValuePair = new ArrayList&lt;NameValuePair&gt;(2);
                 EditText message = (EditText)findViewById(R.id.textMessage);

                    String msg = message.getText().toString();

                    nameValuePair.add(new BasicNameValuePair(""message"", msg));


            }
        });

    }

   class doThePost extends AsyncTask&lt;Void, Void, Void&gt;{

        protected Void doInBackground(ArrayList&lt;NameValuePair&gt;... nameValuePair) {
            // TODO Auto-generated method stub
            ArrayList&lt;NameValuePair&gt; nvPairs = nameValuePair[0];
             HttpClient httpClient = new DefaultHttpClient();
                // Creating HTTP Post
             HttpPost httpPost = new HttpPost(""http://10.0.2.2/android_post/test.php"");
                // Url Encoding the POST parameters
                try {
                    httpPost.setEntity(new UrlEncodedFormEntity(nvPairs));
                } catch (UnsupportedEncodingException e) {
                    // writing error to Log
                    e.printStackTrace();
                }

                // Making HTTP Request
                try {
                    HttpResponse response = httpClient.execute(httpPost);

                    // writing response to log
                    Log.d(""hello"", ""done"");
                    Log.d(""Http Response:"", response.toString());
                } catch (ClientProtocolException e) {
                    // writing exception to log
                    e.printStackTrace();
                } catch (IOException e) {
                    // writing exception to log
                    e.printStackTrace();

                }
                Log.d(""hello"", ""done"");
            return null;
        }

        @Override
        protected Void doInBackground(Void... params) {
            // TODO Auto-generated method stub
            return null;
        }




        }

}
</code></pre>
",<android-networking>
12482572,Logging which template is being loaded in rails,"<p>Lets say I haven't defined any method for a particular action in the rails Controller (like for /users there is no method, and it will directly load up the template). Is there a way I can modify the Logger (I'm using ActiveSupport::BufferedLogger) to emit a log whenever a template is loaded?</p>

<p>EDIT: The reason why I ask this is that I am refactoring the code and an exception is being raised from the template code. Due to that there is no stack trace available and I am not able to figure out where exactly the error is being raised from (more importantly, I don't know which template is being loaded).</p>

<p>EDIT2:</p>

<pre><code>activesupport (3.1.1) lib/active_support/whiny_nil.rb:48:in `method_missing'
cancan (1.6.8) lib/cancan/model_adapters/active_record_adapter.rb:69:in `tableized_conditions'
activesupport (3.1.1) lib/active_support/dependencies.rb:456:in `inject'
cancan (1.6.8) lib/cancan/model_adapters/active_record_adapter.rb:67:in `each'
cancan (1.6.8) lib/cancan/model_adapters/active_record_adapter.rb:67:in `inject'
cancan (1.6.8) lib/cancan/model_adapters/active_record_adapter.rb:67:in `tableized_conditions'
cancan (1.6.8) lib/cancan/model_adapters/active_record_adapter.rb:57:in `conditions'
cancan (1.6.8) lib/cancan/model_adapters/active_record_adapter.rb:94:in `database_records'
cancan (1.6.8) lib/cancan/model_additions.rb:23:in `accessible_by'
cancan (1.6.8) lib/cancan/controller_resource.rb:81:in `load_collection'
cancan (1.6.8) lib/cancan/controller_resource.rb:34:in `load_resource'
cancan (1.6.8) lib/cancan/controller_resource.rb:25:in `load_and_authorize_resource'
cancan (1.6.8) lib/cancan/controller_resource.rb:10:in `send'
cancan (1.6.8) lib/cancan/controller_resource.rb:10:in `_callback_before_1418'
activesupport (3.1.1) lib/active_support/callbacks.rb:448:in `_run__482750358__process_action__686174538__callbacks'
activesupport (3.1.1) lib/active_support/callbacks.rb:386:in `send'
activesupport (3.1.1) lib/active_support/callbacks.rb:386:in `_run_process_action_callbacks'
activesupport (3.1.1) lib/active_support/callbacks.rb:81:in `send'
activesupport (3.1.1) lib/active_support/callbacks.rb:81:in `run_callbacks'
actionpack (3.1.1) lib/abstract_controller/callbacks.rb:17:in `process_action'
actionpack (3.1.1) lib/action_controller/metal/rescue.rb:17:in `process_action'
actionpack (3.1.1) lib/action_controller/metal/instrumentation.rb:30:in `process_action'
activesupport (3.1.1) lib/active_support/notifications.rb:53:in `instrument'
activesupport (3.1.1) lib/active_support/notifications/instrumenter.rb:21:in `instrument'
activesupport (3.1.1) lib/active_support/notifications.rb:53:in `instrument'
actionpack (3.1.1) lib/action_controller/metal/instrumentation.rb:29:in `process_action'
actionpack (3.1.1) lib/action_controller/metal/params_wrapper.rb:201:in `process_action'
activerecord (3.1.1) lib/active_record/railties/controller_runtime.rb:18:in `process_action'
actionpack (3.1.1) lib/abstract_controller/base.rb:121:in `process'
actionpack (3.1.1) lib/abstract_controller/rendering.rb:45:in `process'
actionpack (3.1.1) lib/action_controller/metal.rb:193:in `dispatch'
actionpack (3.1.1) lib/action_controller/metal/rack_delegation.rb:14:in `dispatch'
actionpack (3.1.1) lib/action_controller/metal.rb:236:in `action'
actionpack (3.1.1) lib/action_dispatch/routing/route_set.rb:65:in `call'
actionpack (3.1.1) lib/action_dispatch/routing/route_set.rb:65:in `dispatch'
actionpack (3.1.1) lib/action_dispatch/routing/route_set.rb:29:in `call'
rack-mount (0.8.3) lib/rack/mount/route_set.rb:152:in `call'
rack-mount (0.8.3) lib/rack/mount/code_generation.rb:96:in `recognize'
rack-mount (0.8.3) lib/rack/mount/code_generation.rb:75:in `optimized_each'
rack-mount (0.8.3) lib/rack/mount/code_generation.rb:95:in `recognize'
rack-mount (0.8.3) lib/rack/mount/route_set.rb:141:in `call'
actionpack (3.1.1) lib/action_dispatch/routing/route_set.rb:532:in `call'
sass (3.2.1) lib/sass/./sass/plugin/rack.rb:54:in `call'
warden (1.2.1) lib/warden/manager.rb:35:in `call'
warden (1.2.1) lib/warden/manager.rb:34:in `catch'
warden (1.2.1) lib/warden/manager.rb:34:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/best_standards_support.rb:17:in `call'
rack (1.3.6) lib/rack/etag.rb:23:in `call'
rack (1.3.6) lib/rack/conditionalget.rb:25:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/head.rb:14:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/params_parser.rb:21:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/flash.rb:243:in `call'
rack (1.3.6) lib/rack/session/abstract/id.rb:195:in `context'
rack (1.3.6) lib/rack/session/abstract/id.rb:190:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/cookies.rb:331:in `call'
activerecord (3.1.1) lib/active_record/query_cache.rb:62:in `call'
activerecord (3.1.1) lib/active_record/connection_adapters/abstract/connection_pool.rb:477:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/callbacks.rb:29:in `call'
activesupport (3.1.1) lib/active_support/callbacks.rb:392:in `_run_call_callbacks'
activesupport (3.1.1) lib/active_support/callbacks.rb:81:in `send'
activesupport (3.1.1) lib/active_support/callbacks.rb:81:in `run_callbacks'
actionpack (3.1.1) lib/action_dispatch/middleware/callbacks.rb:28:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/reloader.rb:68:in `call'
rack (1.3.6) lib/rack/sendfile.rb:101:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/remote_ip.rb:48:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/show_exceptions.rb:47:in `call'
railties (3.1.1) lib/rails/rack/logger.rb:13:in `call'
rack (1.3.6) lib/rack/methodoverride.rb:24:in `call'
rack (1.3.6) lib/rack/runtime.rb:17:in `call'
rack (1.3.6) lib/rack/lock.rb:15:in `call'
actionpack (3.1.1) lib/action_dispatch/middleware/static.rb:53:in `call'
rack-cache (1.2) lib/rack/cache/context.rb:136:in `forward'
rack-cache (1.2) lib/rack/cache/context.rb:245:in `fetch'
rack-cache (1.2) lib/rack/cache/context.rb:185:in `lookup'
rack-cache (1.2) lib/rack/cache/context.rb:66:in `call!'
rack-cache (1.2) lib/rack/cache/context.rb:51:in `call'
railties (3.1.1) lib/rails/engine.rb:456:in `call'
railties (3.1.1) lib/rails/railtie/configurable.rb:30:in `send'
railties (3.1.1) lib/rails/railtie/configurable.rb:30:in `method_missing'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/rack/request_handler.rb:96:in `process_request'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_request_handler.rb:516:in `accept_and_process_next_request'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_request_handler.rb:274:in `main_loop'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/rack/application_spawner.rb:206:in `start_request_handler'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/rack/application_spawner.rb:171:in `send'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/rack/application_spawner.rb:171:in `handle_spawn_application'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/utils.rb:470:in `safe_fork'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/rack/application_spawner.rb:166:in `handle_spawn_application'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server.rb:357:in `__send__'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server.rb:357:in `server_main_loop'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server.rb:206:in `start_synchronously'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server.rb:180:in `start'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/rack/application_spawner.rb:129:in `start'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/spawn_manager.rb:253:in `spawn_rack_application'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server_collection.rb:132:in `lookup_or_add'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/spawn_manager.rb:246:in `spawn_rack_application'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server_collection.rb:82:in `synchronize'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server_collection.rb:79:in `synchronize'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/spawn_manager.rb:244:in `spawn_rack_application'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/spawn_manager.rb:137:in `spawn_application'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/spawn_manager.rb:275:in `handle_spawn_application'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server.rb:357:in `__send__'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server.rb:357:in `server_main_loop'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/lib/phusion_passenger/abstract_server.rb:206:in `start_synchronously'
/var/lib/passenger-standalone/3.0.17-x86-ruby1.8.7-linux-gcc4.4.6-1002/support/helper-scripts/passenger-spawn-server:99
</code></pre>
",<ruby-on-rails><logging>
59242988,Logstash exception while fetching incremental data from SQL Server,"<p>I am using LogStash 7.3.2 to fetch incremental data from SQL Server using this query:</p>

<pre><code>select * from mytable where lastupdatetimestamp &gt; :sql_last_value
</code></pre>

<p>I also have specified last_run_metadata_path in logstash config file.</p>

<p>It works fine but sometimes it is throwing an exception:-</p>

<blockquote>
  <p>Exception when executing JDBC query {:exception=>#
  
  <p>transition (daylight savings time 'gap'): 1942-09-01T00:00:00.000 (Asia/Kolkata)>}</p>
</blockquote>

<p>Why am I getting this exception and due to this exception it does not save last timestamp value and again it fetches duplicate records from SQL Server.</p>

<p>Any help regarding this would be highly appreciated.</p>
",<sql-server><logstash><logstash-jdbc>
19222636,Log when a row is deleted from a given table in MySQL,"<p>I have a MySQL-table that's accessed from different APIs. I would like to log when any rows are deleted from this table. Is this possible?</p>
",<mysql>
3570463,Data Privacy for Google Charts,"<p>We're looking at adding charts to our webapp. I recommended using a 3rd-party service such as Google Charts; this idea was rejected over fears about client data being passed to Google. </p>

<p><a href=""http://www.google.com/privacypolicy.html"" rel=""nofollow noreferrer"">Google's Privacy Policy</a> (which appears to apply to Charts) seems to preclude the abuse of our data, since it states that they require opt-in to share it with anyone. Still, I'm not sure of this.</p>

<p>Is there a legitimate concern here with respect to privacy/security of the data we send to Google?</p>
",<google-visualization><privacy-policy>
311408,Turning off hibernate logging console output,"<p>I'm using hibernate 3 and want to stop it from dumping all the startup messages to the console. I tried commenting out the stdout lines in log4j.properties but no luck. I've pasted my log file below. Also I'm using eclipse with the standard project structure and have a copy of log4j.properties in both the root of the project folder and the bin folder.</p>

<pre>### direct log messages to stdout ###
#log4j.appender.stdout=org.apache.log4j.ConsoleAppender
#log4j.appender.stdout.Target=System.out
#log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
#log4j.appender.stdout.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L - %m%n

### direct messages to file hibernate.log ###
log4j.appender.file=org.apache.log4j.FileAppender
log4j.appender.file.File=hibernate.log
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L - %m%n

### set log levels - for more verbose logging change 'info' to 'debug' ###

log4j.rootLogger=warn, stdout

#log4j.logger.org.hibernate=info
log4j.logger.org.hibernate=debug

### log HQL query parser activity
#log4j.logger.org.hibernate.hql.ast.AST=debug

### log just the SQL
#log4j.logger.org.hibernate.SQL=debug

### log JDBC bind parameters ###
log4j.logger.org.hibernate.type=info
#log4j.logger.org.hibernate.type=debug

### log schema export/update ###
log4j.logger.org.hibernate.tool.hbm2ddl=debug

### log HQL parse trees
#log4j.logger.org.hibernate.hql=debug

### log cache activity ###
#log4j.logger.org.hibernate.cache=debug

### log transaction activity
#log4j.logger.org.hibernate.transaction=debug

### log JDBC resource acquisition
#log4j.logger.org.hibernate.jdbc=debug

### enable the following line if you want to track down connection ###
### leakages when using DriverManagerConnectionProvider ###
#log4j.logger.org.hibernate.connection.DriverManagerConnectionProvider=trac5</pre>
",<java><hibernate><logging>
31830976,How to enable restkit logging in swift,"<p>In iOS I can enable restkit logging with:</p>

<pre><code>RKLogConfigureByName(""RestKit/Network*"", RKLogLevelTrace);
</code></pre>

<p>But, I can't find a solution to do the same in Swift</p>
",<ios><swift><restkit>
4450555,Can I neglect the input current to an analog pin on an 8 bit Microchip PIC12F683?,"<p>I'm trying to measure ambient brightness values with a CdS light-dependent resistor (R2 in the below diagram.) R1 is a known value, and the resistance of R2 has an inverse log relationship with the current ambient brightness.</p>

<p>I can use the voltage in the middle of the voltage divider to calculate the value of R2, and therefore the brightness, in software. I intend to use the A-D capabilities of my PIC chip to measure that voltage. Although CdS cells are inherently a bit imprecise, I'd like to get the best precision possible. Is the input current flowing into pin AN0 negligible?</p>

<pre><code>Vdd ---
     |
     R1           
     |          -|--|-
     +------ AN0-|IC|-
     |          -|--|-
     R2
     |
Vss ---
</code></pre>

<p>Bonus question - anyone know how I can linearize the inverse log response of my LDR? At 1 lux it's 1 megaohm, at 10 lux it's 100k, at 100 lux it's 10k etc. I need to calculate values as accurately as possible between 10 and 600 lux, so if I just plug it into my A-D I'm going to have to pick one end that has much crappier resolution.</p>
",<embedded><sensors><pic><circuit>
57663783,Error in glm.fit when using a tweedie distribution with log link,"<p>When running <code>glm</code> in R using tweedie and log link, I run into</p>

<blockquote>
  <p>""Error in glm.fit ... NA/NAN/INF in x""</p>
</blockquote>

<p>I have tried using different distributions and links. I have also tried adding 1 to the response because it is insurance data with lots of 0s.</p>

<p>I have already checked for na's, nan's, and inf values and have none in my dataset (or have already corrected for them).</p>

<p>Here is the code I have:</p>

<pre><code>fit = glm(y~x, data=data1,
             family=tweedie(var.power=1.6, link.power=0), weights=weights)
</code></pre>
",<r><glm><tweedie>
65110689,Getting undefined from console log,"<p>When I did a console.log(dbdata.user) it returned:</p>
<pre><code>createdAt: &quot;2020-11-17T04:32:17.934Z&quot;
date: &quot;2020-11-17T04:32:17.931Z&quot;
displayname: &quot;Batman&quot;
followers: [&quot;5fbb3879e8902d14f8c60448&quot;]
updatedAt: &quot;2020-12-02T14:58:17.880Z&quot;
__v: 0
_id: &quot;5fb35251888e8d081c06a7fa&quot;
__proto__: Object
</code></pre>
<p>But when I did a console.log(dbdata.user.followers), it returned undefined. What am I missing here?</p>
<p>I am using useEffect and the state code:</p>
<pre><code> const [dbdata,setDBData] = useState({post:[],user:[]})

   useEffect(async() =&gt; {
        const response = await Axios.get('http://localhost:5000/api/posts/allpost', {withCredentials:true})
        setDBData(response.data)
    }, [])
</code></pre>
<p>Many thanks in advance and greatly appreciated.</p>
",<reactjs>
61814299,current_predicate in SICStus Prolog,"<p>SICStus Prolog offers both current_predicate/1 and current_predicate/2.</p>

<p>The <a href=""https://sicstus.sics.se/sicstus/docs/latest4/html/sicstus.html/mpg_002dref_002dcurrent_005fpredicate.html#index-current_005fpredicate_002f_005b1_002c2_005d-_0028built_002din_002c-ref-page_0029-1"" rel=""nofollow noreferrer"">manual page</a> states:</p>

<blockquote>
  <p>current_predicate(?PredSpec)</p>
  
  <p>Unifies PredSpec with a predicate specifications of the form Name/Arity.</p>
  
  <p>current_predicate(?Name, ?Term)</p>
  
  <p>Unifies Name with the name of a user-defined predicate, and Term with the most general term corresponding to that predicate.</p>
</blockquote>

<p>They appear to have the same features:
both predicates work for enumerating predicates, both work with modules.</p>

<p>The manual page comments:</p>

<blockquote>
  <p>current_predicate/1 is part of the ISO Prolog standard; current_predicate/2 is not.</p>
</blockquote>

<p>Should I ever use <code>current_predicate/2</code> in new (= non-legacy) code?</p>
",<prolog><iso-prolog><sicstus-prolog>
46313895,logistic regression doesn't find optimal decision boundary,"<p>I run Logistic Regression on a very small and simple dataset that is well separable. But I realized that the model cannot find the optimal decision boundary. Where is my mistake? </p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn import linear_model

sm_df = pd.DataFrame()
sm_df['x'] = [0.5,4.0,1.0,2.5,2.0,3.5,1.0,3.0, 1.0, 2.0]
sm_df['y'] = [1.0,3.5,1.0,3.5,1.0, 4.5, 2.0,3.0, 0.0, 2.5]
sm_df['Bad_data'] = [True, False, True, False, True, False, True, False, True, False]

log = linear_model.LogisticRegression()

log.fit(sm_df[['x','y']], sm_df['Bad_data'])
test_score = log.score(sm_df[['x','y']], sm_df['Bad_data'])
print(""test score: "", test_score)

# Create scatterplot of dataframe
sns.lmplot('x', # Horizontal axis
           'y', # Vertical axis
           data=sm_df, # Data source
           fit_reg=False, # Don't fix a regression line
           hue=""Bad_data"", # Set color
           scatter_kws={""marker"": ""D"", # Set marker style
                        ""s"": 100}) # S marker size

plt.xlabel('x')
plt.ylabel('y')

# to plot desision bountdary
w0 = log.intercept_
w1, w2 = log.coef_[0]

X = np.array([0,4])
x2 = np.array([-w0/w2, -w0/w2 -w1*4/w2])
plt.plot(X, x2)
t_x = [1.5]
t_y = [1.8]
pr = log.predict([1.5,1.8])
plt.scatter(t_x, # Horizontal axis
           t_y, c='r') # S marker size
plt.annotate(pr, ([1.5,1.9]))
</code></pre>

<p><a href=""https://i.stack.imgur.com/NCE1w.png"" rel=""nofollow noreferrer"">my plot:</a></p>
",<python><machine-learning><scikit-learn><logistic-regression>
653384,verilog or systemc for testbench,"<p>I am assigned with the task of verifying some verilog based RTL code. Now, coding the RTL testbench using verilog seems to be very difficult (for me). So I would like to try one of the following.
- Try providing a PLI interface to the RTL and thereby invoke 'C functions for testing
- Using system 'C for interfacing the 'C functions</p>

<p>PS: I already have a extensive 'C code that was used for testing the behavioral model. I am new to the world of hardware programming. Any pointers would be greatly appreciated.</p>
",<verilog><hardware><systemc><register-transfer-level>
7691064,What level to use for exception stack trace logging in Java?,"<p>I'm looking for best practices document (or your opinions) on how to effectively log exceptions and their stack traces. Of course, assuming one of popular logging frameworkks such as Log4J, SLF4J, java.util.logging, etc.</p>

<p>I'm particularly interested in your opinion about on what level stack traces should be logged.</p>

<p>I heard few contradicting each other opinions such as:</p>

<ul>
<li>stack traces should be logged only on DEBUG level while ERROR level should contain only ""human readable"" error message</li>
<li>stack traces should be logged on ERROR level in order to give to the operator maximum amount of information required to find root cause of an exception</li>
</ul>

<p>I have found couple of interesting articles however none of them touches this particular subject:</p>

<ul>
<li><a href=""http://today.java.net/pub/a/today/2006/04/06/exception-handling-antipatterns.html"" rel=""nofollow"">http://today.java.net/pub/a/today/2006/04/06/exception-handling-antipatterns.html</a></li>
<li><a href=""http://today.java.net/pub/a/today/2003/12/04/exceptions.html"" rel=""nofollow"">http://today.java.net/pub/a/today/2003/12/04/exceptions.html</a></li>
</ul>

<p>which probably means that authors of these articles had same concerns as I do :-)</p>

<p>I'd be really interested in your view on this subject.</p>
",<java><exception><error-handling><stack-trace>
10601555,JBoss and log4j extras,"<p>I want to use <a href=""http://logging.apache.org/log4j/companions/extras/"" rel=""nofollow"">log4j extras</a> with JBoss 5.1.0.GA.<br>
On my local server I put the jar in <code>JBOSS_HOME/common/lib</code> and it works.<br>
On the integration server, I did the same, but I read the following error:</p>

<blockquote>
  <p>log4j:WARN Continuable parsing error 20 and column 76<br>
  log4j:WARN Element type ""rollingPolicy"" must be declared. 
  log4j:WARN Continuable parsing error 22 and column 40<br>
  log4j:WARN The content of element type ""rollingPolicy"" must match ""EMPTY"".  Children of type ""comment"" are not allowed.</p>
</blockquote>

<p>If I move the extras jar in <code>JBOSS_HOME/server/&lt;profile&gt;/lib</code> the error disappears, and the logging works as expected (as it does on my machine).</p>

<p>Can someone explain to me why this is happening? What part of the <strong>JBoss configuration</strong> is responsible of the different behaviour?</p>

<p><strong>EDIT</strong>
I also did a diff between the conf dir on my machine and on the remote server, and the directories are identical.</p>
",<jboss><log4j><classpath><jboss5.x>
56268648,Python OpenCV with Logitech C922 only gives 10 fps,"<p>I know similar threads exist, no trick worked for me though, so I am asking here again. I am using two Logitech C922 webcams. Theoretically, they can records with 60fps on 720p. However, using OpenCV (version 4.1.0) and this code</p>

<pre><code>import numpy as np
import cv2

width = 160
height = 120
fps = 30

fourcc = cv2.VideoWriter_fourcc('M','J', 'P', 'G')
out1 = cv2.VideoWriter('cam1.avi',fourcc, fps, (width,height))
out2 = cv2.VideoWriter('cam2.avi',fourcc, fps, (width,height))

cap1 = cv2.VideoCapture(0)
cap1.set(cv2.CAP_PROP_FOURCC,  1196444237)
cap1.set(3,width)
cap1.set(4,height)
cap1.set(cv2.CAP_PROP_FPS, fps)
cap2 = cv2.VideoCapture(2)
cap2.set(cv2.CAP_PROP_FOURCC,  1196444237)
cap2.set(3,width)
cap2.set(4,height)
cap2.set(cv2.CAP_PROP_FPS, fps)



while(True):
    # Capture frame-by-frame
    ret1, frame1 = cap1.read()
    ret2, frame2 = cap2.read()

    out1.write(frame1)
    out2.write(frame2)

    # Display the resulting frame
    #cv2.imshow('cam1',frame1)
    #cv2.imshow('cam2', frame2)
    if cv2.waitKey(1) &amp; 0xFF == ord('q'):
        break

cap1.release()
cap2.release()
out1.release()
out2.release()
cv2.destroyAllWindows()
</code></pre>

<p>I only get about 10fps. Is there any fix by now?
(I am on Ubuntu 18.04 if that matters)</p>

<p><em>EDIT:</em>
Output from v4l2-ctl --list-formats-ext is</p>

<pre><code>ioctl: VIDIOC_ENUM_FMT
    Index       : 0
    Type        : Video Capture
    Pixel Format: 'YUYV'
    Name        : YUYV 4:2:2
        Size: Discrete 640x480
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 160x90
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 160x120
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 176x144
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 320x180
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 320x240
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 352x288
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 432x240
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 640x360
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 800x448
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 800x600
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 864x480
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 960x720
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1024x576
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1280x720
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1600x896
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1920x1080
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 2304x1296
            Interval: Discrete 0.500s (2.000 fps)
        Size: Discrete 2304x1536
            Interval: Discrete 0.500s (2.000 fps)

    Index       : 1
    Type        : Video Capture
    Pixel Format: 'MJPG' (compressed)
    Name        : Motion-JPEG
        Size: Discrete 640x480
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 160x90
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 160x120
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 176x144
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 320x180
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 320x240
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 352x288
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 432x240
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 640x360
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 800x448
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 800x600
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 864x480
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 960x720
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1024x576
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1280x720
            Interval: Discrete 0.017s (60.000 fps)
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1600x896
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
        Size: Discrete 1920x1080
            Interval: Discrete 0.033s (30.000 fps)
            Interval: Discrete 0.042s (24.000 fps)
            Interval: Discrete 0.050s (20.000 fps)
            Interval: Discrete 0.067s (15.000 fps)
            Interval: Discrete 0.100s (10.000 fps)
            Interval: Discrete 0.133s (7.500 fps)
            Interval: Discrete 0.200s (5.000 fps)
</code></pre>
",<opencv><video><video-capture>
42559959,Class Assignment Numerology Report Java Code,"<p>Write a program that will add the digits of a person’s birth date to obtain a single digit to generate a numerology report. </p>

<p>Below is my code, it is mostly complete however I don't know if it is correct because when I try to compile it, I get an error message that I need a ';' after the first while, but when I add the ; it just gives me more errors. Any help is appreciated Thank you!</p>

<pre><code>import java.util.Scanner;

public class rneely_Numerology {

    public static void main (String args [])
    {
        int date = 0;
        int sum;
        int day = 0;
        int month = 0;
        int year = 0;
        int numerology = 0;
        int tempnumerology = 0;
        char A;
        char B;
        int leapyear = 0;

        leapyear = year % 4;

        Scanner input = new Scanner (System.in);

        do {
            System.out.print ( ""Enter the birth date (mm/dd/yyyy): "");
            month = input.nextInt();
            A = input.next().charAt(0);
            day = input.nextInt();
            B = input.next().charAt(0);
            year = input.nextInt();
        }
        while (month &lt; 1 || month &gt; 12)
            {
                System.out.printf ( ""Bad month: %d\n"", month);
                System.out.println();
                System.out.print ( ""Enter the birth date (mm/dd/yyyy): "");
                month = input.nextInt();
                A = input.next().charAt(0);
                day = input.nextInt();
                B = input.next().charAt(0);
                year = input.nextInt();
            }
            while (month == 1 || month == 3 || month == 5 || month == 7 || month == 8 || month == 10 || month == 12 );
            {
                if (day &lt; 1 || day &gt; 31)
                {
                    System.out.printf ( ""Bad day: %d\n"", day);
                    System.out.println();
                }
                System.out.print ( ""Enter the birth date (mm/dd/yyyy): "");
                month = input.nextInt();
                A = input.next().charAt(0);
                day = input.nextInt();
                                                                                   B = input.next().charAt(0);
                year = input.nextInt();
            }
            while (month == 4 || month == 6 || month == 9 || month == 11);
            {
                if (day &lt; 1 || day &gt; 30)
                {
                    System.out.printf ( ""Bad day: %d\n"", day);
                    System.out.println();
                }

                System.out.print ( ""Enter the birth day (mm/dd/yyyy): "");
                month = input.nextInt();
                A = input.next().charAt(0);
                day = input.nextInt();
                B = input.next().charAt(0);
                year = input.nextInt();
            }
            while (month == 2);
            {
                if (year % 400 = 0) {
                    if (year % 100 = 0) {}}
                else if (year % 4 = 0)
                {
                    if (day &lt; 1 || day &gt; 29)
                    {
                        System.out.printf ( ""Bad day for %d%d: %d\n"", month, year, day);
                        System.out.println();
                    }
                }
                else
                {
                    if (day &lt; 1 || day &gt; 28)
                    {
                        System.out.printf ( ""Bad day for %d%d: %d\n"", month, year, day);
                        System.out.println();
                    }
                }

                System.out.print ( ""Enter the birth date (mm/dd/yyyy): "");
                month = input.nextInt();
                A = input.next().charAt(0);
                day = input.nextInt();
                B = input.next().charAt(0);
                year = input.nextInt();
            }
            while (year &lt; 1880 || year &gt; 2280);
            {
                System.out.printf ( ""Bad year: %d\n"", year);
                System.out.println();
                            System.out.print ( ""Enter the birth date (mm/dd/yyyy): "");
                month = input.nextInt();
                A = input.next().charAt(0);
                day = input.nextInt();
                B = input.next().charAt(0);
                year = input.nextInt();
            }
            while (A != '/' || B != '/');

            System.out.print ( ""Use forward slashes between month, day, and year!\n"" );
            System.out.println();
            System.out.print ( ""Enter the birth date (mm/dd/yyyy): "");
            month = input.nextInt();
            A = input.next().charAt(0);
            day = input.next.Int();
            B = input.next().charAt(0);
            year = input.nextInt();



            date = month + day + year;
            for ( int numerology = date; numerology &lt;= 9; numerology %= 10 ) {
                date = numerology;
            }

            System.out.printf ( ""Welcome to the numerology report for %d/%d/%d\n"", month, day, year);

            switch (numerology)
            {
                case 1:
                    System.out.println ( ""-1- Hard work pays off in the future, laziness pays off now. "");
                    break;
                case 2:
                    System.out.println ( ""-2- You learn from your mistakes... you will learn a lot today. "");
                    break;
                case 3:
                    System.out.println ( ""-3- Your high minded principles spell success. "");
                    break;
                case 4:
                    System.out.println ( ""-4- A dream you have will come true. "");
                    break;
                case 5:
                    System.out.println ( ""-5- The greatest risk is not taking one. "");
                    break;
                case 6:
                    System.out.println ( ""-6- Your ability for accomplishment will follow with success. "");
                    break;
                case 7:
                    System.out.println ( ""-7- You will travel to many exotic places in your lifetime. "");
                    break;
                case 8:
                     System.out.println ( ""-8- Keep your eye out for someone special. "");
                    break;
                case 9:
                    System.out.println ( ""-9- Now is the time to try something new. "");
                    break;
            }
        }

    }
</code></pre>
",<java><debugging><compiler-errors>
13413392,Log4net detailed only for 1 particular user,"<p>I'm using log4net to log errors/info for our website and it works great.</p>

<p>Is it possible to control the level of logging based on the user logged in/sessionid or something similar.  Ie. a user rings us with a problem and we turn on detailed logging just for them so we can troubleshoot but only slow down that user with detailed logging?</p>

<p>Obviously I could code explicitly but I was wondering if there is anything built into log4net?  Maybe by using the filters with global properties?</p>
",<asp.net><log4net>
50646381,Elastic search azure deployment log-stash details,"<p>I am trying to deploy ElasticSearch on Azure Cloud. Installed the Elastic template from Azure Marketplace and able to access in kibana by hitting this url <a href=""http://ipaddress:5601"" rel=""nofollow noreferrer"">http://ipaddress:5601</a> with user id and password given at the time of creation.
Also able to access elastic search <a href=""http://ipaddress:9200/"" rel=""nofollow noreferrer"">http://ipaddress:9200/</a> and getting below configuration </p>

<pre><code>{
  ""name"" : ""myesclient-1"",
  ""cluster_name"" : ""myes"",
  ""cluster_uuid"" : ""........"",
  ""version"" : {
    ""number"" : ""6.2.4"",
    ""build_hash"" : ""ccec39f"",
    ""build_date"" : """",
    ""build_snapshot"" : false,
    ""lucene_version"" : ""7.2.1"",
    ""minimum_wire_compatibility_version"" : ""5.6.0"",
    ""minimum_index_compatibility_version"" : ""5.0.0""
  },
  ""tagline"" : ""You Know, for Search""
}
</code></pre>

<p>Now i am facing problem in,
On which VM runs logstash?
How to start logstash?
Where to store the config files and jdbc config file and how to run BAT file periodically. Bat file syntax for normal VM is like </p>

<pre><code>Run
cd C:\logstash\logstash-6.2.2\bin
logstash -f C:\Users\basudeb\Desktop\config\jdbc.config
pause 
</code></pre>
",<azure><elasticsearch><logstash><kibana><elastic-stack>
32467561,Logging with asl layout on mac OS-X multi-threaded project,"<p>I'd like to convert all my log messages in my multi-threaded project, to use Apple System Log facility (or asl). </p>

<p>according to the following asl manual - <a href=""https://developer.apple.com/library/ios/documentation/System/Conceptual/ManPages_iPhoneOS/man3/asl_get.3.html"" rel=""nofollow"">https://developer.apple.com/library/ios/documentation/System/Conceptual/ManPages_iPhoneOS/man3/asl_get.3.html</a></p>

<blockquote>
  <p>When logging from multiple threads, each thread must open a separate client handle using asl_open.  </p>
</blockquote>

<p>For that reason, I've defined asl client per thread to be used in all my log commands. However, in facing some major difficulties in binding asl client to each asl_log command.  </p>

<pre><code>1. what if some of my asl log commands reside in a code that is common for
   more than one thread - which asl client should i decide use on such message.

2. Even on thread unique code, one should be consistent in choosing the same
   asl_client on all log functions on a single thread code scope (this is
   not always easy to find in complex projects.). 
</code></pre>

<p>Is there any easier way to adopt my project logging messages to use asl ? </p>

<p>I'd think about something like binding asl client to thread,</p>

<p>thanks </p>
",<c++><c><macos><logging><asl>
39653387,How to post a mutli-tiered json object into epilogue using associated models in sequelize,"<p>I am trying to post a multitiered object to an epilogue generated REST sever with many associated models.</p>

<p>The object:</p>

<pre><code>{
""customer"": {
    ""name"": ""string"",
    ""phone"": ""string"",
    ""address1"": ""string"",
    ""address2"": ""string"",
    ""city"": ""string"",
    ""state"": ""string"",
    ""zip"": ""string"",
    ""cross-street"": ""string"",
    ""special-instructions"": ""string"",
    ""longitude"": ""string"",
    ""latitude"": ""string""
},
""info"": {
    ""scheduled-dt"": ""string"",
    ""estimated-dt"": ""string"",
    ""confirmation-number"": ""string"",
    ""service-type"": ""string"",
    ""payment-is-cash"": ""string"",
    ""tip-payment-is-cash"": ""string"",
    ""payment-type"": ""string"",
    ""tip-payment-type"": ""string"",
    ""subtotal"": ""string"",
    ""delivery-charge"": ""string"",
    ""sales-tax"": ""string"",
    ""tip"": ""string"",
    ""total"": ""string"",
    ""coupon-description"": ""string"",
    ""coupon-amount"": ""string""
},
""restaurant"": {
    ""name"": ""string"",
    ""billing-comment"": ""string""
},
""items"": [
    {
        ""name"": ""string"",
        ""group_name"": ""string"",
        ""group_id"": ""string"",
        ""pos_id"": ""string"",
        ""quantity"": ""string"",
        ""price"": ""string"",
        ""mods"": [
            {

                ""name"": ""string"",
                ""pos_id"": ""string"",
                ""portion"": ""string"",
                ""group_name"": ""string"",
                ""group_id"": ""string"",
                ""price"": ""string"",
                ""quantity"": ""string""
            }
        ]
    }
]
</code></pre>

<p>}</p>

<p>The current associations are as follows:</p>

<ul>
<li>Order has one Restaurant </li>
<li>Restaurant belongs to Order</li>
<li>Order has one Customer</li>
<li>Customer belongs to Order</li>
<li>Order has one Info</li>
<li>Info belongs to Order</li>
<li>Order has many Items</li>
<li>Items belong to Order</li>
<li>Items has many Mods</li>
<li>Mods belongs to Items</li>
</ul>

<p>so far I can post individually to all. But they do not associate.</p>

<p>How would I post the entire object into one route, say ""create-order"".</p>

<p>And then be able to find order info via orders/1/info/ for instance.</p>

<p>I am very new to node, and I am deeply over my head.</p>

<p>Any help would be a blessing.</p>

<p>I am using sequelize, express, and of course, epilogue.</p>
",<node.js><rest><express><sequelize.js><epilogue>
59337497,How to get the object from PostgreSQL DB of the logged in user with a querySet in Django?,"<p>I would like to only fetch the row from the database where the pk equals to the pk of the logged in user. In my case the pk is an <code>uuid</code> called <code>DID</code>.</p>

<p><strong>What I tried:</strong></p>

<pre><code>def getAccountInfo(request, *args, **kwargs):
    account_information = serializers.serialize('json', AccountInformation.objects.filter(pk=request.user.DID))
    return HttpResponse(account_information)
</code></pre>

<pre><code>def getAccountInfo(request, *args, **kwargs):
    account_information = serializers.serialize('json', AccountInformation.objects.filter(pk=request.user.pk))
    return HttpResponse(account_information)
</code></pre>

<p>with both attempts returning empty objects.</p>

<p><strong>This is a snippet of the DB:</strong><br></p>

<p><a href=""https://i.stack.imgur.com/TNrf7.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TNrf7.jpg"" alt=""enter image description here""></a></p>

<p><strong>Edit:</strong>
This works just fine, I used a wrong account while testing...</p>

<pre><code>def getAccountInfo(request, *args, **kwargs):
    account_information = serializers.serialize('json', AccountInformation.objects.filter(pk=request.user.DID))
    return HttpResponse(account_information)
</code></pre>
",<python><django>
47441586,Users are getting logged out on mobile devices,"<p>Users are unexpectedly getting logged out, sometimes multiple times in a day.</p>

<p>Originally, I was using storing the user with put_session. I recently switched to using Guardian for authentication but I am experiencing the same issue (calling current_resource would return nil instead of the user).</p>

<p>Some things to note, for both cases:</p>

<ol>
<li>I have not experienced this issue on desktop/laptop browsers.</li>
<li>This problem seems to happen after some period of inactivity, but I can't say for sure since I can't figure out how to consistently reproduce the issue.</li>
</ol>

<p>This has been an issue for about 6 months so I'm really hoping that I can get some help with brainstorming.</p>

<p>Setup:</p>

<ul>
<li>raspbian (jessie) over home internet connection</li>
<li>Elixir 1.5 / Phoenix 1.3</li>
</ul>
",<phoenix-framework>
58188819,Is this the right way of logging in Flask?,"<p>I have written a Flask App as follows:</p>

<pre><code>import logging
from flask import Flask, jsonify
from mongo import Mongo
app = Flask(__name__)
app.config.from_object(""config.ProductionConfig"")


# routes to a particular change and patch number
@app.route(""/&lt;project&gt;/"")
def home(project):

    app.logger.info('testing info log')
    Mongo_obj = Mongo(ip=app.config[""DB_HOST""], port=app.config[""DB_PORT""],
                      username=app.config[""DB_USERNAME""],

.....................
if __name__ == '__main__':
    app.run(host = '0.0.0.0', port = '5000')
</code></pre>

<p>Now, the problem I face is, when I look at the logs of the Flask application, all I see is the following:</p>

<pre><code>* Serving Flask app ""service"" (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
172.16.40.189 - - [01/Oct/2019 14:44:29] ""GET /abc HTTP/1.1"" 200 -
172.16.11.231 - - [01/Oct/2019 14:44:29] ""GET /abc HTTP/1.1"" 200 -
............
</code></pre>

<p>Is there something specific that needs to be done in order to see the log message? Do I need to run the Flask App in debug mode?</p>
",<python><logging><flask>
41980964,Parsing log file with sed in linux,"<p>I'm trying to use <code>sed</code> for parsing log file to extract xml messages from it using the template. I want to get all xml messages in new file.</p>

<p>I'm using this command <code>sed 's/&lt;sending&gt;\(.*\)&lt;\/sending&gt;/\1/' input.out&gt;output.xml</code></p>

<p>input.out have following сontent:</p>

<pre><code> WARNING: Exchange[ExchangePattern: InOut, BodyType: byte[], Body: &lt;?xml version=""1.0"" encoding=""utf-8"" standalone=""yes""?&gt;&lt;sending&gt;&lt;query&gt;        &lt;describe&gt;            &lt;data&gt;city&lt;/data&gt;        &lt;/describe&gt;    &lt;/query&gt;&lt;/sending&gt;]
Sep 26, 2016 11:54:30 AM org.apache.camel.util.CamelLogger log
WARNING: Exchange[ExchangePattern: InOut, BodyType: byte[], Body: &lt;?xml version=""1.0"" encoding=""utf-8"" standalone=""yes""?&gt;&lt;sending&gt;    &lt;query&gt;        &lt;key_info/&gt;    &lt;/query&gt;&lt;/sending&gt;]
</code></pre>

<p>I'm expecting to get result like this:</p>

<pre><code> &lt;query&gt;        &lt;describe&gt;            &lt;data&gt;city&lt;/data&gt;        &lt;/describe&gt;    &lt;/query&gt;    &lt;query&gt;        &lt;key_info/&gt;    &lt;/query&gt;
</code></pre>

<p>But i only get source file without <code>&lt;sending&gt;</code> and <code>&lt;/sending&gt;</code> elements like this:</p>

<pre><code>WARNING: Exchange[ExchangePattern: InOut, BodyType: byte[], Body: &lt;?xml version=""1.0"" encoding=""utf-8"" standalone=""yes""?&gt;&lt;query&gt;        &lt;describe&gt;            &lt;data&gt;city&lt;/data&gt;        &lt;/describe&gt;    &lt;/query&gt;]
Sep 26, 2016 11:54:30 AM org.apache.camel.util.CamelLogger log
WARNING: Exchange[ExchangePattern: InOut, BodyType: byte[], Body: &lt;?xml version=""1.0"" encoding=""utf-8"" standalone=""yes""?&gt;    &lt;query&gt;        &lt;key_info/&gt;    &lt;/query&gt;]
</code></pre>

<p>Sorry for my english and have a nice day. Thank you for help.</p>
",<xml><bash><unix><sed><cygwin>
48323670,Logging - Log4j2 logging issue,"<p>I am currently working on an application that is using Log4j2 for logging.</p>

<p>Below is the Log4j2.xml file</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;Configuration status=""debug"" packages=""myappsystem""&gt;
&lt;Appenders&gt;
    &lt;MyDockerAppender name=""STDOUT"" /&gt;
&lt;/Appenders&gt;
&lt;Loggers&gt;
    &lt;logger name=""org.springframework"" level=""ERROR""/&gt;
    &lt;logger name=""myappsystem""  level=""INFO""/&gt;
    &lt;Root level=""ERROR"" additivity=""true"" includeLocation=""true""&gt;
        &lt;AppenderRef ref=""STDOUT""/&gt;
    &lt;/Root&gt;
&lt;/Loggers&gt;
</code></pre>

<p></p>

<p>Now the challenge that I am facing here is the logger seems to be logging only when I do something like below</p>

<pre><code>private static final Logger LOGGER = LogManager.getLogger(""myappsystem"");
LOGGER.info(""Entering method"");
</code></pre>

<p>The problem here is, It is not giving me the details of the class files from which this particular line is being logged.</p>

<p>So, I tried to do something like below:</p>

<pre><code>private static final Logger LOGGER = LogManager.getLogger(MyServiceImpl.class);
</code></pre>

<p>This doesn't seem to be working.
Any ideas on where I am going wrong?</p>
",<java><spring-boot><logging><log4j2>
5140907,How can I see values of Object in NSLog?,"<p>Suppose I have an object containing some data.</p>

<p>How can I see that data using NSLog?</p>

<p>If anyone is not clear about my question, then can ask me again.</p>
",<iphone><objective-c><object><nslog>
19634713,"NSFileManager's ubiquityIdentityToken always returning null, even when logged in","<p>My Mac application in Xcode has recently begun exhibiting strange symptoms when attempting to access iCloud. There haven't been any changes to my provisioning profiles, code signing identities, etc.</p>

<p>However, when running this code:</p>

<pre><code>id token = [fileManager ubiquityIdentityToken];
NSLog(@""Token is: %@"", token);
NSURL *iCloudURL = [fileManager URLForUbiquityContainerIdentifier:nil];
NSLog(@""iCloud URL is: %@"", iCloudURL);
</code></pre>

<p>The output is:</p>

<pre><code>2013-10-28 08:17:12.372 MyApp[21101:303] Token is: (null)
2013-10-28 08:17:12.373 MyApp[21101:303] iCloud URL is: (null)
</code></pre>

<p>Which I find extremely strange, especially considering I <em>am</em> actually signed into iCloud on this machine. To be sure, I ran a quick test with Calendar, adding an event on an iPhone and ensuring that it showed up on the Calendar on my Mac.</p>

<p>But I was under the impression that <code>[fileManager ubiquityIdentityToken];</code> would return whether the user was logged into iCloud, regardless of whether your entitlements, code signing, etc. was properly configured - indicating that it's less an issue on my end, and more an issue of the system's ability to return this value.</p>

<p>I have tried logging out (and back in) to iCloud, and have ensured that ""Documents &amp; Data"" is enabled in the iCloud settings.</p>
",<objective-c><macos><icloud><osx-mavericks>
62823035,'Could not find schema..' messages when nlog.config file is created,"<p>When I create a nlog.config file in the root of my project , I get the following messages</p>
<pre><code>Could not find schema information for the element 'http://www.nlog-project.org/schemas/NLog.xsd:nlog'.  
Could not find schema information for the element 'http://www.nlog-project.org/schemas/NLog.xsd:targets'.       
This is an invalid xsi:type 'http://www.nlog-project.org/schemas/NLog.xsd:File'.    
Could not find schema information for the element 'http://www.nlog-project.org/schemas/NLog.xsd:target'.    
Could not find schema information for the attribute 'name'.     
Could not find schema information for the attribute 'fileName'. 
Could not find schema information for the element 'http://www.nlog-project.org/schemas/NLog.xsd:rules'. 
Could not find schema information for the element 'http://www.nlog-project.org/schemas/NLog.xsd:logger'.    
Could not find schema information for the attribute 'minlevel'.     
Could not find schema information for the attribute 'writeTo'.  
</code></pre>
<p>The code that I used was</p>
<pre><code>        &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;
    &lt;nlog xmlns=&quot;http://www.nlog-project.org/schemas/NLog.xsd&quot;
          xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;
    
      &lt;!-- the targets to write to --&gt;
      &lt;targets&gt;
        &lt;!-- write logs to file  --&gt;
        &lt;target name=&quot;allfile&quot; xsi:type=&quot;File&quot;
                fileName=&quot;c:\CsharpTutorials\EmployeeManagement\DemoLogs\nlog-all-${shortdate}.log&quot;/&gt;
      &lt;/targets&gt;
    
      &lt;!-- rules to map from logger name to target --&gt;
      &lt;rules&gt;
        &lt;!--All logs, including from Microsoft--&gt;
        &lt;logger name=&quot;*&quot; minlevel=&quot;Trace&quot; writeTo=&quot;allfile&quot; /&gt;
      &lt;/rules&gt;
    &lt;/nlog&gt;
</code></pre>
<p>I am following a tutorial and this was the code that was used. How can I rectify the problem?</p>
",<xml><asp.net-core><nlog>
47289455,How to use docker passed environment variable in log4j2?,"<p>I have a spring-boot based application that uses <code>log4j2.xml</code> in a dockerized environment. </p>

<p>When I launch the docker I pass <code>-e ""LOG4J_PATH=/tmp/app.log""</code> to specify where the logs should go to. </p>

<p>Next, in the <code>log4j2.xml</code> I use <code>fileName=""${env:LOG4J_PATH}""</code> but this doesn't work. I searched the web for hours and thus tried double $ and tried <code>sys</code> instead of <code>env</code>... nothing. </p>

<p>This <code>System.getenv(""LOG4J_PATH"")</code> and <code>(new EnvironmentLookup()).lookup(""LOG4J_PATH"")</code> work fine, so I know that the variable is being passed to the running image ok, but from some reason the log4j doesn't seem to pick it up. </p>

<p>If I run this not via a docker and set the <code>LOG4J_PATH</code> environment variable in my <code>.bash_profile</code> it works fine so this is something between docker and log4j. </p>

<p>What am I doing wrong?</p>
",<java><docker><spring-boot><log4j2>
39290180,Consul service catalog to store important urls,"<p>I have a web application which send rest api calls to external services. As of now I have all the urls hardcoded in my application and I intend to store these urls in consul service catalog. Here are few questions related to this.</p>

<p>1) How do I store this url in service catalog?<a href=""https://prepiam.toronto.ca.ibm.com/idaas/oidc/endpoint/default/authorize?client_id=ssdfsjdfsdfew&amp;response_type=code&amp;scope=openid&amp;redirect_url=https://localhost:9000/mydashboard"" rel=""nofollow"">https://prepiam.toronto.ca.ibm.com/idaas/oidc/endpoint/default/authorize?client_id=ssdfsjdfsdfew&amp;response_type=code&amp;scope=openid&amp;redirect_url=https://localhost:9000/mydashboard</a>""
Will I be able to access this as a key value pair in my application. Is there any link to help understand the use and purpose of service catalog?</p>

<p>I also need to store some urls like <a href=""https://localhost:9000/users"" rel=""nofollow"">https://localhost:9000/users</a>. I was hoping I could store this url in parts like hostname,port,base_url etc.</p>
",<consul>
57673936,Vertx: Log4j2 without using the vertx logger factory,"<p>I would like to use Log4j2 without losing its API like passing lambdas for lazy loading.</p>

<p>So, I would like to avoid to use Vertx LoggerFactory (returning generic Logger API) and use the Log4j2 directly.</p>

<p>Is there any serious drawback to consider when Log4j2 is used directly without using the Vertx logger factory?</p>

<p>Thank you</p>
",<log4j2><vert.x>
11121496,Log4Net Stops logging,"<p>I have a utility which runs all day for data conversions and synchronization. </p>

<p>If the app stops running temporarily, it's not a big deal, but it has to log it's actions. I would rather the app fail than have it not log. I have come across a few posts which touch on the subject, but I cannot get any of the solutions to work.</p>

<p>I need to set up a way to stop the application from running (depending on an app setting) and send out a warning email if Log4Net stops logging. </p>

<p>I have this for my appender:</p>

<pre><code>&lt;log4net&gt;
&lt;appender name=""LogFileAppender"" type=""log4net.Appender.FileAppender""&gt;
  &lt;errorHandler type=""SomeApp.PresentationLayer.Log4NetErrorHandler"" /&gt;
  &lt;file type=""log4net.Util.PatternString"" value=""H:\SomeApp-%property{RegNo}-log.txt"" /&gt;
  &lt;appendToFile value=""true"" /&gt;
  &lt;layout type=""log4net.Layout.PatternLayout""&gt;
    &lt;header value=""[START]"" /&gt;
    &lt;footer value=""[END]"" /&gt;
    &lt;conversionPattern value=""%date %-5level - %message%newline"" /&gt;
  &lt;/layout&gt;
&lt;/appender&gt;
&lt;!-- Setup the root category, add the appenders and set the default level --&gt;
&lt;root&gt;
  &lt;level value=""DEBUG"" /&gt;
  &lt;appender-ref ref=""LogFileAppender"" /&gt;
  &lt;!-- &lt;appender-ref ref=""A"" /&gt; --&gt;
&lt;/root&gt;
</code></pre>

<p></p>

<p>And here's my Error Handler:</p>

<pre><code>namespace SomeApp.PresentationLayer
{
class Log4NetErrorHandler : IErrorHandler
{

    public bool HandleError(Exception ex)
    {
        //Trace.TraceError(ex.ToString());
        ExceptionUtil.GetAndLogMessage(ex, ""Log4Net Error in SomeApp"", false, true);

        return false;
    }

    public void ProvideFault(Exception error, MessageVersion version, ref Message fault)
    {
        // Shield the unknown exception
        FaultException faultException = new FaultException(
            ""Server error encountered. All details have been logged."");
        MessageFault messageFault = faultException.CreateMessageFault();

        fault = Message.CreateMessage(version, messageFault, faultException.Action);
    }
}
}
</code></pre>

<p>No matter what I try, the exception handler never fires. I have the log file set to a mapped drive. While it's logging I disconnect the drive and it never throws an exception to my exception handler. Anyone see what I'm missing?</p>

<p>I'm using c# .net 3.5 log4net 1.2.10</p>

<p>Thanks for any help in advance.</p>
",<.net><exception><c#-3.0><log4net>
67989579,How to store the IP with the error logs reported in Laravel,"<p>I usually get logs of 404 errors URLs, for some reason, I also want to store the IP of the user who visited the URL which will throw 404.
Please help.
This is the code I am using in Exceptions/handler.php</p>
<pre><code> public function render($request, Throwable $exception)
{

    if($exception instanceof \Illuminate\Database\Eloquent\ModelNotFoundException ||
        $exception instanceof \Symfony\Component\HttpKernel\Exception\MethodNotAllowedHttpException ||
        $exception instanceof \Symfony\Component\HttpKernel\Exception\NotFoundHttpException){
        $error = [
            'url'    =&gt; $request-&gt;url(),
        ];

        $message = '404: ' . $error['url'] . &quot;\n&quot; . json_encode($error, JSON_PRETTY_PRINT);
        \Log::channel('404logfile')-&gt;debug($message);
    }
    return parent::render($request, $exception);
}
</code></pre>
",<php><laravel><logging>
22954767,How to prevent duplicate exception logging from a celery task,"<p><strong>Second Edit:</strong> After a bit of digging, the question changed from how to log an exception with local variables to  how to prevent celery from sending the 2nd log message which does not has the local vars. After the below attempt, I actually noticed that I was always receiving 2 emails, one with local vars per frame and the other without.</p>

<p><strong>First Edit:</strong> I've managed to sort of get the local variables, by adding a custom on_failure override (using <a href=""http://celery.readthedocs.org/en/latest/configuration.html#celery-annotations"" rel=""nofollow"">annotations</a> for all tasks like so:</p>

<pre><code>def include_f_locals(self, exc, task_id, args, kwargs, einfo):
    import logging
    logger = logging.getLogger('celery')
    logger.error(exc, exc_info=einfo)

CELERY_ANNOTATIONS = {'*': {'on_failure': include_f_locals}}
</code></pre>

<p>But the problem now is that the error arrives 3 times, once through the celery logger and twice through root (although I'm not propagating 'celery' logger in my logging settings)</p>

<p><strong>Original question:</strong>
I have a django/celery project to which I recently added a sentry handler as the root logger with level 'ERROR'. This works fine for most errors and exceptions occurring in django, except the ones coming from celery workers.</p>

<p>What happens is that sentry receives an exception with the traceback and the locals of the daemon, but does not include the <code>f_locals</code> (local vars) of each frame in the stack. And these do appear in normal python/django exceptions.</p>

<p>I guess I could try to catch all exceptions and log with exc_info manually. But this is less than ideal.</p>
",<python><django><celery><sentry><raven>
19215029,How to implement a MVC 4 change log?,"<p>I currently am developing a mvc 4 application.
The client wants to have a change log, so that they can view what fields have been changed.  It should show the old value and the new value, in case of an edit.   If its a delete, then it should show what row was deleted.</p>

<p>Whats the best way to achieve something like this? </p>

<p>Just to clarify.. the changes will be the actual data in the database..</p>

<p>ie I might have a record of customer names and addresses.. the user might update the addresses.. I need the ability to see what the user changed.. old data and new data</p>

<p>Thanks...</p>
",<.net><asp.net-mvc-3><c#-4.0><asp.net-mvc-4>
23963168,"Common.Logging ""void Error( object message, Exception exception );"" not logging the ""Exception""","<p>I'm using Common.Logging with the NLog adapter.</p>

<p><a href=""http://netcommon.sourceforge.net/docs/1.2.0/reference/html/logging.html"" rel=""nofollow"">http://netcommon.sourceforge.net/docs/1.2.0/reference/html/logging.html</a></p>

<p>I'm calling this method:</p>

<pre><code>void Error( object message, Exception exception );
</code></pre>

<p>The text of the ""message"" shows up in the Logs (a txt-file and in the EventLog), but the details about the exception do not.  Not even the ex.Message.</p>

<p>Am I missing something?</p>

<p>How do I get the details about the Exception to show up.  Do I have to just tack it on the ""object message""?  I guess having the overload'ed method with the exception, I thought there would be some auto-logging.</p>

<p>My NLog.config is fairly simple.</p>

<pre><code>&lt;nlog xmlns=""http://www.nlog-project.org/schemas/NLog.xsd"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt;
  &lt;targets&gt;
    &lt;target name=""logfile"" xsi:type=""File"" fileName=""MyFile.log.txt""/&gt;
    &lt;target name=""console"" xsi:type=""Console"" /&gt;
    &lt;target xsi:type=""EventLog""
             name=""eventLog"" 
             source=""MySource""
       eventId=""555""
             log=""Application""
                     /&gt;
  &lt;/targets&gt;
  &lt;rules&gt;
    &lt;logger name=""*"" minLevel=""Error"" writeTo=""eventLog"" /&gt;
    &lt;logger name=""*"" minLevel=""Info"" writeTo=""console"" /&gt;
    &lt;logger name=""*"" minLevel=""Info"" writeTo=""logfile""/&gt;
  &lt;/rules&gt;

&lt;/nlog&gt;
</code></pre>

<p>EDIT:</p>

<p>Ok...based on the Sergey answer, I just roided up my setup:</p>

<pre><code>layout=""${longdate}|${level}|${callsite}|${logger}|${threadid}|${windows-identity:domain=false}__${message} ${exception:format=message,stacktrace:separator=*""
</code></pre>
",<c#><nlog><common.logging>
66993021,bool(true) message appears when user is not logged in on wordpress,"<p>I have a website with wp-event manager plugin and when is user is not logged in, it shows bool(true) message on top of my event submit form. I have test it in local and the message says</p>
<pre><code>&quot;C:\wamp64\www\testing\wp-content\plugins\wp-event-manager\wp-event-manager-template.php:393:boolean false&quot;
</code></pre>
<p>The code ate that line is:</p>
<pre><code>390    $generate_username_from_email      = event_manager_generate_username_from_email();
391    $use_standard_password_setup_email = event_manager_use_standard_password_setup_email();
392    $account_required  = event_manager_user_requires_account();
393    var_dump($use_standard_password_setup_email);
</code></pre>
",<php><wordpress>
32425625,Xcode 6 to Xcode 11 - Detach the Console/Log Window,"<p>Is it possible to detach the console/log window in Xcode 6 to Xcode 9? If so, how do you detach it from the main console, into it's own window?</p>

<p>This question was previously asked for Xcode 4 but the answer doesn't work for Xcode 6 to Xcode 9 -</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/5306276/xcode-4-detach-the-console-log-window"">Stackoverflow - Same Question for Xcode 4</a></li>
</ul>

<p>See the attached screenshot for illustration of the console/log view in question</p>

<p><a href=""https://i.stack.imgur.com/2Mtv3.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/2Mtv3.png"" alt=""enter image description here""></a></p>
",<xcode>
57758973,"Pino error log is empty, although error object contains information","<p>I have written a small error handling function, which is invoked after an AXIOS request, like so:</p>

<pre><code>try {
 ...
} catch (error) {
    handleAxiosError(error);
}
</code></pre>

<p>The function is as follows:</p>

<pre><code>function handleAxiosError(error) {
    if (error.response !== undefined) {
        logger.error(`Received a HTTP error. Status code: ${error.response.status}, Data: ${error.response.data}`);
    } else if (error.request !== undefined) {
        logger.error(error.request);
    } else {
        logger.error(error.message);
    }
    throw new Error(error);
}
</code></pre>

<p>Although an error is thrown:</p>

<p>(node:94324) UnhandledPromiseRejectionWarning: Error: Error: connect ECONNREFUSED 127.0.0.1:6557
    at handleAxiosError (C:\pathtoapp\utils\utils.js:66:11)</p>

<p>Pino only saves the following to the log. I can't find the problem. Is this an async issue?</p>

<p>{""level"":50,""time"":1567435455281,""pid"":94324,""hostname"":""host"",""name"":""app"",""res"":{},""v"":1}</p>

<p>Thanks!</p>
",<javascript><node.js><logging><axios>
46067834,"log writing failed. ""\xC3"" from ASCII-8BIT to UTF-8","<p>I am developing rails based api and I used to always get this warning, log writing failed. ""\xC3"" from ASCII-8BIT to UTF-8. 
Does any body have any idea why this warning appears?</p>
",<ruby-on-rails-3>
58119657,Propper container logs monitoring in Ansible/Rundeck,"<p>I am using Ansible and Rundeck to deploy docker containers, one of which starts generating logs which I would like to make visible in Rundeck. I know i can do it with an Ansible playbook that does<br>
<code>docker container logs {{container_name}} --until=5s</code><br>
pauses for 5 sec and does this over and over but is there a proper plugin/module in either Ansible or Rundeck to do this?</p>
",<docker><logging><ansible><continuous-integration><rundeck>
59422468,Log Azure Function Request as failed and return status 200,"<p>I have a azure function V3 in dotnet. In case of an application error, the function returns a status 200 and a json with an error property. (like graphql is doing it.)</p>

<p>If an error occurs, Application insights shows this Request as successful:</p>

<p><a href=""https://i.stack.imgur.com/rlcmw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rlcmw.png"" alt=""Successful request""></a></p>

<p>Since it is much easier to identify and alert on unsuccessful, I would prefer if this is logged with <code>Successful request: false</code>.</p>

<p>Is there a way to return status 200, but set the Request for logging to failed?</p>
",<azure-functions><azure-application-insights>
3348958,Efficient way of setting Logging across a Package Module,"<p>I have a package that has several components in it that would benefit greatly from using logging and outputting useful information.</p>

<p>What I do not want to do is to 'setup' proper logging for every single file with somewhere along these lines:</p>

<pre><code>import logging
logging.basicConfig(level=DEBUG)
my_function = logging.getLogger(""my_function"")
my_class = logging.getLogger(""my_class"")
</code></pre>

<p>I have tried a couple of approaches, one of them being adding the boilerplate code into a class within a utility module and try and do something like this:</p>

<pre><code>from util import setlogging
set_logging()
</code></pre>

<p>But even the above solution doesn't look clean to me and would cause issues because setLogger doesn't have a <code>__call__</code> method. What I did liked was that my ""set_logging"" class would read form a config file and have some default values so it wouldn't matter what level or what type of logging format I wanted it would set it up correctly.</p>

<p>Is there a way to initialize proper logging across the board in my package? Maybe in the <code>__init__.py</code> file? </p>

<p>And just to be as verbose as possible, this is what setlogging (now a function, not a class) looks like:</p>

<pre><code>def setlogging(config=None):
    if config == None:
        config = config_options() # sets default values
    levels = {
        'debug': DEBUG,
       'info': INFO
        }

    level = levels.get(config['log_level'])
    log_format = config['log_format']
    datefmt = config['log_datefmt']

    basicConfig(
        level   = level,
        format  = log_format,
        datefmt = datefmt)
</code></pre>
",<python><logging><module><package>
63375383,Movesense data logger for ECG,"<p>Right now I’m trying to write ECG data to the logbook using my own app. But, every time I try to read the logs, I get an internal server error as response. Here is an example of this error.</p>
<pre><code>E/Komposti: Logbook::getData: Failed to read data.
    [SDS RESPONSE] type: GET status: INTERNAL_SERVER_ERROR header: {&quot;TaskId&quot;: 41, &quot;Uri&quot;: &quot;suunto://MDS/Logbook/192630002431/ById/2/Data&quot;, &quot;Content-Length&quot;: 0, &quot;Reason&quot;: &quot;INTERNAL_SERVER_ERROR&quot;, &quot;Status&quot;: 500} error: Failed to read data
</code></pre>
<p>Before I wrote this issue, I also tried to fetch the log data with the “DataLoggerSample” app, provided by your company. It works fine if I log “/Meas/Acc/13”, in my own app, and also with the DataLoggerSample app, but if I change the logger config to “/Meas/ECG/125/” or “/Meas/ECG/128/”, the Movesense sensor answers with: STATUS 500 - INTERNAL_SERVER_ERROR.</p>
<p>The following JSON, shows the logger configuration for ECG:</p>
<pre><code>{
    &quot;config&quot;: {
        &quot;dataEntries&quot;: {
            &quot;dataEntry&quot;: [
                {
                    &quot;path&quot;: &quot;/Meas/ECG/125&quot;
                }
            ]
        }
    }
}
</code></pre>
<pre><code>{
    &quot;config&quot;: {
        &quot;dataEntries&quot;: {
            &quot;dataEntry&quot;: [
                {
                    &quot;path&quot;: &quot;/Meas/Acc/13&quot;
                }
            ]
        }
    }
}
</code></pre>
<p>I don’t know if I’m missing something, but I already spent several hours but haven’t found anything. Is the “config” object in the JSON needed? In the documentation of the datalogger, the “config” object is not described, but it works well with the Acc.
Is there a trick, to get it to work?</p>
<p>My setup is:</p>
<ul>
<li><p>Sensor 1 - SW version: 1.9.4</p>
</li>
<li><p>Sensor 2 - SW version: 1.9.0</p>
</li>
<li><p>Models: OP174</p>
</li>
<li><p>MDS lib version: 1.44.0</p>
</li>
</ul>
<p>‌</p>
",<logging><movesense>
39853960,Parsing lines from a log file containing date-time greater than something,"<p>I have log files of size of the order of several 100 MBs, containing lines like this, containing the date-time information in the beginning:</p>

<pre><code>[Tue Oct  4 11:55:19 2016] [hphp] [25376:7f5d57bff700:279809:000001] [] \nFatal error: syntax error, unexpected T_ENCAPSED_AND_WHITESPACE, expecting ')' in /var/cake_1.2.0.6311-beta/app/webroot/openx/www/delivery/postGetAd.php(12479)(62110d90541a84df30dd077ee953e47c) : eval()'d code on line 1
</code></pre>

<p>I have a plugin (nagios check_logwarn) to print out only those lines which contain some of the error strings. Following is the command to run it:</p>

<pre><code>/usr/local/nagios/libexec/check_logwarn -d /tmp/logwarn -p /mnt/log/hiphop/error_20161003.log ""^.*Fatal error*"" 
</code></pre>

<p>I want to filter out further, based on the date-time, i.e., all the lines which are after, say, 11:55:10. </p>

<p>I am not sure whether to use regex for this. Following is what I have so far:</p>

<pre><code>/usr/local/nagios/libexec/check_logwarn -d /tmp/logwarn -p /mnt/log/hiphop/error_20161003.log ""^.*Fatal error*"" | grep ""15\:19\:1*""
</code></pre>

<p>But this will only filter those logs whose time is in the 19th minute of the 15th hour. </p>

<p><strong>Update</strong></p>

<p>I am now able to compare the time part of the date-time. </p>

<pre><code>/usr/local/nagios/libexec/check_logwarn -d /tmp/logwarn -p /mnt/log/hiphop/error_20161004.log ""^.*Fatal error*"" | awk '$4 &gt; ""14:22:11""'
</code></pre>

<p>How do I compare the day part?</p>

<p><strong>Update 2 - opening bounty</strong></p>

<p>I am having to open a bounty because I do not have much expertise with shell and I need a solution soon.</p>

<p>I am stuck at the part of comparing the dates. With The solution <a href=""https://stackoverflow.com/a/39856560/351903"">https://stackoverflow.com/a/39856560/351903</a>, I am facing <a href=""https://stackoverflow.com/questions/39853960/parsing-lines-from-a-file-containing-date-time-greater-than-something#comment67107842_39856560"">this problem</a>. If that is fixed, I would be happy. </p>

<p>I am also open to some enhancement to this (I don't mind if the output has some jumbled up order of logs) -</p>

<pre><code>/usr/local/nagios/libexec/check_logwarn -d /tmp/logwarn -p /mnt/log/hiphop/error_20161004.log ""^.*Fatal error*"" | awk '$4 &gt; ""14:22:11""'
</code></pre>

<p>I looked for some date-time to timestamp comparison, but couldn't find something working.</p>

<p>I am not able to proceed from what is given in <a href=""https://stackoverflow.com/questions/10990949/convert-date-time-string-to-unix-timestamp-in-bash-command"">this question</a>. I cannot see the timestamp value using this - </p>

<pre><code>echo date -d '06/12/2012 07:21:22' +""%s""
</code></pre>

<p>Not sure what am I missing.</p>
",<parsing><grep><nagios>
61639439,What kafka mean when log that consumer id **** Leave Group,"<p>We use kafka 2.1.0
Please help me understand what is really going on when in Kafka log we see this message:</p>

<pre><code>Preparing to rebalance group some-service in state PreparingRebalance with old  generation 21668 
(__consumer_offsets-47) (reason: removing member consumer-24-f5b9a9b1-ffed-4088-999b-378df9aaa71b on LeaveGroup) 
(kafka.coordinator.group.GroupCoordinator)
</code></pre>

<p>Does this indicate that Kafka removed a consumer from the group (due to timeout or other things) or consumer left group itself?</p>
",<apache-kafka>
5704959,Parsing a log file with optional fields,"<p>I want to read a log file and split it into four scalars.</p>
<p>This is a log file example:</p>
<pre><code>[time1] [error1] [who is1] mess is here1
[time2] [error2] mess is here2
</code></pre>
<p>And id like to get those scalars as output:</p>
<pre class=""lang-perl prettyprint-override""><code>($time, $err, $who, $mess)=('time1', 'error1', 'who is1', 'mess is here1')
($time, $err, $who, $mess)=('time2', 'error2', '', 'mess is here2') 
</code></pre>
<p>How to do it in Perl?</p>
<p>This is my current code, but it is not working:</p>
<pre class=""lang-perl prettyprint-override""><code>while (&lt;MYFILE&gt;) {
    chomp;
    ($time, $err, $who, $mess)=($_ =~/\[([.]*)\] \[([.]*)\] (\[([.]*)\]|[ ])([.]*)/);
    $logi.= &quot;&lt;tr&gt;&lt;td&gt;$time&lt;/td&gt;&lt;td&gt;$err&lt;/td&gt;&lt;td&gt;$who&lt;/td&gt;&lt;td&gt;$mess&lt;/td&gt;&lt;/tr&gt;\n&quot;;
}
</code></pre>
",<regex><perl>
12599558,Is there a way to log that someone has made a CSRF attack to a web-application,"<p>I understand how CSRF works, why it works &amp; how to mitigate it. now, I have a web-application, its vulnerable to CSRF, I want to know if someone has successfully made a CSRF attack on my web-app. Is there a way to log it if there's CSRF</p>

<p>Thanks 
Suzee </p>
",<csrf-protection>
28737662,"Why does prolog don't give all results, when I place the equality-comparision at the beginning?","<p>Currently I'm exercising the Prolog chapter of seven languages in seven weeks. I tried to change the coloring example, in order to not write down every valid color combination.</p>
<pre><code>different(red, green).
different(green, red).
different(red, blue).
different(blue, red).
different(blue, green).
different(green, blue).

coloring(A, M, G, T, F) :-
    different(M, T),
    different(M, A),
    different(A, T),
    different(A, M),
    different(A, G),
    different(A, F),
    different(G, F),
    different(G, T).
</code></pre>
<p>I changed the file to make different a <s>function</s>predicate:</p>
<pre><code>color(red).
color(blue).
color(green).

different(X, Y) :- color(X), color(Y), \+(X=Y).
different_fail(X, Y) :- \+(X=Y), color(X), color(Y).

coloring(A, M, G, T, F) :-
    different(M, T),
    different(M, A),
    different(A, T),
    different(A, M),
    different(A, G),
    different(A, F),
    different(G, F),
    different(G, T).
</code></pre>
<p>What I don't get is that <code>different</code> gives me all combinations of different colors, but <code>different_fail</code> does only check if they are really different.</p>
<pre><code>GNU Prolog 1.4.5 (32 bits)
Compiled Feb 23 2015, 08:36:31 with gcc
By Daniel Diaz
Copyright (C) 1999-2015 Daniel Diaz
| ?- ['color'].             
compiling /home/rudi/7langs/prolog/color.pl for byte code...
/home/rudi/7langs/prolog/color.pl compiled, 17 lines read - 2206 bytes written, 7 ms
| ?- different(red, red).   

no
| ?- different(red, blue).

yes
| ?- different_fail(red, red). 

no
| ?- different_fail(red, blue).
</code></pre>
<p>Up to here everything works as expected.</p>
<pre><code>yes
| ?- different(red, A).        

A = blue ? ;

A = green

yes
| ?- different_fail(red, A).

no
</code></pre>
<p>But here I would expect that <code>different_fail</code> yields the exact results as <code>different</code>.</p>
<p>What is the difference in these functions, which cause my <code>different_fail</code> to fail?</p>
",<prolog>
26132153,Configure a Logitech corded mouse's special buttons to work when connected to KVM switch,"<p>Here is the equipment I'm using:<br>
- Logitech M500 corded mouse<br>
- ioGear 2-port (DVI + USB) KVM switch<br>
- Macbook Pro w/ OSX Mavericks<br></p>

<p>Problem:<br>
When I try to configure the M500's special buttons (mouse wheel button, back/forward buttons) to work with OSX Mavericks via Logitech Control Center (LCC), I get an error message ""No Logitech Device Found.""</p>

<p>I contacted Logitech and they said that LCC is not compatible with KVM switches. </p>

<p>Any alternatives?</p>
",<macos><mouse><osx-mavericks><kvm><logitech>
42524385,Logrotate encryption before mailing,"<p>I use logrotate that sends me logs on a regular basis. My server is a VPS running Postfix as an outgoing-only SMTP server. </p>

<p>I would like all the mailed logs (which Logrotate sends) to be encrypted with PGP or S/MIME. How can I do that?</p>

<p>I searched for logrotate mail encryption, but couldn't find any. Therefore, I'm thinking that I can pass ""nomail"" command in logrotate config, but then add in the ""postscript"" a script to first encrypt the mail and then send. </p>

<p>So, is there a better way to encypt logrotate mail with PGP? Or that's what I need to do? I would appreciate any advise or an example of such a script. </p>

<p>Also, I'm not considering to use TLS as there are possible ways to bypass it in the SMTP server. And I would rather rely on encryption of individual messages.</p>

<p>Thanks! </p>

<p>Edit:</p>

<p>Here is my script I'm using for custom email sending(Without GPG for now):</p>

<pre><code>#!/bin/bash
read MSG
echo $MSG | mail -s $1 $2
</code></pre>

<p>But when I force rotate with <code>logrotate --mail=loggpg.sh --force /etc/logrotate.d/ufw</code> I keep getting error about uncompression, do I need to manually uncompress it? Or there is smth wrong with the script?</p>

<p>Error I get:</p>

<pre><code>error: mail command failed for /var/log/ufw.log.5.gz
error: uncompress command failed mailing /var/log/ufw.log.5.gz`
</code></pre>
",<email><logging><smtp><pgp><logrotate>
47331625,Symfony exclude 400 errors from log,"<p>I noticed that when I throw a <code>BadRequestHttpException</code> it is logged with Monolog.</p>

<p>How can I exclude specific exceptions and HTTP errors from my log? My configuration is the following:</p>

<pre><code>monolog:
    handlers:
        main:
            type: fingers_crossed
            action_level: error
            handler: nested
            excluded_404s:
                - ^/
        nested:
            type: rotating_file
            path: '%kernel.logs_dir%/%kernel.environment%.log'
            level: debug
            max_files: 30
</code></pre>

<p>Since this is an API website I have a lot of ""good"" 400 errors which should not be logged.</p>

<p>Note: I don't want to raise the level to <strong>critical</strong>.</p>
",<php><symfony><monolog>
28373915,Structured Logging in a relational database,"<p>How to design the relational database layout to capture structured logging?</p>

<p><strong>Usecase 1</strong></p>

<p>The output of sensors should be logged. Data: temperature and sensor-id.</p>

<p><strong>Usecase 2</strong></p>

<p>The duration of web requests should be logged. One entry for every request. Data: URL and duration</p>

<p><strong>Common data</strong></p>

<p>The two usecases are just examples. There could be much more. Each log entry should have a timestamp and a source-host column</p>

<p><strong>Relational</strong></p>

<p>Please don't tell my to use noSQL. This particular question is about a relational database layout. :-)</p>

<p>Our preferred database is PostgreSQL, but this should not matter here.</p>
",<postgresql><database-design><relational-database>
11503784,log4net rolling file appender file name format when maximumFileSize reached,"<p>We're using the log4net rolling file appender and have the following requirements for our log files:</p>

<ul>
<li>A new log file at the start of each day, with the date in the filename</li>
<li>A maximum log file size of 500KB</li>
</ul>

<p>The issue we are having is the file naming strategy when files hit 500KB: they get renamed with a <code>.1</code> suffix. This is problematic as it breaks file association in Windows, so opening the files is (slightly) more of a chore.</p>

<p>The configuration we're using is:</p>

<pre class=""lang-xml prettyprint-override""><code>&lt;appender name=""RollingFileAppender"" type=""log4net.Appender.RollingFileAppender""&gt;
  &lt;file value=""c:\log\path"" /&gt;
  &lt;staticLogFileName value=""false"" /&gt;
  &lt;appendToFile value=""true"" /&gt;
  &lt;rollingStyle value=""Composite"" /&gt;
  &lt;datePattern value="".yyyy-MM-dd.lo\g"" /&gt;
  &lt;lockingModel type=""log4net.Appender.FileAppender+MinimalLock"" /&gt;
  &lt;maxSizeRollBackups value=""50"" /&gt;
  &lt;maximumFileSize value=""500KB"" /&gt;
  &lt;layout type=""log4net.Layout.PatternLayout""&gt;
    &lt;conversionPattern value=""%date [%thread] %-5level %message%newline"" /&gt;
  &lt;/layout&gt;
&lt;/appender&gt;
</code></pre>

<p>Is there support for specifying the naming strategy used when our files hit the <code>maximumFileSize</code>?</p>
",<log4net><rollingfileappender>
11033981,how to setup logback for maven tests,"<p>When I'm running the maven tests from my IntelliJ environment i can see all the application setup logs. I'm working with logback. 
But when I'm running same maven tests on jenkins, there is no output for application logs. 
Thus I have some tests that fails on linux and i have no idea why.</p>

<p>How can I make the logs be printed when i'm running: </p>

<pre><code> mvn clean -DskipTests=false test 
</code></pre>
",<java><maven><jenkins>
19713419,Python logging over UDP ignoring setLevel(),"<p>I'm trying to filter Python logging messages coming over UDP, but for some reason setting loglevel on the receiving end doesn't seem to affect the incoming messages.</p>

<p>The receiving end's code is as follows:</p>

<pre><code>import cPickle
import logging
import socket

logging.basicConfig(format='%(asctime)s %(levelname)-8s %(message)s')
logger = logging.getLogger()
logger.setLevel(logging.INFO)

s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.bind(('', 51010))

while True:
    d, _ = s.recvfrom(1024)
    log = cPickle.loads(d[4:])
    logger.handle(logging.makeLogRecord(log))
</code></pre>

<p>Despite the fact that I've set the logging level to logging.INFO, I am still seeing debug messages. If I add </p>

<pre><code>logging.debug(""Debug"")
logging.info(""Info"")
</code></pre>

<p>before the while loop, I see the info message, but not the debug one, indicating that the setLevel is working locally, but doesn't affect messages coming over the UDP socket.</p>

<p>Any ideas why this would occur? If I manually check the 'levelno' field of the dict that is received (which is then turned into a log record), it is 10 (debug), but filtering doesn't seem to care...</p>

<p>Thanks!</p>

<p>EDIT:</p>

<p>For reference, the code generating the packets being sent over UDP is simply</p>

<pre><code>import logging
import logging.handlers
import time

logging.basicConfig(level=logging.DEBUG,
    format='%(asctime)s %(levelname)-8s %(message)s')

logging.getLogger().addHandler(logging.handlers.DatagramHandler('', 51010))

while True:
    logging.debug(""This shouldn't show up"")
    logging.info(""This should show up"")
    time.sleep(3)
</code></pre>
",<python><logging><udp>
26892509,iOS enabling custom logger in release mode,"<p>In a recent application, i have been asked to enable debug logging when releasing builds so the testers can send us the log when testing the application.
I have created a custom logger which depends on #IF DEBUG macro to enable or disable custom logging.
This works fine on debug mode. But when i build a new release (with Bamboo) the testers could not see the custom log anymore.
How can i enable my custom logging in release mode (via gcc_preprocessor_macros)? Should i rely on other preprocessor macros and ignore the DEBUG directive ?</p>
",<ios><objective-c><debugging><logging><release>
48243410,How to configure BLE Wifi Sniffer and Node Red on Synology,"<p>I've bought a Wireless IBeacon Receiver BLE 4.0 WI-FI Sniffer <a href=""https://www.aliexpress.com/item/New-arrival-Wireless-iBeacon-Receiver/32463483551.html?spm=2114.search0104.3.1.E5Nlpv&amp;ws_ab_test=searchweb0_0,searchweb201602_5_10152_10151_10065_10344_10068_10342_10343_10059_10340_10314_10341_10534_100031_10084_10604_10083_10103_10304_10307_10615_10301_10142-10152_10151,searchweb201603_25,ppcSwitch_7&amp;algo_expid=4b4879e7-ae62-4317-900d-c62510a648f9-0&amp;algo_pvid=4b4879e7-ae62-4317-900d-c62510a648f9&amp;priceBeautifyAB=0"" rel=""nofollow noreferrer"">here</a> installed Node Red on my Synology DS414j. I've been able to configure the sniffer to use my local WLAN and I can access the webpages on the sniffer. So far so good.</p>

<p>Now I'm trying to connect MQTT node from Node Red to the device. Maybe I'm not understanding thing correctly but I would have expected this to work.</p>

<p>There is a Wiki <a href=""http://wiki.aprbrother.com/wiki/Wireless_iBeacon_Receiver/en#How_to_Config"" rel=""nofollow noreferrer"">here</a> but that does not contain a lot of information. I tried signing on the forum but the confirmation mails never arrives.</p>

<p>Configuration of the sniffer:</p>

<ol>
<li>I've added my SSID, security token for my WLAN. That works.</li>
<li>Device mode is configured to 'Station'</li>
<li>MQTT is configured to the IP of the NAS port 1883. With credentials. Topic is set to '/beacons'.</li>
<li>Node Red node is configured to IP of device port 1883, with credentials.</li>
</ol>

<p>Questions:</p>

<ol>
<li>Does it work the way I think this should work. Is it possible to have the MQTT Node Red node to connect to the device or do I need something else?</li>
<li>The sniffer can be put into 3 modes. Station, P2P and Access Point. I've now configured it at Station. Does anyone know what this setting means?</li>
<li>Node Red says 'connecting' but never connects. I've also installed a MQTT Dashboard on my Samsung Phone. It says 'connection failed'. What am I doing wrong? Do I need SSL/TLS? to be activated?</li>
</ol>
",<mqtt><node-red><synology>
39247924,"SLF4J: Required log4j version not found, but in pom","<p>Using Eclipse Aether, I get the following error:</p>

<p>SLF4J: This version of SLF4J requires log4j version 1.2.12 or later. See also <a href=""http://www.slf4j.org/codes.html#log4j_version"" rel=""nofollow"">http://www.slf4j.org/codes.html#log4j_version</a></p>

<p>In my Maven dependency tree, I clearly have log4j 1.2.14 (last line):</p>

<pre><code>de.continentale.spu:rrep-pjava-deployer:jar:1.0.0-SNAPSHOT
+- org.slf4j:slf4j-log4j12:jar:1.7.9:compile
|  \- org.slf4j:slf4j-api:jar:1.7.9:compile
+- junit:junit:jar:4.11:test
|  \- org.hamcrest:hamcrest-core:jar:1.3:test
+- org.eclipse.aether:aether-impl:jar:1.1.0:compile
|  +- org.eclipse.aether:aether-api:jar:1.1.0:compile
|  +- org.eclipse.aether:aether-spi:jar:1.1.0:compile
|  \- org.eclipse.aether:aether-util:jar:1.1.0:compile
+- org.eclipse.aether:aether-connector-basic:jar:1.1.0:compile
+- org.eclipse.aether:aether-transport-file:jar:1.1.0:compile
+- org.eclipse.aether:aether-transport-http:jar:1.1.0:compile
|  +- org.apache.httpcomponents:httpclient:jar:4.3.5:compile
|  |  +- org.apache.httpcomponents:httpcore:jar:4.3.2:compile
|  |  \- commons-codec:commons-codec:jar:1.6:compile
|  \- org.slf4j:jcl-over-slf4j:jar:1.6.2:compile
+- org.apache.maven:maven-aether-provider:jar:3.3.3:compile
|  +- org.apache.maven:maven-model:jar:3.3.3:compile
|  +- org.apache.maven:maven-model-builder:jar:3.3.3:compile
|  |  +- org.codehaus.plexus:plexus-interpolation:jar:1.21:compile
|  |  +- org.apache.maven:maven-builder-support:jar:3.3.3:compile
|  |  \- com.google.guava:guava:jar:18.0:compile
|  +- org.apache.maven:maven-repository-metadata:jar:3.3.3:compile
|  +- org.codehaus.plexus:plexus-component-annotations:jar:1.5.5:compile
|  \- org.codehaus.plexus:plexus-utils:jar:3.0.20:compile
+- de.continentale.spu:rrep-pjava-index:jar:0.0.1-SNAPSHOT:compile
|  \- de.regnis.q.sequence:sequence-library:jar:1.0.2:compile
+- org.tmatesoft.svnkit:svnkit:jar:1.8.12:compile
|  +- com.jcraft:jsch.agentproxy.svnkit-trilead-ssh2:jar:0.0.7:compile
|  |  \- com.jcraft:jsch.agentproxy.core:jar:0.0.7:compile
|  +- com.trilead:trilead-ssh2:jar:1.0.0-build220:compile
|  +- net.java.dev.jna:jna-platform:jar:4.1.0:compile
|  +- net.java.dev.jna:jna:jar:4.1.0:compile
|  \- com.jcraft:jsch.agentproxy.connector-factory:jar:0.0.7:compile
|     +- com.jcraft:jsch.agentproxy.usocket-jna:jar:0.0.7:compile
|     |  \- net.java.dev.jna:platform:jar:3.4.0:compile
|     +- com.jcraft:jsch.agentproxy.usocket-nc:jar:0.0.7:compile
|     +- com.jcraft:jsch.agentproxy.sshagent:jar:0.0.7:compile
|     \- com.jcraft:jsch.agentproxy.pageant:jar:0.0.7:compile
+- org.tmatesoft.sqljet:sqljet:jar:1.1.9:compile
|  \- org.antlr:antlr-runtime:jar:3.4:compile
+- commons-io:commons-io:jar:2.4:compile
+- org.apache.commons:commons-lang3:jar:3.1:compile
\- log4j:log4j:jar:1.2.14:compile
</code></pre>

<p>It is unclear to me how to avoid the SLF4J error.</p>

<p>EDIT:</p>

<p>I am using Eclipse aether to contact a Maven repository</p>

<pre><code>private static RepositorySystem newRepositorySystem()
{
DefaultServiceLocator locator = MavenRepositorySystemUtils
    .newServiceLocator();
locator.addService(RepositoryConnectorFactory.class,
    BasicRepositoryConnectorFactory.class);
locator.addService(TransporterFactory.class, FileTransporterFactory.class);
locator.addService(TransporterFactory.class, HttpTransporterFactory.class);
RepositorySystem service = locator.getService(RepositorySystem.class);
return service;
}
</code></pre>

<p>The line <code>RepositorySystem service = locator.getService(RepositorySystem.class);</code> produces the error because it is probably the first position where SLF4J is contacted.</p>
",<java><maven><log4j><slf4j>
39912918,Can I reduce the size of my catalog_product_index_eav table or increase my indexing speed?,"<p>In Magento 1.9.2.4 table catalog_product_index_eav contains 3.802.998 records and catalog_product_index_eav_idx contains 2.447.411 records. The sizes of other tables are 100000 records or less, normal sizes I think.</p>

<p>Reindexing table catalog_product_attributes takes a lot of time in the CLI, more then 10 minutes or fails because losing the mysql connection.</p>

<p>I think the big size of table catalog_product_index_eav is related to taking a lot of time indexing Product Attributes.</p>

<p>There are no files in the var/locks directory. In my magento test environment I have truncated table catalog_product_index_eav and reindexing again. Table catalog_product_index_eav stays empty and indexing takes a lot of time.</p>

<p>I have 8GB mysql memory with mysql server mariaDB on Ubuntu.</p>

<p>Is there a way to reduce the size of catalog_product_index_eav or speed up indexing?</p>
",<magento><magento-1.9><reindex>
76987630,Mouse cursor stops moving in the Logcat window in Android Studio,"<p>I'm on the latest Android Studio beta (Android Studio Hedgehog | 2023.1.1 Beta 1) on a Macbook Pro 2015 running macOS High Sierra.</p>
<p>I've been facing this issue since the last few beta versions. The moment my mouse cursor moves to the Logcat windows, it stops moving. As I try to move it, the cursor turns into the &quot;I&quot; shape as it does over some editable text and then it starts flickering and I'm unable to move the cursor with my mouse or the trackpad.</p>
<p>If I press Command+A and select all the text, then the cursor starts operating as normal again.</p>
<p>Here's a gif to show the issue
<a href=""https://i.stack.imgur.com/HBLH4.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HBLH4.gif"" alt=""enter image description here"" /></a></p>
<p>I have tried clearing cache and restarting Android Studio. I am even on the latest beta. I checked my keyboard to make sure that none of the keys are stuck and everything seems fine.</p>
<p>What might be the issue and how do I fix it?</p>
",<android><android-studio><intellij-idea><logcat>
848782,log4net when to log?,"<p>DOes anyone have any good information with regards to when to log, I was thinking of logging an INFO type when i enter each c# method and recording another info when exiting..</p>

<p>Is this considered good or bad? Will i see a performance hit?</p>

<p>If i do record an INFO when i enter a method, the idea would be to record the method name, and all variable and values</p>

<p>Any idea how this can be done automatically without entering each value and name of method, i suppose i could use reflection but maybe i would see a slow down here?</p>

<p>If reflection would slow things down, maybe i could just use the ""REFLECTION"" bit when there program FAILS hence i can write the stacktrace, all vars, and values.</p>

<p>Any ideas or examples on this really appreciated</p>

<p>Thanks</p>
",<c#><reflection><logging><log4net>
51431929,Liquibase generateChangeLog command generates No Change Sets,"<p>Following <a href=""https://www.liquibase.org/documentation/existing_project.html"" rel=""nofollow noreferrer"">these</a> instructions, executing a generateChangeLog command on my existing PostgreSQL database, the resulting file contains no changeset tags. Maybe I misunderstood something, but I thought the modifications to the database up to this point (tables created, etc.) would be already summed up here, and this was the point of the ""Make It Look Like You've Always Been Using Liquibase"" option.</p>

<p>If this is not a correct assumption, and going forward if I make a modification directly to the database that I want to be described as a changeSet, how do I use the Liquibase command line to add these changesets to the file?</p>

<p>EDIT:</p>

<p>Here is an example of stepping through generateChangeLog and update:</p>

<pre><code>./liquibase --driver=org.postgresql.Driver --classpath=postgresql-42.2.4.jar --changeLogFile=changelog1.xml --url=""jdbc:postgresql://localhost:5432/my_database"" --username=postgres --password=postgres --logLevel=debug generateChangeLog
</code></pre>

<p>Output:</p>

<blockquote>
  <p>DEBUG 7/20/18 8:15 PM: liquibase: Connected to postgres@jdbc:postgresql://localhost:5432/my_database</p>
  
  <p>DEBUG 7/20/18 8:15 PM: liquibase: Setting auto-commit to false from true</p>
  
  <p>DEBUG 7/20/18 8:15 PM: liquibase: Computed checksum for 1532117738554 as 2d79fcfb744a18b475eac6c1d1bd804d</p>
  
  <p>DEBUG 7/20/18 8:15 PM: liquibase: Executing QUERY database command: SELECT c.relname AS SEQUENCE_NAME FROM pg_class c join pg_namespace on c.relnamespace = pg_namespace.oid WHERE c.relkind='S' AND nspname = 'public' AND c.oid not in (select d.objid FROM pg_depend d where d.refobjsubid > 0)</p>
  
  <p>INFO 7/20/18 8:15 PM: liquibase: changelog1.xml does not exist, creating</p>
  
  <p>DEBUG 7/20/18 8:15 PM: liquibase: MissingObjectChangeGenerator type order:     liquibase.structure.core.Catalog    liquibase.structure.core.Schema    liquibase.structure.core.Sequence    liquibase.structure.core.StoredProcedure    liquibase.structure.core.Table    liquibase.structure.core.Column    liquibase.structure.core.PrimaryKey    liquibase.structure.core.UniqueConstraint    liquibase.structure.core.Index    liquibase.structure.core.ForeignKey    liquibase.structure.core.View</p>
  
  <p>DEBUG 7/20/18 8:15 PM: liquibase: UnexpectedObjectChangeGenerator type order:     liquibase.structure.core.Catalog    liquibase.structure.core.ForeignKey    liquibase.structure.core.Schema    liquibase.structure.core.StoredProcedure    liquibase.structure.core.UniqueConstraint    liquibase.structure.core.View    liquibase.structure.core.Table    liquibase.structure.core.PrimaryKey    liquibase.structure.core.Column    liquibase.structure.core.Index    liquibase.structure.core.Sequence</p>
  
  <p>DEBUG 7/20/18 8:15 PM: liquibase: ChangedObjectChangeGenerator type order:     liquibase.structure.core.Catalog    liquibase.structure.core.ForeignKey    liquibase.structure.core.Schema    liquibase.structure.core.Sequence    liquibase.structure.core.StoredProcedure    liquibase.structure.core.Table    liquibase.structure.core.Column    liquibase.structure.core.PrimaryKey    liquibase.structure.core.UniqueConstraint    liquibase.structure.core.Index    liquibase.structure.core.View
  Liquibase 'generateChangeLog' Successful</p>
</blockquote>

<p>At this point in my local PostgreSQL server, my_database has 2 schemas, one named my_schema (containing 11 tables populated with data that my application is using) and the other named public. The public has no tables.</p>

<p>Running liquibase update:</p>

<pre><code>./liquibase --driver=org.postgresql.Driver --classpath=postgresql-42.2.4.jar --changeLogFile=changelog1.xml --url=""jdbc:postgresql://localhost:5432/my_database"" --username=postgres --password=postgres --logLevel=debug update
</code></pre>

<p>Returns:</p>

<blockquote>
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Connected to postgres@jdbc:postgresql://localhost:5432/my_database</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Setting auto-commit to false from true</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing QUERY database command: select count(*) from public.databasechangeloglock</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Create Database Lock Table
  DEBUG 7/20/18 8:21 PM: liquibase: Executing EXECUTE database command: CREATE TABLE public.databasechangeloglock (ID INT NOT NULL, LOCKED BOOLEAN NOT NULL, LOCKGRANTED TIMESTAMP WITHOUT TIME ZONE, LOCKEDBY VARCHAR(255), CONSTRAINT PK_DATABASECHANGELOGLOCK PRIMARY KEY (ID))</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Created database lock table with name: public.databasechangeloglock</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing QUERY database command: select count(*) from public.databasechangeloglock</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Initialize Database Lock Table</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing EXECUTE database command: DELETE FROM public.databasechangeloglock</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing EXECUTE database command: INSERT INTO public.databasechangeloglock (ID, LOCKED) VALUES (1, FALSE)</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing QUERY database command: SELECT LOCKED FROM public.databasechangeloglock WHERE ID=1</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Lock Database</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing UPDATE database command: UPDATE public.databasechangeloglock SET LOCKED = TRUE, LOCKEDBY = '10.0.2.15 (10.0.2.15)', LOCKGRANTED = '2018-07-20 20:21:26.650' WHERE ID = 1 AND LOCKED = FALSE
  INFO 7/20/18 8:21 PM: liquibase: Successfully acquired change log lock</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Resolving XML entity name='null', publicId='null', baseURI='null', systemId='<a href=""http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.5.xsd"" rel=""nofollow noreferrer"">http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.5.xsd</a>'</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Opening jar:file:/home/vagrant/Documents/liquibase.jar!/liquibase/parser/core/xml/dbchangelog-3.5.xsd as liquibase/parser/core/xml/dbchangelog-3.5.xsd</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Computed checksum for 1532118089029 as cfbe2a0b147c646104f738103a68b2fd</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Create Database Change Log Table</p>
  
  <p>INFO 7/20/18 8:21 PM: liquibase: Creating database history table with name: public.databasechangelog</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing EXECUTE database command: CREATE TABLE public.databasechangelog (ID VARCHAR(255) NOT NULL, AUTHOR VARCHAR(255) NOT NULL, FILENAME VARCHAR(255) NOT NULL, DATEEXECUTED TIMESTAMP WITHOUT TIME ZONE NOT NULL, ORDEREXECUTED INT NOT NULL, EXECTYPE VARCHAR(10) NOT NULL, MD5SUM VARCHAR(35), DESCRIPTION VARCHAR(255), COMMENTS VARCHAR(255), TAG VARCHAR(255), LIQUIBASE VARCHAR(20), CONTEXTS VARCHAR(255), LABELS VARCHAR(255), DEPLOYMENT_ID VARCHAR(10))</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing QUERY database command: select count(*) from public.databasechangelog</p>
  
  <p>INFO 7/20/18 8:21 PM: liquibase: Reading from public.databasechangelog</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing QUERY database command: SELECT * FROM public.databasechangelog ORDER BY DATEEXECUTED ASC, ORDEREXECUTED ASC</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing QUERY database command: select count(*) from public.databasechangeloglock</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Release Database Lock</p>
  
  <p>DEBUG 7/20/18 8:21 PM: liquibase: Executing UPDATE database command: UPDATE 
  public.databasechangeloglock SET LOCKED = FALSE, LOCKEDBY = NULL, LOCKGRANTED = NULL WHERE ID = 1</p>
  
  <p>INFO 7/20/18 8:21 PM: liquibase: Successfully released change log lock</p>
  
  <p>Liquibase Update Successful</p>
</blockquote>

<p>Now under the Public schema, there are 2 tables, databasechangelog, and databasechangeloglock. databasechangelog is empty, but databasechangeloglock contains one row with id 1 and ""locked boolean"" col ""FALSE"".</p>
",<liquibase>
551412,Check if no user is currently logged on to Windows,"<p>I'm writing a Windows Service application which listens for connections and performs certain tasks as instructed from a different application running on another computer on the network.</p>

<p>One of the tasks ensures no user is currently logged on, locks the workstation, delete some files, and then restarts the system. I considered using <a href=""https://stackoverflow.com/questions/132620/how-do-you-retrieve-a-list-of-logged-in-connected-users-in-c"">this solution</a> to look through the list of running processes and check the user names, determining if no user is logged on by matchhing the user names against SYSTEM, NETWORK, etc. I realized I have PostgreSQL running which uses a user account named postgres so that wouldn't work. Checking if explorer.exe is running also wouldn't work because explorer sometmes crashes, or I sometimes end the process myself and restart it.</p>

<p>What would be a good way of determining that NO user is logged on to a workstation using C#?</p>
",<c#><.net><windows-services>
13401789,No embedded stylesheet instruction for file: error using logback,"<p>I have the following <code>logback.xml</code> configuration: </p>

<pre class=""lang-xml prettyprint-override""><code>&lt;configuration&gt;
  &lt;appender name=""STDOUT"" class=""ch.qos.logback.core.ConsoleAppender""&gt;
    &lt;!-- encoders are assigned the type
         ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --&gt;
    &lt;encoder&gt;
      &lt;pattern&gt;%-4relative [%thread] %-5level %logger{35} - %msg %n&lt;/pattern&gt;
    &lt;/encoder&gt;
  &lt;/appender&gt;

    &lt;appender name=""FILE"" class=""ch.qos.logback.core.rolling.RollingFileAppender""&gt;
    &lt;file&gt;logFile.log&lt;/file&gt;
    &lt;rollingPolicy class=""ch.qos.logback.core.rolling.TimeBasedRollingPolicy""&gt;
      &lt;!-- daily rollover --&gt;
      &lt;fileNamePattern&gt;logFile.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt;

      &lt;!-- keep 30 days' worth of history --&gt;
      &lt;maxHistory&gt;30&lt;/maxHistory&gt;
    &lt;/rollingPolicy&gt;

    &lt;encoder&gt;
      &lt;pattern&gt;%-4relative [%thread] %highlight(%-5level) %cyan(%logger{35}) - %msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
  &lt;/appender&gt; 

  &lt;root level=""DEBUG""&gt;
    &lt;appender-ref ref=""STDOUT"" /&gt;
    &lt;appender-ref ref=""FILE"" /&gt; 

  &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>

<p>If I edit the config file in eclipse (Juno), I get the following error: </p>

<pre><code>11:02:54,114 INFO  [main] Main  - javax.xml.transform.TransformerFactory=null
11:02:54,115 INFO  [main] Main  - java.endorsed.dirs=C:\Program Files\Java\jre7\lib\endorsed
11:02:54,117 INFO  [main] Main  - launchFile: C:\Users\roberth\Programming_Projects\eclipse\.metadata\.plugins\org.eclipse.wst.xsl.jaxp.launching\launch\launch.xml
11:02:54,145 FATAL [main] Main  - No embedded stylesheet instruction for file: file:/C:/Users/roberth/Programming_Projects/eclipse/javaport/src/logback.xml
org.eclipse.wst.xsl.jaxp.debug.invoker.TransformationException: No embedded stylesheet instruction for file: file:/C:/Users/roberth/Programming_Projects/eclipse/javaport/src/logback.xml
    at org.eclipse.wst.xsl.jaxp.debug.invoker.internal.JAXPSAXProcessorInvoker.transform(JAXPSAXProcessorInvoker.java:225)
    at org.eclipse.wst.xsl.jaxp.debug.invoker.internal.JAXPSAXProcessorInvoker.transform(JAXPSAXProcessorInvoker.java:186)
    at org.eclipse.wst.xsl.jaxp.debug.invoker.internal.Main.main(Main.java:73)
Caused by: org.eclipse.wst.xsl.jaxp.debug.invoker.TransformationException: No embedded stylesheet instruction for file: file:/C:/Users/roberth/Programming_Projects/eclipse/javaport/src/logback.xml
    at org.eclipse.wst.xsl.jaxp.debug.invoker.internal.JAXPSAXProcessorInvoker.transform(JAXPSAXProcessorInvoker.java:214)
    ... 2 more
</code></pre>

<p>If I delete and recreate the config, sometimes it works, sometimes not. If I edit the file in Notepad++ or another text editor, it works fine. Is this an eclipse issue or am I missing something? </p>
",<eclipse><logback>
46684164,Velocity initialization error: AvalonLogChute does not implement LogChute,"<p>I am trying to initialize <code>VelocityEngine</code> but getting exception on <code>.init()</code> call: </p>

<pre><code>org.apache.velocity.exception.VelocityException: The specified logger
class org.apache.velocity.runtime.log.AvalonLogChute does not
implement the org.apache.velocity.runtime.log.LogChute interface.
</code></pre>

<p>My code looks like: </p>

<pre><code>VelocityEngine velocityEngine = new VelocityEngine();
velocityEngine.setProperty(....) //I do not change logging properties
...
velocityEngine.init();
</code></pre>

<p>There is no second velocity jar in dependency tree. But there is apache-click jar, which, from what I see, contains it's own Velocity implementation or at least part of it.</p>

<p>So it looks like classloader problem.
I found temporary solution here: <a href=""https://plus.google.com/116012605255269201011/posts/6tviyMPbqTU"" rel=""nofollow noreferrer"">https://plus.google.com/116012605255269201011/posts/6tviyMPbqTU</a></p>

<p>But I wonder if there is any way to solve this problem without substituting thread classloader.</p>
",<java><classloader><velocity>
21937367,the crash log EXC_BAD_ACCESS (SIGSEGV) iTunes connect,"<p>i have test my app on my device it run. But when it submit it to app store, i get a crash log. I desymbolicate it and it show something wrong in line 70 in my code with EXC_BAD_ACCESS (SIGSEGV) error. 
I known it is the memory management problem. But it don't knwon what wrong in my code:
the line 70:</p>

<pre><code>69: distanceLabel = [CCLabelTTF labelWithString:@""0"" fontName:@""Marker Felt"" fontSize:24];
70: distanceLabel.anchorPoint = ccp(1, 1);
71: distanceLabel.position = ccp(size.width/2, size.height-20);
72: distanceLabel.color = ccBLACK;
73: [self addChild:distanceLabel z:20];
</code></pre>

<p>And in the header file i declare the distanceLabel:</p>

<pre><code> @property(nonatomic,unsafe_unretained) CCLabelTTF * distanceLabel;
</code></pre>

<p>So what is problem in my code ?</p>
",<ios>
48509349,Spring boot log4j2 database appender,"<p>I am trying to use log4j2 database appender in a Spring boot project. I don't need any other database use in my project. I tried creating a ConnectionFactory using commons-dbcp2 and commons-pool2 (used sample codes available ), but unfortunately, Spring boot is failing during Startup, stating that it's unable to access ConnectionFactory. Seems like log4j2 is initialized before the ConnectionFactory. Is there a simple way to integrate log4j2 database appender in Spring boot, or it's something not possible? I don't want to make it complicated, and might use a different toolset, if these frameworks are not supposed to collaborate in a simpler manner.
Code that I used for ConnectionFactory:</p>

<pre><code>DriverManagerConnectionFactory connectionFactory = new DriverManagerConnectionFactory(databaseUrl, properties);
PoolableConnectionFactory poolableConnectionFactory = new PoolableConnectionFactory(connectionFactory, null);
GenericObjectPool&lt;PoolableConnection&gt; connectionPool = new GenericObjectPool&lt;PoolableConnection&gt;(
            poolableConnectionFactory);
poolableConnectionFactory.setPool(connectionPool);
this.dataSource = new PoolingDataSource&lt;PoolableConnection&gt;(connectionPool);
</code></pre>
",<spring-boot><log4j2>
47936605,Logs Parse Errors In PHP,"<p>I am working on logging errors in php. I create user define error handler and log the error and save it into DB. There are few type of errors which i am not able to log.</p>

<p><strong>My Error Handler Code...</strong></p>

<pre><code>&lt;?php


/**
  * Parameters:
  *  $errno:   Error level
  *  $errstr:  Error message
  *  $errfile: File in which the error was raised
  *  $errline: Line at which the error occurred
  */

function my_error_handler($errno, $errstr, $errfile, $errline)
{  
  switch ($errno) {
    case E_USER_ERROR:
      // Send an e-mail to the administrator
     // error_log(""Error: $errstr \n Fatal error on line $errline in file $errfile \n"", DEST_EMAIL, ADMIN_EMAIL);
 echo ""Error: $errstr \n  on line $errline in file $errfile"";

 //stack trace
 $host='mysql:host=localhost;dbname=logs';
$user='root';
$password='';
$con=new PDO($host,$user,$password);
$trace=json_encode(debug_backtrace());
$qry=$con-&gt;prepare(""insert into error_log (error_type,error_message,error_file,error_line,stack_trace) values('"".$errno.""','"".$errstr.""','"".$errfile.""','"".$errline.""','"".$trace.""')"");
$qry-&gt;execute();

      // Write the error to our log file
    //  error_log(""Error: $errstr \n Fatal error on line $errline in file $errfile \n"", DEST_LOGFILE, LOG_FILE);
echo ""&lt;br&gt;"";     
     break;

    case E_USER_WARNING:
      // Write the error to our log file
      //error_log(""Warning: $errstr \n in $errfile on line $errline \n"", DEST_LOGFILE, LOG_FILE);
      echo ""$errstr \n in $errfile on line $errline \n"";
       //stack trace
 $host='mysql:host=localhost;dbname=logs';
$user='root';
$password='';
$con=new PDO($host,$user,$password);
$trace=json_encode(debug_backtrace());
$qry=$con-&gt;prepare(""insert into error_log (error_type,error_message,error_file,error_line,stack_trace) values('"".$errno.""','"".$errstr.""','"".$errfile.""','"".$errline.""','"".$trace.""')"");
$qry-&gt;execute();

    case E_USER_NOTICE:
      // Write the error to our log file
      //error_log(""Notice: $errstr \n in $errfile on line $errline \n"", DEST_LOGFILE, LOG_FILE);

     echo ""$errstr \n in $errfile on line $errline \n"";
      //stack trace
 $host='mysql:host=localhost;dbname=logs';
$user='root';
$password='';
$con=new PDO($host,$user,$password);
$trace=json_encode(debug_backtrace());
$qry=$con-&gt;prepare(""insert into error_log (error_type,error_message,error_file,error_line,stack_trace) values('"".$errno.""','"".$errstr.""','"".$errfile.""','"".$errline.""','"".$trace.""')"");
$qry-&gt;execute();
     echo ""&lt;br&gt;"";
      break;

    default:
      // Write the error to our log file
      //error_log(""Unknown error [#$errno]: $errstr \n in $errfile on line $errline \n"", DEST_LOGFILE, LOG_FILE);
      break;
  }

  // Don't execute PHP's internal error handler
  return TRUE;
}


// Use set_error_handler() to tell PHP to use our method
$old_error_handler = set_error_handler(""my_error_handler"");

?&gt;
</code></pre>

<p><strong>Errors I want Log:</strong></p>

<pre><code>trigger_error(""Core Error"",E_CORE_ERROR);
trigger_error(""Core Warning"",E_CORE_WARNING);
trigger_error(""Compile Error"",E_COMPILE_ERROR);
trigger_error(""Compile Warning"",E_COMPILE_WARNING);
trigger_error(""Strict Error"",E_STRICT);
trigger_error(""Recoverable Error"", E_RECOVERABLE_ERROR);
trigger_error(""Depreciated Error"",E_DEPRECATED);
trigger_error(""parse error"",E_PARSE);
trigger_error(""Error"",E_ERROR);
</code></pre>

<p>I want to log all the above mentioned errors, like when something is missing in code like semicolon etc then we got a syntax error etc... so i want log all that errors.... 
I have searched a lot but could not find a solution which best fits my needs, and on most places it says that these error can not be logged by using custom error handler, but i am sure that these errors can be logged because it is also logged when we check it in <strong><em>php_error_log</em></strong> file, so i want the WAY to logged it using custom error handler...
Any help will be greatly appreciated.</p>

<blockquote>
  <p>Please do not comment or down vote the question because of the code i
  paste here, this code is just under the development and i did not
  clean, secure it yet, Only post according / related to the issue.</p>
</blockquote>
",<php><error-handling><error-logging><custom-error-handling>
971217,List of browser as the are listed in IIS logs,"<p>Greetings,</p>

<p>I am looking for a list of browser entries as they are listed in an IIS log to help identify the different versions of browsers which visit our sites.  Perhaps there isn't a list but an algorithm which should be used to identify different browsers and their versions. </p>

<p>Please note that I am not looking for a log analyzer, but the different values I can expect for browser version in a log.  If their isn't a list of these, is there an algorithm I can follow to determine what the browser is and it's version?</p>
",<iis><logging><browser><user-agent>
19967850,Parsing log entries using awk,"<p>I get the below logs:</p>

<pre><code>2013-10-24 18:35:49,728 ERROR [xx.xx.xx.xx.xx.xx] (xx.xx.xx.xx.xx) Manila Olongapo Leyte Tacloban has updated their subscriber details. But, the Regional Account Update interface call has failed for the following Local Registries: &lt;br/&gt;Visayas&lt;br/&gt;Data between LRA and the above Local Registries is out of synch as a result.
</code></pre>

<p>I want the result input to be in the below format. What is the better way to do this — using <code>awk</code> or <code>sed</code> perhaps? Please advise.</p>

<pre><code>$Province$ has updated their subscriber details. However, the Customer Account Update interface call has failed for the following Land Registries:
$Region Name$
</code></pre>
",<parsing><awk>
40586189,Adjust Intercept of Spark DataFrame API Logistic Regression Model,"<p>I'm training a logistic regression in Spark. However, due to specifics in my training data, I need to manually adjust the model afterwards, namely change the intercept.</p>

<p>That was easy to do with the RDD api - just instantiate a new LogisticRegressionModel:</p>

<pre><code>val intercept = model.intercept() + adjustment
val model = new LogisticRegressionModel(model.weights(), intercept)
</code></pre>

<p>However, the LogisticRegressionModel constructor in the DataFrame API was made private. How can I make manual adjustments to the model?</p>
",<apache-spark><apache-spark-mllib>
70380420,How to predict ln(odds) with rcs term in mixed effects logistic model?,"<p>I am using &quot;lme4&quot; package to fit mixed-effects nonlinear logistic model to access the association of Y and X. As the response variable of my data is binary and nlmer function requires response variable to be continuous, I use glmer function and &quot;rms&quot; package function rcs to fit the model and visualize the nonlinear association like the R code below:</p>
<pre><code>library(lme4)
library(rms)
m &lt;- glmer(r2 ~ rcs(Anger, 5) + Gender + situ + btype + (1 | id), 
           data = VerbAgg, family = binomial(&quot;logit&quot;),
           control=glmerControl(optimizer=&quot;bobyqa&quot;))
p &lt;- predict(m, newdata = VerbAgg, type = &quot;link&quot;)
scatter.smooth(VerbAgg$Anger,p,pch='.',col=&quot;blue&quot;,lpars=list(type=&quot;l&quot;,col=&quot;red&quot;))
</code></pre>
<p>I have some questions about using this code:</p>
<ol>
<li>Is the code correct?</li>
<li>How to predict the ln(Odds) of r2? Is it &quot;p &lt;- predict(m, newdata =
VerbAgg, type = &quot;link&quot;)&quot; ?</li>
<li>How to visualize the spline of ln(Odds) of r2 and Anger? Is it
correct to use &quot;scatter.smooth&quot; function to plot and add a smooth
curve in scatters?</li>
<li>How to get the P-nonlinear for this model?</li>
</ol>
",<r><logistic-regression><lme4><mixed-models><spline>
63170424,How to assure reliability of log-to-eventhub policies?,"<p><strong>Problem / Background</strong></p>
<p>For logging every request and response out of API Management, I use a log-to-eventhub policy. My goal is to assure that all logged data of every single request / response is transmitted to Event Hubs.</p>
<p><em>Example Code for log-to-eventhuv-policy</em></p>
<pre><code>&lt;policies&gt;
    &lt;inbound&gt;
        &lt;set-variable name=&quot;test1&quot; value=&quot;1&quot; /&gt;
        &lt;log-to-eventhub logger-id=&quot;CslLog&quot; partition-id=&quot;0&quot;&gt;@{
            return new JObject(
                new JProperty(&quot;test1&quot;, context.Variables[&quot;test1&quot;])
            ).ToString();
        }&lt;/log-to-eventhub&gt;
        &lt;base /&gt;
    &lt;/inbound&gt;
</code></pre>
<p>Unfortunately I could not find any documentation about the reliability of the log-to-eventhub policy.</p>
<p><strong>Goals / Questions</strong></p>
<ol>
<li>In Case the log-to-eventhub policy can not reach the Event Hub for whatever reasons, a reconnection should be tried.</li>
<li>If the transmission of logged data of the requests/responses to Event Hubs finally failed, these requests should throw an error.</li>
</ol>
<p>So far I haven´t found any solution to assure the reliability of transmission of data logged with my log-to-eventhub policy.</p>
<p>Looking forward for your responses.</p>
",<azure><azure-functions><azure-api-management><azure-eventhub>
46575392,Plotting Logistic Regression Non-Scaled values,"<p>I'm new to Python and programming in general. I'm taking a class about Logistic Regression. The code below is correct and plots relatively nice (not so beautiful, but OK):</p>

<pre><code># ------ LOGISTIC REGRESSION ------ #

# --- Importing the Libraries --- #

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from matplotlib.colors import ListedColormap

# --- Importing the Dataset --- #

path = '/home/bohrz/Desktop/Programação/Machine Learning/Part 3 - ' \
       'Classification/Section 14 - Logistic Regression/Social_Network_Ads.csv'
dataset = pd.read_csv(path)
X = dataset.iloc[:, 2:4].values
y = dataset.iloc[:, -1].values

# --- Splitting the Dataset into Training and Test set --- #

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,
                                                    random_state=0)

# --- Feature Scaling --- #

sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

# --- Fitting the Logistic Regression Model to the Dataset --- #

classifier = LogisticRegression(random_state=0)
classifier.fit(X_train, y_train)

# --- Predicting the Test set results --- #

y_pred = classifier.predict(X_test)

# --- Making the Confusion Matrix --- #

cm = confusion_matrix(y_test, y_pred)

# --- Visualizing Logistic Regression results --- #

# --- Visualizing the Training set results --- #

X_set_train, y_set_train = X_train, y_train
X1, X2 = np.meshgrid(np.arange(start=X_set_train[:, 0].min(),
                               stop=X_set_train[:, 0].max(), step=0.01),
                     np.arange(start=X_set_train[:, 1].min(),
                               stop=X_set_train[:, 1].max(), step=0.01))

# Building the graph contour based on classification method
Z_train = np.array([X1.ravel(), X2.ravel()]).T
plt.contourf(X1, X2, classifier.predict(Z_train).reshape(X1.shape), alpha=0.75,
                                                         cmap=ListedColormap(
                                                             ('red', 'green')))

# Apply limits when outliers are present
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())

# Creating the scatter plot of the Training set results
for i, j in enumerate(np.unique(y_set_train)):
    plt.scatter(X_set_train[y_set_train == j, 0], X_set_train[y_set_train == j,
                                                              1],
                c=ListedColormap(('red', 'green'))(i), label=j)

plt.title('Logistic Regression (Trainning set results)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()
</code></pre>

<p>My question is: how do I plot the results with no scale? I tried using invert_transform() method in several places along the code but it didn't help.</p>

<p>Thank you in advance.</p>
",<python><scaling><logistic-regression>
29327371,What is the analogue of CTRL + ARROW in cygwin bash?,"<p>In Windows applications in general, we can step over words by using <code>CTRL+ -&gt;</code> to step right and <code>CTRL + &lt;-</code> to step left. But in Bash, those combinations print <code>3C</code> and <code>3D</code> correspondingly. Is there the analogue of such combination in Cygwin Bash at all?</p>
",<bash><cygwin>
62379394,Python log file didn't properly write logging messages and only the format,"<p>I ran a Python script overnight and found out that the log file is just repeated lines of the message format that I specified rather than the actual messages. In the <code>main</code> module, I created the logger as follows:</p>

<pre><code>from datetime import datetime
import logging
import os


def main():
    msg_format = '[%(asctime)s - %(levelname)s - %(filename)s: %(lineno)d (%(funcName)s)] %(message)s'
    logging.basicConfig(format=msg_format, level=logging.INFO)
    logger = logging.getLogger()
    logger.setLevel(level=logging.INFO)

    timestamp = datetime.now().strftime(format='%Y%m%d-%H%M')
    log_filename = '_'.join(['log', run_type, timestamp]) + '.txt'
    save_pathname = '_'.join([run_type, datetime.now().strftime(format='%Y%m%d')])
    save_path = os.path.join(save_path, save_pathname)

    if not os.path.exists(save_path):
        os.mkdir(path=save_path)

    log_file = os.path.join(save_path, log_filename)
    file_handler = logging.FileHandler(filename=log_file)
    file_handler.setLevel(level=logging.INFO)
    file_handler.setFormatter(fmt=msg_format)
    logger.addHandler(hdlr=file_handler)
    .
    .
    .
</code></pre>

<p>I have <code>logger.info(msg='something')</code> statements throughout my module. When I opened the log file, all I saw was:</p>

<pre><code>[%(asctime)s - %(levelname)s - %(filename)s: %(lineno)d (%(funcName)s)] %(message)s
[%(asctime)s - %(levelname)s - %(filename)s: %(lineno)d (%(funcName)s)] %(message)s
[%(asctime)s - %(levelname)s - %(filename)s: %(lineno)d (%(funcName)s)] %(message)s
[%(asctime)s - %(levelname)s - %(filename)s: %(lineno)d (%(funcName)s)] %(message)s
.
.
.
</code></pre>

<p>What part of the logging initialization went wrong? Am I supposed to explicitly set <code>filemode='w'</code> in the <code>logging.basicConfig</code>? Thanks.</p>
",<python><logging>
47685708,Prolog - Find path and its distance between nodes in a graph with passing through all the nodes,"<p>I am kind of new to prolog and I quite don't understand why this code doesn't work, so I want to find a path and its distance with passing through all the nodes just one time and then returning to the first node here is what I did:</p>

<pre><code>distance(a,b,5).
distance(b,a,5).
distance(a,c,3).
distance(c,a,3).
distance(c,b,2).
distance(b,c,2).


head([H|List],H).
tail([H|List],List).
%Finding the Cycle
  cycle(Node,Cycle) :-
      distance(Node,Next,D),
      cycle(Node,Next,[Node],Cycle).

  cycle(Curr,Curr,Visited,Cycle) :-
      reverse([Curr|Visited],Cycle).
  cycle(Node,Curr,Visited,Cycle) :-
      \+ member(Curr,Visited),
      distance(Curr,Next,D),
      cycle(Node,Next,[Curr|Visited],Cycle).

    %Finding all the possible paths
    find(Start,Cycle):-findall(Z,cycle(Start,Z),Cycle).

    %Selecting only the cycles that contains all the nodes
    path(Start,Cycle,DT):-find(Start,List),
                        path(Start,Cycle,DT,List).
    path(Start,Cycle,DT,List):-head(List,Cycle),
                            tail(List,T),
                            distanceC(Cycle,DT),
                            pathL(Cycle),
                            path(Start,Cycle,DT,T).
%Calculating the distance of a path
distanceC([_],0).
distanceC([X,Y|Rest],DT):-distance(X,Y,D1),distanceC([Y|Rest],DT1), DT is D1 + DT1.
pathL(H):-      length(H,Z),
                Z==3.
</code></pre>

<p><code>path(Start,Cycle,DT,List)</code> doesn't work when I start the Recursion </p>
",<prolog>
29152309,Dimensions of micro-benchmarking in Prolog,"<p>I want to micro-benchmark predicate int_cntA/2 ...</p>

<pre><code>int_cntA(I,W) :- I &gt;= 0, int_cntA0_cntA(I,0,W).

int_cntA0_cntA(0,W0,W) :- !, W0 = W.
int_cntA0_cntA(I,W0,W) :- I0 is I/\(I-1), W1 is W0+1,      int_cntA0_cntA(I0,W1,W).
</code></pre>

<p>... against predicate int_cntB/2:</p>

<pre><code>int_cntB(I,W) :- I &gt;= 0, int_cntB0_cntB(I,0,W).

int_cntB0_cntB(0,W0,W) :- !, W0 = W.
int_cntB0_cntB(I,W0,W) :- I0 is I&gt;&gt;1,     W1 is W0+(I/\1), int_cntB0_cntB(I0,W1,W).
</code></pre>

<p>I'm not 100% sure about what I need to consider to get good results... What are even interesting dimensions?</p>

<p>So far, I came up with: Should I include meta-call performance into the benchmark or should it be about raw number crunching? Should the loop be failure driven or not? Should I care about the garbage generated during execution or not?</p>

<p>The following code snippet is a simple benchmark implementation that goes for raw performance, is failure driven and does (thus) not care about garbage:</p>

<pre><code>:- use_module(library(between)).

rep_10.
rep_10.
rep_10.
rep_10.
rep_10.
rep_10.
rep_10.
rep_10.
rep_10.
rep_10.

rep_100M :- rep_10, rep_10, rep_10, rep_10, rep_10, rep_10, rep_10, rep_10.
</code></pre>

<p>Code for int_cntA/2:</p>

<pre><code>benchA_1(I,W,Rt) :- statistics(runtime,_),
                    ( repeat(100000000),      int_cntA(I,W), false ; true ),
                    statistics(runtime,[_,Rt]),
                    int_cntA(I,W).

benchA_2(I,W,Rt) :- statistics(runtime,_),
                    ( between(1,100000000,_), int_cntA(I,W), false ; true ),
                    statistics(runtime,[_,Rt]),
                    int_cntA(I,W).

benchA_3(I,W,Rt) :- statistics(runtime,_),
                    ( rep_100M,               int_cntA(I,W), false ; true ),
                    statistics(runtime,[_,Rt]),
                    int_cntA(I,W).
</code></pre>

<p>Code for int_cntB/2:</p>

<pre><code>benchB_1(I,W,Rt) :- statistics(runtime,_),
                    ( repeat(100000000),      int_cntB(I,W), false ; true ),
                    statistics(runtime,[_,Rt]),
                    int_cntB(I,W).

benchB_2(I,W,Rt) :- statistics(runtime,_),
                    ( between(1,100000000,_), int_cntB(I,W), false ; true ),
                    statistics(runtime,[_,Rt]),
                    int_cntB(I,W).

benchB_3(I,W,Rt) :- statistics(runtime,_),
                    ( rep_100M,               int_cntB(I,W), false ; true ),
                    statistics(runtime,[_,Rt]),
                    int_cntB(I,W).
</code></pre>

<p>On an Intel Core i7 Haswell machine running SICStus Prolog 4.3.1 worst-case performance differences due to the different benchmarking methods (A,B,C) exceed 100%:</p>

<pre><code>| ?- benchA_1(0,W,Rt).
W = 0,
Rt = 3140 ? 
yes
| ?- benchA_2(0,W,Rt).
W = 0,
Rt = 4130 ? 
yes
| ?- benchA_3(0,W,Rt).
W = 0,
Rt = 1960 ? 
yes
</code></pre>

<p>Do you have ideas if/how I could further reduce the overhead of the micro-benchmark? Thank you!</p>
",<prolog><benchmarking><microbenchmark><sicstus-prolog>
28591433,Laravel Monolog Syslog specify individual log file?,"<p>I have Laravel setup so Monolog logs to <code>syslog</code>. Here is whats' in my <code>start/global.php</code>:</p>

<pre><code>$monolog = Log::getMonolog();
$monolog-&gt;pushHandler(new Monolog\Handler\SyslogHandler('mywebsitename'));
</code></pre>

<p>This works well, except all log messages are dumped into <code>/var/log/messages</code>. </p>

<p>How can I specify a specific log file instead of <code>messages</code>? I've seen something called custom ""channels"" with Monolog. Is it something to do with that?</p>

<p>Also, how do I make sure that this log file is rotated like the rest of my log files?</p>
",<laravel><syslog><monolog>
58446681,Implement log4net in asp.net core webapi,"<p>I have a asp.net core web api. As of now I'm using ILogger to log the messages. But ILogger doesn't have Fatal loglevel in it. There is Critical level, but our team requires Fatal word instead of Critical word.Is there any way I can tweak the work which gets printed to logs?  </p>

<p>If not, I want to replace ILogger with log4Net which has Fatal level in it.So this is what I have done , but somehow it is not working.
I have multi layer architecture : <strong>WebApplication1</strong>, <strong>WebApplication1.Helper</strong>  . All these are different projects with in a solution.  </p>

<p>In <strong>WebApplication1</strong>:
I have added Microsoft.Extensions.Logging.Log4Net.AspNetCore reference.<br>
In <strong>startup.cs</strong> </p>

<pre><code>public void ConfigureServices(IServiceCollection apiServices)
    {
        var provider = apiServices.BuildServiceProvider();

        var factory = new LoggerFactory()
               .AddConsole().AddLog4Net().AddApplicationInsights(provider, LogLevel.Information);

        apiServices.AddSingleton(factory);
        apiServices.AddLogging();
        apiServices.AddMvc();
        apiServices.AddOptions();
    }
</code></pre>

<p><strong>HomeController.cs</strong></p>

<pre><code>[Route(""api/[controller]"")]
    [ApiController]
    public class HomeController : Controller
    {
        private readonly ILog4NetHelper _logHelper = new Log4NetHelper();
        [HttpGet]
        public virtual IActionResult GetData()
        {
            try
            {
                _logHelper.Log4NetMessage(""Info"", ""Start GetData"");
                return new OkObjectResult(""Your in Home Controller"");
            }
            catch (Exception ex)
            {
                _logHelper.Log4NetMessage(""Error"", ""Exception in GetData"" + ex.Message);
                throw;
            }
        }
    }
</code></pre>

<p><strong>WebApplication1.Helper project</strong><br>
And in <code>WebApplication1.Helper</code> project , I have added a interface <code>ILog4NetHelper</code> and class which implements this interface <code>Log4NetHelper</code>. Also I have added log4Net config file.</p>

<pre><code>  public class Log4NetHelper : ILog4NetHelper
    {
        readonly ILog _log =log4net.LogManager.GetLogger(typeof(Log4NetHelper));
        public void Log4NetMessage(string type,string message)
        {
            string logMessage = message;    
            switch (type)
            {
                case ""Info"":
                    _log.Info(logMessage);
                    break;
                case ""Error"":
                    _log.Error(logMessage);
                    break;
                case ""Fatal"":
                    _log.Fatal(logMessage);
                    break;
                default:
                    _log.Info(logMessage);
                    break;
            }
        }
    }
</code></pre>

<p>When I host this application and run this, it is giving me a 500 internal server error. The error message is this :</p>

<blockquote>
  <p>InvalidOperationException: Unable to resolve service for type
  'WebApplication1.Helper.Log4NetHelper' while attempting to activate
  'WebApplication1.Helper.Log4NetHelper'.
  Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteFactory.CreateArgumentCallSites(Type
  serviceType, Type implementationType, CallSiteChain callSiteChain,
  ParameterInfo[] parameters, bool throwIfCallSiteNotFound)</p>
</blockquote>

<p>How can I resolve this?</p>
",<c#><log4net><asp.net-core-webapi>
12248379,Eclipse/Android Logcat: open file + go to line from the stack trace,"<p>While debugging with Logcat I'd like be able to open files/scroll to a line  by clicking at  the line numbers in the stack trace - is there any plugin or option that enables this functionality ?</p>

<p>UPD:
Eclipse Java EE IDE for Web Developers.</p>

<p>Version: Indigo Service Release 2
Build id: 20120216-1857</p>

<p>Thanks</p>
",<android><eclipse>
5969321,hsqldb messing up with my server´s logs,"<p>I have a server I made in Java that needs to use a database, I chose HSQLDB.</p>

<p>So I have a lot of entries in my server like:</p>

<pre><code>Logger.getLogger(getClass().getName()).  severe or info  (""Some important information"");
</code></pre>

<p>When I run my server it goes to <code>System.out</code> which I think its the default configuration of <code>java.util.logging?</code>, so far its ok for me, and later I will make it go to a file ...</p>

<p>But, the problem is, when I start hsqldb it messes up with the default configuration and I can´t read my log entries on <code>System.out</code> anymore..</p>

<p>I already tried to change <code>hsqldb.log_data=false</code>, but it still messes up the default configuration.</p>

<p>Can someone help me??
I dont want to log hsqldb events, just my server ones.</p>

<p>Thanks</p>
",<java><logging><hsqldb>
26734289,Coefficients from multinomial logistic regression in sklearn,"<p>I'm running <code>sklearn.linear_model.LogisticRegression</code> on a multi-class problem. From what I understand, the output of the <code>coef_</code> attribute are the coefficients for each feature for each class. What I don't understand is the interpretation in sklearn. For example, in SPSS you would have one class as the base and then interpret the odds in relation to that class, so you'd actually get the coefficients for n-1 classes. That is not the case in sklearn, where I get coefficients for each class. </p>

<p>Example exponentiated coefficients for one feature (for four classes) are:</p>

<p>1.1649  | 1.0660    | 0.9589    | 0.8607</p>

<p>Is this interpretation correct: with one unit value increase for this feature the probability of that instance belonging in the first class increases by ~16%, then by ~7% in second class, and decreases for third and fourth classes?</p>

<p>Also, how can I calculate the p-value for the coefficients?</p>
",<scikit-learn><logistic-regression><multinomial>
5940889,Android Eclipse not hitting breakpoints / not printing to Logcat,"<p>I'm not really sure what else I can do with this. Here's a function that refuses to print the stacktrace whatever I do. I'm not sure if it's because Eclipse isnt' deploying the right .apk to the emulator or if it's something I'm doing. So:</p>

<pre><code>private String getStringFromResponse(HttpResponse response) {
    try {
        InputStream in = response.getEntity().getContent();
        BufferedReader reader = new BufferedReader(new InputStreamReader(in));
        StringBuilder str = new StringBuilder();
        String line = null;
        while((line = reader.readLine()) != null){
            str.append(line);
        }
        in.close();
        String responseXMLString = str.toString();
        return responseXMLString;
    }
    catch(Exception ex) {
        ex.printStackTrace();
        String stackTrace = ex.getStackTrace().toString();
        Log.i(""PPKMCC-NtwrkAccessClass"", stackTrace);
        return null;
    }
}
</code></pre>

<p>There is an exception at <code>str.toString()</code>. I don't know the cause because I'm not able to view the stacktrace. I don't think it's because of the size of the response because the same code was downloading the prefs fine till now.</p>

<p>In the <code>catch</code> block, <code>printStackTrace()</code> doesn't output to the Logcat. I have a break point at <code>String stacktrace</code> but it doesn't hit that particular breakpoint and instead goes directly to <code>return null</code>. I've tried resetting the emulator, creating a completely new emulator instance, cleaning my project, none of them seem to work.</p>

<p>Any help is much appreciated! </p>

<p>Thanks, <br />
Teja.</p>
",<android><eclipse>
48444755,Batch script to read a specific line from a log file,"<p>I am trying to write a batch script that reads 18th line from a .log file and outputs the same. The .log file name varies each time. abc_XXXX.log where xxxx are process IDs. Below is the code I am trying to run to achieve this.</p>

<pre><code>:Test1
set ""xprvar="" for /F ""skip=17 delims="" %%p in (abc*.log) do (echo %%p&amp; goto 
break)

:break
pause
goto END  
</code></pre>
",<batch-file>
59241603,Summary of Logistic Regression Model Showing Rows as Coefficients and Not Column Variables,"<p>I have a clinical dataset which is made of subject IDs as rows and different variables as columns. I wanted to make a prediction model and split my data into testing and training data appropriately. I built a logistic regression model but for some reason the summary output for the fit is showing me the subject IDs as coefficients instead of the columns/variables. </p>

<p><strong>This is what the dataset looks like:</strong>  </p>

<pre><code>subjectkey         sex   height      weight   interview_age flanker_score cardsort_score intbehaviour_score
NDAR_INV09AUXBBT    M   59.00000    104.00000     118           107          109            GOOD
NDAR_INV0BVP2PTD    F   50.25000    60.00000      120           92           103            GOOD
NDAR_INV0CV2Y4YR    M   55.30000    97.00000      120           83           94             BAD
NDAR_INV0X45NBYM    M   63.50000    104.50000     128           101          103            BAD
</code></pre>

<p><strong>This is the code I'm using to fit the model:</strong></p>

<pre><code>data.train.glm &lt;- glm(intbehaviour_score~., data = data.train, family = binomial)

#summary of fit
summary(data.train.glm)
</code></pre>

<p><strong>This is the output I'm getting:</strong></p>

<pre><code>Call:
glm(formula = intbehaviour_score ~ ., family = binomial, data = data.train)

Deviance Residuals: 
  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
 [34]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
 [67]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
[100]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
[133]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
[166]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
[199]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
[232]  0  0  0  0

Coefficients: (11 not defined because of singularities)
                             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)                -2.657e+01  3.561e+05       0        1
subjectkeyNDAR_INV0BVP2PTD -5.916e-13  5.036e+05       0        1
subjectkeyNDAR_INV0CV2Y4YR  5.313e+01  5.036e+05       0        1
subjectkeyNDAR_INV0X45NBYM  5.313e+01  5.036e+05       0        1
subjectkeyNDAR_INV10EP1VM2 -6.084e-13  5.036e+05       0        1
</code></pre>

<p>I don't understand why the subject IDs are coming up as the coefficients and not the variables.</p>
",<r><arrays><logistic-regression>
58567539,"What is the difference between a GBM continuous prediction in [0, 1] and a Logistic Regression continous prediction in [0, 1]","<p>From a Gradient Boosted Model, if you get a continuous prediction between 0 and 1, what is the difference in the meaning of this compared to the probability derived from Logistic Regression?</p>

<p>For example, if I had an LR model output .6 for predicting variable Y, and I had a GBM output .7 for predicting variable Y, is there any significance to the higher value?</p>
",<machine-learning><statistics><probability><logistic-regression><gbm>
19345153,Getting empty response on Netflix /catalog/titles/streaming,"<p>I'm using node.js and nodefilx to try this out.  It's a very simple query:</p>

<pre><code>var nodeflix = require('nodeflix');

var n = new nodeflix({
    consumer_key:       'MY_KEY',
    consumer_secret:    'MY_SECRET',
    oauth_token:        '',     // optional, for signed user requests
    oauth_token_secret: '',     // optional, for signed user requests
    user_id:            ''      // optional, for signed user requests
});

// lookup something from the people catalog
n.get('/catalog/titles/streaming',function(data) {
    console.log(data);
});
</code></pre>

<p>I have a valid dev keys, and the query to /catalog/titles (with proper parameters) returns results.  It's very strange because I get """" as a response, not any kind of error.  I've also tried modifying nodefilx and adding ""Accept-Encoding : gzip"" to the header but the gzip'd response is still empty.  </p>

<p>When I try this manually in chrome, I do get a response.  Is there something else in the headers that I need to add?</p>
",<node.js><netflix>
32333494,How to display String constant value in the Log,"<p>I have constant String values in the strings.xml, and I want to display some of these values from the Log.i. I tried the following</p>

<pre><code>Log.w(TAG, Integer.toString(R.String.bt_value));
</code></pre>

<p>But at run time, what is getting displayed is ""R.String.bt_value""</p>

<p>How to display that value correctly?</p>
",<android><android-resources>
12611144,php-error.log reports the same error multiple times,"<p>php-error.log keeps reporting the same error multiple times. Seems like with every browser request. Caching is disabled on most pages as this is a dynamic site with user-generated content.</p>

<p>In php.ini, both ignore_repeated_errors and ignore_repeated_source are On.</p>

<p>Does anybody have any ideas to fix this?</p>

<p>Thank you in advance</p>
",<php>
30337360,log4cxx: sending log to log server?,"<p>We have a single threaded application and has to remain single threaded for some reasons. We have a large volume of runtime debug log using log4cxx. What's the best way to do the logging without impact the performance of the application?</p>

<p>I know log4cxx can send log to
* local files directly. This can slow down the application quite a lot. Profiling already confirmed this.
* sending to local syslog. I suppose that this may not be much different from sending to local files directly.
* sending to SocketAppender. I tested using log4j's SimpleSocketServer. The performance is no better than writing files directly. I haven't looked at source code for SimpleSocketServer. The most naive implementation is that SocketAppender is using blocking write, while SimpleSocketServer uses blocking reads from socket and only do next read when it finished writing current log entries. This will perform the same as logging to local file directly.</p>

<p>I guess that we'll have to write a logging server, with 1 threading reads from socket and put the msg on the queue and another thread writes the msg to log file.</p>

<p>There is likely such a free logging server somewhere on the internet. Before start searching for such a server or write one ourselves, are there any other solutions?</p>

<p>Thanks. </p>
",<log4cxx>
13915275,'git log' for a specific file is missing commits,"<p>Yesterday I committed some changes in a file named <em>Network.java</em>. Today I pulled with rebase from the origin. Now the changes are gone in the file.</p>
<p>What is more interesting is that if I run <code>git log -p</code> and search for <em>Network.java</em>, I see the commit with the changes. However, if I run <code>git log -p -- &lt;path to Network.java&gt;</code>, then I don't see my commit (it shows a commit made a week ago).</p>
<p>What is the explanation?</p>
",<git>
58251082,Bayesian logistic regression,"<p>I need to perform a bayesian logistic regression in r. I used the 'arm' package but I don't really understand the outcome. My code: </p>

<pre><code>M2 &lt;- bayesglm (y ~  x1 +  x2 + x3 + x4 + x5 + x6, family=binomial(link=""logit""),data=data,
    prior.scale=Inf, prior.df=Inf)
display (M2)

</code></pre>

<p>Is there a way to obtain results comparable to the classical logistic regression? Or a better way to perform bayesian logistic regression?</p>
",<r><logistic-regression><bayesian>
9451245,use svn log as debian package changelog,"<p>I want to use my svn log as debian/changelog file used by dpkg-buildpackage in package building. </p>

<p>I tried svn2cl in subversion-tools package to create a changelog from svn log but it  is not formatted as a standard debian changelog.</p>
",<svn><debian><package-managers><changelog>
11057745,Mercurial log/diff for range of lines in a file,"<p>I'd like an extension or tool that helps me browse the history of a range of lines in a given file.  Say I want to look at the history of a particular function, currently at lines [start, end].  hg annotate gets me started:</p>

<pre><code>AAA  772 06-Aug-02: void Graphics2DDXF::lineTo(double x, // the x coordinate
AAA  772 06-Aug-02:                            double y // the y cooordinate
AAA  772 06-Aug-02:                            )
AAA  772 06-Aug-02:     {
BBB 2034 30-Aug-04:     LOG;
BBB 6989 05-Dec-11: 
BBB 4638 31-Oct-07:     transform_-&gt;transform(&amp;x,&amp;y);
AAA  772 06-Aug-02: 
BBB 7011 06-Jan-12:     AGcRoot&lt;Line&gt; line = gcnew Line;
BBB 6989 05-Dec-11: 
BBB 6989 05-Dec-11:     Point3d startPoint(lastPenLocation_-&gt;x(), lastPenLocation_-&gt;y(), 0.0);
BBB 6989 05-Dec-11:     Point3d endPoint(x, y, 0.0);
BBB 6989 05-Dec-11:     line-&gt;StartPoint = startPoint;
BBB 6989 05-Dec-11:     line-&gt;EndPoint = endPoint;
BBB 6989 05-Dec-11: 
BBB 4638 31-Oct-07:     lastPenLocation_ = APoint2D::New(x,y,AToleranceID::None);
BBB 7011 06-Jan-12: 
BBB 7011 06-Jan-12:     setAndAddEntity(line);
AAA  772 06-Aug-02:     }
</code></pre>

<p>The last change to this method was changeset 7011.  I can examine that with 'hg diff -c7011'.</p>

<p>The hard part is what happened before that.  Starting with the annotate output for 7011-1:</p>

<pre><code>% hg annotate -r7010 file.cpp
...
AAA  772 06-Aug-02: void Graphics2DDXF::lineTo(double x, // the x coordinate
AAA  772 06-Aug-02:                            double y // the y cooordinate
AAA  772 06-Aug-02:                            )
AAA  772 06-Aug-02:     {
BBB 2034 30-Aug-04:     LOG;
BBB 6989 05-Dec-11: 
BBB 4638 31-Oct-07:     transform_-&gt;transform(&amp;x,&amp;y);
AAA  772 06-Aug-02: 
BBB 6989 05-Dec-11:     Line^ line = gcnew Line;
AAA  772 06-Aug-02:     addEntityToModelSpace(line);
AAA  772 06-Aug-02: 
AAA  772 06-Aug-02:     ensureLayerAvailable();
BBB 6989 05-Dec-11:     line-&gt;LayerId = s_currentLayerObjectId;
BBB 6989 05-Dec-11: 
BBB 6989 05-Dec-11:     Point3d startPoint(lastPenLocation_-&gt;x(), lastPenLocation_-&gt;y(), 0.0);
BBB 6989 05-Dec-11:     Point3d endPoint(x, y, 0.0);
BBB 6989 05-Dec-11:     line-&gt;StartPoint = startPoint;
BBB 6989 05-Dec-11:     line-&gt;EndPoint = endPoint;
BBB 6989 05-Dec-11: 
BBB 6989 05-Dec-11:     line-&gt;LinetypeId = currentLinetypeId();
BBB 6989 05-Dec-11:     line-&gt;ColorIndex = dwgColor(getColor());
BBB 4638 31-Oct-07:     lastPenLocation_ = APoint2D::New(x,y,AToleranceID::None);
AAA  772 06-Aug-02:     }
</code></pre>

<p>So now I can see that the previous changeset affecting this range of lines was 6989.  And so on.</p>

<p>It would be great to have a visual tool that did this, but I would be happy with something that just gave me the sequence of changesets: 7011, 6989, etc.</p>

<p>It wouldn't be hard to filter the annotate output for the linenumber range and find the maximum changeset number.  What is hard is adjusting the range of lines to account for lines added and removed, especially when 'diff' claims that a change spanned the min or max of your range of lines.  At least that was hard with CVS diff output, I haven't tried it with hg diff's output.</p>

<p>If the tool/extension I'm dreaming of doesn't exist, are there at least any tools for computing the modified line numbers?</p>

<p>Thanks,</p>
",<mercurial><diff><history>
13059542,Why MVC4 web app does not use logged in windows authentication credential to access MVC4 web api service,"<p>My MVC4 web-app uses AppPoolIdentity to access MVC4 web-api service running on a different server, instead of using logged in user's Windows authentication credentials. Windows authentication is enabled on both sites. </p>

<p>Http client code to access web-api service;</p>

<pre><code>using (HttpClientHandler _clientHandler = new HttpClientHandler())
{
_clientHandler.UseDefaultCredentials = true;
using (HttpClient _client = new HttpClient(_clientHandler, true))
{
// code to get data
}
}
</code></pre>

<p>I am using ApiController.User to get logged in user's details at web-api controller.</p>

<p>How do I get logged in user's credentials passed over to web-api service?</p>
",<asp.net-mvc-4>
77141052,Is there a way to apply differential privacy on an entire dataset?,"<p>I'm currently trying to find a way to apply Differential Privacy on an entire dataset to anonymize this dataset.</p>
<p>I read that, to release multiple statistics about the same user, I have to add a laplace noise of scale C/espilon with C the number of statistics (<a href=""https://desfontain.es/privacy/differential-privacy-in-practice.html"" rel=""nofollow noreferrer"">https://desfontain.es/privacy/differential-privacy-in-practice.html</a>).</p>
<p>Then I have two main questions :</p>
<ul>
<li>If I have a dataset of C features, can I add a laplace Noise of of scale C/espilon on this dataset to obtain an epsilon-differentially private dataset ?</li>
<li>If this is possible, how can I handle categorical features ?</li>
</ul>
<p>Thanks for help !</p>
<p>I wrote a simple function to add laplace noise on a dataset :</p>
<pre><code>
def Noise(df, epsilon):
    noisy_df = df.copy()
    
    scale = epsilon/df.shape[1]
    noise = np.random.laplace(0, scale, df.shape)
    noisy_df += noise

    return noisy_df
</code></pre>
",<python><privacy>
66122111,How can I use ILogger abstractions in a .NET Library with a singleton pattern?,"<p>I have a class library that currently uses NLog for its logging purposes.  I would like to update this library to use an <code>ILogger&lt;T&gt;</code> abstraction from <strong>Microsoft.Extensions.Logging.Abstractions</strong> so that consumers of this library can choose their own logging frameworks.</p>
<p>The library uses a singleton pattern with a private constructor and <em>Instance</em> property:</p>
<pre><code>public static MyLibrary Instance { get; } = new MyLibrary();

private MyLibrary()
{
...
}
</code></pre>
<p>What are suggestions to keep this library a singleton, yet allow consumers to provide an <code>ILogger</code> implementation at startup/object creation? Is there a way I can have this library accept a logging implementation from other applications without changing the singleton pattern?</p>
",<c#><ilogger>
13329101,How do I output log messages using log4cplus in a format compatible with Chainsaw,"<p>I recently figured out how to output log4cplus messages in a format compatible with LogFactor5 in my C++ application:</p>

<p>In my log4cplus.properties file I have the following appender defined:</p>

<pre><code># LogFactor5 appender
log4cplus.appender.LogFactor5=log4cplus::RollingFileAppender
log4cplus.appender.LogFactor5.Schedule=DAILY
log4cplus.appender.LogFactor5.File=/home/ken/logs/project1.logfactor5
log4cplus.appender.LogFactor5.Append=true
log4cplus.appender.LogFactor5.MaxBackupIndex=9
log4cplus.appender.LogFactor5.MaxFileSize=100KB
log4cplus.appender.LogFactor5.layout=log4cplus::PatternLayout
log4cplus.appender.LogFactor5.layout.ConversionPattern=[slf5s.start]%d{%d %b %Y %H:%M:%S,%Q}[slf5s.DATE]%n%p[slf5s.PRIORITY]%n%x[slf5s.NDC]%n%t[slf5s.THREAD]%n%c[slf5s.CATEGORY]%n%l[slf5s.LOCATION]%n%m[slf5s.MESSAGE]%n%n
</code></pre>

<p>However, I would like to do something similar for Chainsaw but have not found the correct format.  What is the log message format required by Chainsaw?</p>

<p>Does Chainsaw expect the log messages to be an XML format?  Does log4cplus provide XML appenders?</p>

<p>Thanks.</p>
",<log4cplus><apache-chainsaw>
220793,Is there a .net analogue to the Boost libraries?,"<p>As per the title.</p>

<p>I think .Net libraries would definitely benifit from some sort of community development; perhaps something like the Java Community Process. This is where an analogue would be very helpful.</p>

<p>EDIT: I think people are believing that I need to use some libraries. That's not what I'm talking about. I mean something like a formal (or near-formal) process to add new libraries to the BCL.</p>
",<.net><boost>
27896787,log4j:ERROR Failed to load driver java.lang.ClassNotFoundException: sun.jdbc.odbc.JdbcOdbcDriver,"<p>I am on OSX Yosmite and JRE8, I dont get to seem to get the logging to database to work with log4j, does anyone have a solution for this?</p>

<p>log4j:ERROR Failed to load driver</p>

<pre><code>java.lang.ClassNotFoundException: sun.jdbc.odbc.JdbcOdbcDriver
    at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1295)
    at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1147)
    at java.lang.Class.forName0(Native Method)
    at java.lang.Class.forName(Class.java:260)
    at org.apache.log4j.jdbc.JDBCAppender.setDriver(JDBCAppender.java:391)
    at org.apache.log4j.jdbc.JDBCAppender.getConnection(JDBCAppender.java:248)
    at org.apache.log4j.jdbc.JDBCAppender.execute(JDBCAppender.java:215)
    at org.apache.log4j.jdbc.JDBCAppender.flushBuffer(JDBCAppender.java:289)
    at org.apache.log4j.jdbc.JDBCAppender.append(JDBCAppender.java:186)
    at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
    at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
    at org.apache.log4j.Category.callAppenders(Category.java:206)
    at org.apache.log4j.Category.forcedLog(Category.java:391)
    at org.apache.log4j.Category.error(Category.java:322)
</code></pre>
",<java><jdbc><log4j>
39570340,Configuring logback TimeBasedRollingPolicy to roll a file in specific way,"<p>I'm trying to achieve a certain way of rolling files by using <code>TimeBasedRollingPolicy</code> but I can't get it to work as I intended.</p>

<p>My current <code>logback.xml</code> configuration (logback version 1.1.3):</p>

<pre><code>&lt;configuration debug=""true""&gt;
    &lt;appender name=""FILE"" class=""ch.qos.logback.core.rolling.RollingFileAppender""&gt;
        &lt;file&gt;${com.sun.aas.instanceRoot}/logs/server.log&lt;/file&gt;
        &lt;append&gt;true&lt;/append&gt;

        &lt;rollingPolicy class=""ch.qos.logback.core.rolling.TimeBasedRollingPolicy""&gt;
            &lt;fileNamePattern&gt;${com.sun.aas.instanceRoot}/logs/server.%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=""ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP""&gt;
                &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
            &lt;MaxHistory&gt;7&lt;/MaxHistory&gt;
        &lt;/rollingPolicy&gt;

        &lt;encoder&gt;
            &lt;Pattern&gt;[%d] [%thread] [%-5level] [%logger{52}]%n %msg%n%n&lt;/Pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;root&gt;
        &lt;level value=""TRACE""/&gt;
        &lt;appender-ref ref=""FILE""/&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>

<hr>

<p><strong>How I want the logger to behave</strong>:</p>

<ul>
<li>append log to <code>/logs/server.log</code> file until it achieves 5MB filesize or the date rolls</li>
<li>when the <code>/logs/server.log</code> file reaches 5MB (or the date rolls)

<ul>
<li>change its name according to <code>fileNamePattern</code>(e.g. <code>logs/server.2016-09-19T10-58.0.log</code>)</li>
<li>create new server.log file to append fresh logs to</li>
</ul></li>
</ul>

<hr>

<p><strong>How it behaves with mentioned configuration</strong>:</p>

<ul>
<li>appends log to <code>/logs/server.log</code> file indefinitely, doesn't roll the file at all.</li>
</ul>

<hr>

<p><strong>What I've tried so far</strong>:</p>

<ul>
<li><p>removing the main file attribute <code>&lt;file&gt;${com.sun.aas.instanceRoot}/logs/server.log&lt;/file&gt;</code></p></li>
<li><p>using simply the <code>TimeBasedRollingPolicy</code> <strong>without</strong> <code>SizeAndTimeBasedFNATP</code> and setting the rollover period to one minute (by adding <code>HH-mm</code> to <code>fileNamePattern</code>)</p>

<p>These solutions seem to enable file rolling, but unfortunately cause the <code>/logs/server.log</code> file to be completely omitted from logging.</p></li>
<li><p>using <code>FixedWindowRollingPolicy</code> with filesize-based only <code>SizeBasedTriggeringPolicy</code> (using the same <code>fileNamePattern</code>)</p>

<p>It causes the logger to append to <code>/logs/server.log</code> file indefinitely.</p></li>
</ul>
",<java><logging><logback>
58480144,Javascript ensure the N seconds passed between log entries,"<p>I have a logger which writes data every 5 seconds.</p>

<p>It is used for 2 purposes: </p>

<ol>
<li>get the latest data record</li>
<li>get the records for 1 month or week.</li>
</ol>

<p>So, I want it to always keep the latest written record, however ensure that the time frame between records (excluding the last one) is at least one minutes. For that I want to run the db cleanup script periodically.</p>

<p>need help with the algorithm which will remove the db entries which are too close by timestamp. </p>

<p>not working example which removes all records :) </p>

<pre><code>let wasRemoved: boolean = true;
while(wasRemoved) {
    const logs = await logsRepository.find({parent: {id: parents[0].id}});
    const startL = logs.length;
    console.log('start: ' + startL);
    for (let i = 0; i &lt; logs.length - 2; i++) {
        if (i + 1 &lt; logs.length-2 &amp;&amp;
              DataHelpers.getSecondsBetweenDates(logs[i].createdAt, logs[i+1].createdAt) &lt; 60) {
            console.log(DataHelpers.getSecondsBetweenDates(logs[i].createdAt, logs[i+1].createdAt));
            logs.splice(i+1, 1);
            wasRemoved = true;
            await logsRepository.delete(logs[i+1].id);
        }
    }
    if (startL === logs.length) wasRemoved = false;
    console.log('end: ' + logs.length);
}
</code></pre>

<p>basically it always removes the next record. Please help with the proper algorithm to solve this problem.</p>

<p>thanks!</p>
",<javascript>
72607465,Grafana Loki total number of a specific log message,"<p>I am using Grafana Loki and I need to calculate the total number of a certain log message for a specific time interval. For example, I need the total number of log message &quot;some-text&quot; in the period from 12:00:00 to 14:00:00. I just found the following way to count the occurrences of the last minute, something this: <code>count_over_time({container=&quot;some-containter&quot;} |= &quot;some-text&quot;)[1m]</code>, but i did not found any way to query a specific interval.</p>
<p>I would be very happy if this is possible and someone could help.</p>
",<logging><monitoring><grafana><grafana-loki><logql>
41702527,PHP - How to fetch posts if the location of the post matches the location of the currently logged in user,"<p>I'm currently developing a newsfeed app with php. User's are assigned a location. User's can create posts which are assigned the location of the user. So far the newsfeed is being populated by all posts regardless of location. What I need is to populate the newsfeed by posts where the post location matches the user location.</p>

<p>I want the currently logged in user's location to match the posts with the same location and then populate to the newsfeed. This code doesnt work. 
 Any help would be great!</p>

<pre><code> public function getDashboard($posts_location)
  {
 $posts = Post::where('location', $posts_location);

 if(Auth::user()-&gt;location = $posts_location) {
 return view('dashboard', ['posts' =&gt; $posts]);
  }
</code></pre>
",<php><laravel>
13100999,Permission to append to a log denied error on Mac but not on Windows,"<p>I'm trying to port my application to Mac, but I don't understand what's causing this problem.</p>

<p>At some point, I try to load a couple of C++ libraries provided by a third party, using ctypes' <code>LoadLibrary</code>. For Windows, I have dlls, and for Mac, dylibs. Loading the dylibs gives an error too which I'm also trying to solve, but that shouldn't be an issue here, because I do have a try/except block for exactly that.</p>

<pre><code>try:
    self.log('Lib exists? %s: %s' % (libpath, os.path.exists(libpath)))       
    origdir = os.getcwd()
    os.chdir(os.path.dirname(libpath))
    self.lib = cdll.LoadLibrary(os.path.basename(libpath))
    os.chdir(origdir)
    self.log(""Loaded Library!"")
except Exception as e:
    self.log('Error importing Library! %s' % e)
    self.lib_loaded = False
</code></pre>

<p>Any problems are written to a log file. The thing is, it is appending to the log file that somehow works for the first call, but doesn't work the second time it's called in the above fragment, at<br>
 <code>self.log('Error importing Library! %s' % e)</code>.</p>

<p>The log method is pretty obvious:</p>

<pre><code>def log(self, text):
    if self.debug:
        print text
        with open('logfile.log', 'a') as w:
            w.write('%s\n' % text)   
</code></pre>

<p>On Windows, this works without problems. When the library is found, it loads, and when it isn't found, I get the appropriate message printed and written to the log. But on Mac, I get the error</p>

<pre><code>Lib exists? /usr/local/lib/path/to/Mylib: True
Error importing Library! dlopen(lib.dylib, 6): no suitable image found.  Did find:
    lib.dylib: mach-o, but wrong architecture
    /usr/local/lib/lib.dylib: mach-o, but wrong architecture
Traceback (most recent call last):
  File ""myapp.py"", line 987, in &lt;module&gt;
    foo = Foo(pyqtapp, splash)
  File ""myapp.py"", line 83, in __init__
    self.thelibLink = libLink.libLink(0.05, a, b)
  File ""libLink.py"", line 100, in __init__
    self.log('Error importing Library! %s' % e)
  File ""libLink.py"", line 326, in log
    with open(self.logfile, 'a') as w:
IOError: [Errno 13] Permission denied: 'logfile.log'
</code></pre>

<p><code>logfile.log</code> has the permissions <code>-rw-r--r--</code> and is owned by me, so this doesn't make any sense to me. Moreover, after running the program, the logfile contains this:</p>

<pre><code>==Log of date/time==
Lib exists? /usr/local/lib/path/to/Mylib: True
</code></pre>

<p>So somehow I do have the permission to append to the file when <code>self.log</code> is called for the first time. Any ideas how I can solve this?</p>
",<python><macos><logging><permissions><ctypes>
5475800,Mac OS X cron log / tracking,"<p>What is the best way to determine if a cron job has run? Is there a log? What techniques do people use?</p>
",<macos><cron>
41942862,Custom logging in ssis,"<p>I have created a process log table which has a field called execution status, this field should be populated with success when package has completed successfully, failure when package has failed, running when package is running and terminated when package is terminated by user. </p>

<p>I'm able to populate the first three values but I am facing issues to implement the terminated value in the table. </p>

<p>I have used event handler on error to get failed status and rest values are populated in control flow itself. </p>

<p>Help me to implement the terminated value. </p>
",<ssis>
23697795,Log to file and console python,"<p>I'm using Python's logging module to log some debug strings to a file that give me good log 
I use this script attached but it don't give me any output to screen
how can I  show all print in the screen and print it to the log with the formatt ?
any help?</p>

<pre><code>class StreamToLogger(object):
   """"""
   Fake file-like stream object that redirects writes to a logger instance.
   """"""
   def __init__(self, logger, log_level=logging.INFO):
      self.logger = logger
      self.log_level = log_level
      self.linebuf = ''

   def write(self, buf):
      for line in buf.rstrip().splitlines():
         self.logger.log(self.log_level, line.rstrip())

logging.basicConfig(
   level=logging.DEBUG,
   format='%(asctime)s:%(levelname)s:%(name)s:%(message)s',
   filename=""out.log"",
   filemode='a'
)

stdout_logger = logging.getLogger('STDOUT')
sl = StreamToLogger(stdout_logger, logging.INFO)
sys.stdout = sl

#stderr_logger = logging.getLogger('STDERR')
#sl = StreamToLogger(stderr_logger, logging.ERROR)
#sys.stderr = sl
</code></pre>
",<python-2.7><logging>
68786644,Log person who deleted message in Discord.py bot,"<p>I'm logging deleted Discord messages using the <code>on_message_delete</code> event like so:</p>
<pre class=""lang-py prettyprint-override""><code>@commands.Cog.listener()
    async def on_message_delete(self, message):
        if not message.author.bot:
            channel = db.field(&quot;SELECT LogID FROM guilds WHERE GuildID = ?&quot;, message.guild.id)

            if channel != 0: #If this guild wants to log deleted messages

                embed = discord.Embed(title=&quot;Message Deleted&quot;,
                                      color=discord.Color.red(),
                                      timestamp=getTime())
                embed.add_field(name=&quot;Member: &quot;, value=message.author.mention, inline=False)
                embed.add_field(name=&quot;Deleter: &quot;, value=&quot;What do I put here&quot;, inline=False)
                embed.set_footer(text=f&quot;User ID: {message.author.id}&quot;)
                embed.set_thumbnail(url=message.author.avatar_url)
                fields = [(&quot;Message:&quot;, message.content, True),
                          (&quot;Channel:&quot;, message.channel.mention, False)]

                for name, value, inline in fields:
                    embed.add_field(name=name, value=value, inline=inline)

                await self.bot.get_channel(channel).send(embed=embed)

</code></pre>
<p>Is there a way to get the id of a person who deleted a message so that even if a mod deletes someone else's message, you could still get their id?</p>
<p>(I have looked at other sources as well like this Reddit <strong><a href=""https://www.reddit.com/r/Discord_Bots/comments/ksiy7d/get_id_of_user_who_deleted_a_message_with_discord/"" rel=""nofollow noreferrer"">page</a></strong>, and the <strong><a href=""https://discordpy.readthedocs.io/en/latest/api.html?highlight=get_member#message"" rel=""nofollow noreferrer"">API</a></strong> for messages but neither gave any insight)</p>
",<python><discord.py>
57723637,How to Send Mag::Log error using Whatsapp?,"<p>I am using Event Observer for getting custom values, How can i send my EventObserver log message by whatsapp message?</p>
",<magento-1.9><whatsapp>
67021804,"Docker based Elastic Search container stopped due to with a log "" java.io.IOException: No space left on device"" is /dev/sda have 24G free space","<p>I am using a dockerized magento setup from this <a href=""https://gitlab.dev9server.com/swetank_nhz/magento-2.3.6-dockerize.git"" rel=""nofollow noreferrer"">github link</a></p>
<p>I am using main &quot;docker-compose.yml&quot; file from the repo</p>
<pre><code>  elasticsearch:
    build:
      context: .
      dockerfile: build/elasticsearch/Dockerfile
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
      - node.name=node-1
      - cluster.initial_master_nodes=node-1
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./elasticsearchdata:/usr/share/elasticsearch/data
      - ./elasticconfig/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - 9200:9200
    networks:
      - &lt;project_name&gt;-network
</code></pre>
<p>In this  already add the volume to make elastic-data persist
after that everything is running pretty well but after a month i am facing an error from elastic search container logs that</p>
<pre><code>&quot;java.io.IOException: No space left on device&quot;
</code></pre>
<p>and when i checked /dev/sda have 24G free space</p>
<p>So i am not sure my i am facing this now and container is failed to restart or run.
just provide a little path toward the solution that would be enough!!! and thank Already</p>
",<docker><elasticsearch><docker-compose><docker-volume><persistent-volumes>
62367425,Assistance with discord.AuditLogAction,"<p>I've read discord.py docs, and I haven't found anything related to how to use discord.AuditLogAction()</p>

<p>The thing is, I want everything getting logged by the bot in a specific channel</p>

<p>Like, channel_create, member_prune, webhook_create, and so on.</p>

<p>Since I am too new to discord.py, I cant provide code. Sorry about that</p>

<p>Thanks in advance!</p>
",<python><logging>
57958239,how to mock android.util.Log,"<p>I.m using a mockk library in kotlin, and in tests, I have the following exception: </p>

<pre><code>java.lang.RuntimeException: Method getStackTraceString in android.util.Log not mocked. See http://g.co/androidstudio/not-mocked for details.
</code></pre>

<p>I can't find a solution for that.</p>
",<android><kotlin><mockk>
71470231,Force Log4Net to output specific events,"<p>I use log4net for diagnostic logging in my applications, that is, if log4net doesn't work, the application runs fine anyway.
I have a separate Audit Trail log that will block the application if the audit trail fails.</p>
<p>I want to include Audit Trail messages in my log4net logs, but I have a conundrum: I want the AuditTrail messages to be output with the highest priority (Critical like), but I don't want the audit trail messages to be represented as fatal errors.<br />
They should be emitted with an INFO level, given they are not critical errors, but simply mandatory messages.</p>
<p>I was looking into the internals of log4net and I stumbled upon the protected <code>Logger.Forcedlog</code> method:</p>
<pre><code>/// &lt;summary&gt;
/// Creates a new logging event and logs the event without further checks.
/// &lt;/summary&gt;
/// &lt;param name=&quot;logEvent&quot;&gt;The event being logged.&lt;/param&gt;
/// &lt;remarks&gt;
/// &lt;para&gt;
/// Delivers the logging event to the attached appenders.
/// &lt;/para&gt;
/// &lt;/remarks&gt;
protected virtual void ForcedLog(LoggingEvent logEvent)
{
  logEvent.EnsureRepository((ILoggerRepository) this.Hierarchy);
  this.CallAppenders(logEvent);
}
</code></pre>
<p>I can call this method via reflection and bypass any level check, but I'm feeling very guilty.</p>
<p>Are there any &quot;cleaner&quot; alternatives?</p>
",<c#><log4net>
57590074,Logstash JDBC: Update row issue,"<p>Im using the Below JDBC code in Logstash for updating the already existing index in Elasticsearch, without duplicating rows or adding the updated row as another new row.
Versions: Elasticsearch, Logstash and Kibana are v7.1.0.</p>

<pre><code>input {
    jdbc {
        jdbc_connection_string =&gt; ""jdbc:sqlserver://DB01:1433;databasename=testdb;integratedSecurity=true""
        jdbc_driver_class =&gt;  ""com.microsoft.sqlserver.jdbc.SQLServerDriver""
    jdbc_driver_library =&gt; ""C:\Program Files\sqljdbc_6.2\enu\mssql-jdbc-6.2.2.jre8.jar""
        jdbc_user =&gt; nil
        statement =&gt; ""SELECT * from data WHERE updated_on &gt; :sql_last_value ORDER BY updated_on""
    use_column_value =&gt;true
        tracking_column =&gt;updated_on
        tracking_column_type =&gt; ""timestamp""
    }
}
output {
          elasticsearch { hosts =&gt; [""localhost:9200""] 
        index =&gt; ""datau"" 
        action=&gt;update
            document_id =&gt; ""%{id}""
            doc_as_upsert =&gt;true}
          stdout { codec =&gt; rubydebug }
       }
</code></pre>

<p>when i run the above in logstash (logstash -f myfile.conf)
the below error appars.</p>

<pre><code>[2019-08-21T10:46:33,864][ERROR][logstash.outputs.elasticsearch] Failed to insta ll template. {:message=&gt;""Got response code '400' contacting Elasticsearch at URL  'http://localhost:9200/_template/logstash'"", :class=&gt;""LogStash::Outputs::Elasti cSearch::HttpClient::Pool::BadResponseCodeError"", :backtrace=&gt;[""D:/ELK 6.4.0/log stash-6.4.0/logstash-6.4.0/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasti csearch-9.2.0-java/lib/logstash/outputs/elasticsearch/http_client/manticore_adap ter.rb:80:in `perform_request'"", ""D:/ELK 6.4.0/logstash-6.4.0/logstash-6.4.0/ven dor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.2.0-java/lib/logstas h/outputs/elasticsearch/http_client/pool.rb:291:in `perform_request_to_url'""...
</code></pre>

<p>Where am i gong wrong?</p>
",<elasticsearch><jdbc><logstash>
42772111,Filter Log from console in Android,"<p>I'm new in android and I'm using android studio to build app. Sometimes I need to check variable values I set log for them but It's very difficult to find a single log line out of too many lines So, I need to filter the logs.</p>

<pre><code>  Log.i(""Some info"", ""Show some thing here""); 
</code></pre>

<p>I'm using <code>Android 2.2.3</code>. In this studio I'm not able to find any filter Here is image of console.
<a href=""https://i.stack.imgur.com/4Z19Q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4Z19Q.png"" alt=""enter image description here""></a></p>
",<android>
32492736,Can't get logging to work in Spring boot 1.2.5.RELEASE,"<ol>
<li><p>I am using spring boot 1.2.5.RELEASE. I have added logging.file to my application.properties. I have printed out LOG_PATH env variable and it shows the appropriate log file, but still there is not log file. I am using the spring boot default logger logback with slf4j. The only way it would work is to put a logback.xml in classpath. The documentation unfortunately doesn't say so.</p></li>
<li><p>I am using spring-data-neo4j 4.0.0.RELEASE. I updated to Spring Boot 1.3.0.M5 to see if the logging issue had been fixed. Before I could test that, another problem appeared, now spring boot is forcing spring-data-3.4.2.RELEASE. I could not exclude that in any way.</p></li>
</ol>

<p>Both of these are issues, which I hope someone in the spring data team notices.</p>
",<logging><spring-boot><slf4j><logback><spring-data-neo4j>
39524898,Log4r const_get issue with rails 4.2.4,"<p>I try to configure log4r with my application:
Gem info:
gem 'log4r', '1.1.10'
gem 'rails', '4.2.4'
gem 'mysql2', '0.3.20'</p>

<p>application.rb</p>

<pre><code>require 'log4r'
require 'log4r/yamlconfigurator'
require 'log4r/outputter/datefileoutputter'
include Log4r
</code></pre>

<p>inside of Application class:</p>

<pre><code>log4r_config = YAML.load_file(File.join(File.dirname(__FILE__), ""log4r.yml""))
log_cfg      = YamlConfigurator
log_cfg.decode_yaml( log4r_config['log4r_config'] )

config.logger             = Log4r::Logger['rails']
config.log_level          = DEBUG
ActiveRecord::Base.logger = Log4r::Logger['mysql']
</code></pre>

<p>config/log4r.yml</p>

<pre><code>log4r_config:
  pre_config:
    custom_levels:
      - DEV0
      - DEBUG
      - PARAMS
      - DEV1
      - INFO
      - WARN
      - ERROR
      - EXCEPTION
      - FATAL

 #
 # define all loggers:
 #
 loggers:
   - name          : rails
     level         : DEBUG
     trace         : 'false'
     outputters    : 
       - console
       - rails_file

   - name          : mysql
     level         : DEBUG
     trace         : 'false'
     outputters    :
       - console
       - rails_file

  #
  # define all outputters (incl. formatters)
  #
  outputters:
   - type: StdoutOutputter
     name: console
     formatter:
       date_pattern: '%H:%M:%S'
       pattern     : '%d %l: %m'
       type        : PatternFormatter

   - type: FileOutputter
     name: rails_file
     filename: ""log/#{ENV}.log""
     trunc: false
     formatter:
       date_pattern: '%Y %m %d %H:%M:%S.%L %z'
       pattern     : '%d %l: %m'
       type        : PatternFormatter
</code></pre>

<p>While i start my application i got below error:</p>

<pre><code>=&gt; Booting WEBrick
=&gt; Rails 4.2.4 application starting in development on http://localhost:3000
=&gt; Run `rails server -h` for more startup options
=&gt; Ctrl-C to shutdown server
Exiting
/home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/application/bootstrap.rb:70:in ***`const_get': wrong constant name 2 (NameError)***
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/application/bootstrap.rb:70:in `block in &lt;module:Bootstrap&gt;'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/initializable.rb:30:in `instance_exec'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/initializable.rb:30:in `run'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/initializable.rb:55:in `block in run_initializers'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:228:in `block in tsort_each'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:350:in `block (2 levels) in each_strongly_connected_component'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:431:in `each_strongly_connected_component_from'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:349:in `block in each_strongly_connected_component'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:347:in `each'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:347:in `call'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:347:in `each_strongly_connected_component'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:226:in `tsort_each'
    from /home/softices/.rvm/rubies/ruby-2.3.0/lib/ruby/2.3.0/tsort.rb:205:in `tsort_each'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/initializable.rb:54:in `run_initializers'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/application.rb:352:in `initialize!'
    from /home/softices/personal/workspace/ruby/trusted-driver/rails/admin/config/environment.rb:5:in `&lt;top (required)&gt;'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:274:in `require'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:274:in `block in require'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:240:in `load_dependency'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:274:in `require'
    from /home/softices/personal/workspace/ruby/trusted-driver/rails/admin/config.ru:3:in `block in &lt;main&gt;'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/builder.rb:55:in `instance_eval'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/builder.rb:55:in `initialize'
    from /home/softices/personal/workspace/ruby/trusted-driver/rails/admin/config.ru:in `new'
    from /home/softices/personal/workspace/ruby/trusted-driver/rails/admin/config.ru:in `&lt;main&gt;'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/builder.rb:49:in `eval'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/builder.rb:49:in `new_from_string'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/builder.rb:40:in `parse_file'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/server.rb:299:in `build_app_and_options_from_config'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/server.rb:208:in `app'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands/server.rb:61:in `app'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/rack-1.6.4/lib/rack/server.rb:336:in `wrapped_app'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands/server.rb:139:in `log_to_stdout'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands/server.rb:78:in `start'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands/commands_tasks.rb:80:in `block in server'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands/commands_tasks.rb:75:in `tap'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands/commands_tasks.rb:75:in `server'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands/commands_tasks.rb:39:in `run_command!'
    from /home/softices/.rvm/gems/ruby-2.3.0/gems/railties-4.2.4/lib/rails/commands.rb:17:in `&lt;top (required)&gt;'
    from bin/rails:4:in `require'
    from bin/rails:4:in `&lt;main&gt;'
</code></pre>
",<ruby-on-rails-4><log4r>
12386168,How to change log file from SystemOut.log to other in WAS.7,"<p>In websphere application server.7 ,(WAS/RAD) , How to change the the logs that are storing in SystemOut.log file into other file ??</p>

<p>Is there any steps to change log file in logging and tracing??</p>
",<rad><websphere-7>
12941812,Getting Facebook user's privacy settings via Facebook API,"<p>I'm writing a javascript application to get Facebook user's privacy settings.
Can I get them from privacy-setting table and is there any fql reference on the topic?</p>
",<facebook-fql><privacy>
6194632,Valid JSON Array logs Undefined to the console no matter what I do,"<p>I'm using Jquery to call a php script which then generates an array. I'm using</p>

<pre><code>echo json_encode (array ( ""key""=&gt;$value, ""key""=&gt;$value, ""key""=&gt;$value ));
</code></pre>

<p>As the last line of the PHP document which is generating a valid JSON array. I checked via Firebug. Unfortunately when I try to access one of the values with dot-notation, it's coming up as undefined.</p>

<pre><code>$.ajax({
        type        : ""POST"",
        cache       : false,
        url     : ""/generateArray.php"",
        data        : { data: $(this).attr('id') },
        success: function(data) {
                     console.log(data.key);
        }
</code></pre>

<p>This is outputting ""undefined"" to the console, even though when I check the JSON output the array is valid.</p>

<p>I have no idea how to even begin debugging what's wrong with my code. Please help!</p>
",<php><jquery><ajax><json>
57647674,How to set up log4j?,"<p>I have trtied to use the  jzy3d api to plot a 3d graph, I tried to set it up using maven (I am new to this), I basically just copied what the api page told me, but i am consistenly running into a log4j warning.</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;org.jzy3d&lt;/groupId&gt;
    &lt;artifactId&gt;jzy3d-tutorials&lt;/artifactId&gt;
    &lt;version&gt;1.0.3-SNAPSHOT&lt;/version&gt;

    &lt;name&gt;Jzy3d Tutorials&lt;/name&gt;

    &lt;!--To retrieve Jzy3d dependencies
    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;jzy3d-snapshots&lt;/id&gt;
            &lt;name&gt;Jzy3d Snapshots&lt;/name&gt;
            &lt;url&gt;http://maven.jzy3d.org/snapshots/&lt;/url&gt;
        &lt;/repository&gt;
        &lt;repository&gt;
            &lt;id&gt;jzy3d-releases&lt;/id&gt;
            &lt;name&gt;Jzy3d Releases&lt;/name&gt;
            &lt;url&gt;http://maven.jzy3d.org/releases/&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt; --&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;Sonatype-snapshots&lt;/id&gt;
            &lt;name&gt;Sonatyp Snapshots&lt;/name&gt;
            &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt;
        &lt;/repository&gt;
        &lt;repository&gt;
            &lt;id&gt;Sonatype-releases-staging&lt;/id&gt;
            &lt;name&gt;Sonatype Releases Staging&lt;/name&gt;
            &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;


    &lt;!--To deploy tutorials: 1) this project does not references master to be
        able to be build alone 2) master still reference this project to build it
        with the API involve being deployable by mvn deploy --&gt;
    &lt;!--&lt;distributionManagement&gt;
        &lt;repository&gt;
            &lt;id&gt;jzy3d-ftp-maven&lt;/id&gt;
            &lt;name&gt;Jzy3d Maven Folder&lt;/name&gt;
            &lt;url&gt;ftp://www.jzy3d.org/v1/maven/releases&lt;/url&gt;
        &lt;/repository&gt;
        &lt;snapshotRepository&gt;
            &lt;id&gt;jzy3d-ftp-maven&lt;/id&gt;
            &lt;name&gt;Jzy3d Maven Folder SNAPSHOTS&lt;/name&gt;
            &lt;url&gt;ftp://www.jzy3d.org/v1/maven/snapshots&lt;/url&gt;
        &lt;/snapshotRepository&gt;
    &lt;/distributionManagement&gt;--&gt;

    &lt;distributionManagement&gt;
        &lt;snapshotRepository&gt;
            &lt;id&gt;ossrh&lt;/id&gt;
            &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;
        &lt;/snapshotRepository&gt;
        &lt;repository&gt;
            &lt;id&gt;ossrh&lt;/id&gt;
            &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/distributionManagement&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;version.jzy3d&gt;${project.version}&lt;/version.jzy3d&gt;
        &lt;version.java.source&gt;1.8&lt;/version.java.source&gt;
        &lt;version.java.target&gt;1.8&lt;/version.java.target&gt;
        &lt;version.mvn.compiler&gt;3.0&lt;/version.mvn.compiler&gt;
        &lt;version.mvn.ftp&gt;1.0-beta-6&lt;/version.mvn.ftp&gt;
        &lt;version.mvn.deploy&gt;2.4&lt;/version.mvn.deploy&gt;
        &lt;version.mvn.javadoc&gt;2.9.1&lt;/version.mvn.javadoc&gt;
        &lt;version.mvn.release&gt;2.5.3&lt;/version.mvn.release&gt;
        &lt;version.libs.junit&gt;4.10&lt;/version.libs.junit&gt;
        &lt;version.libs.swt&gt;4.2.1&lt;/version.libs.swt&gt;
    &lt;/properties&gt;


    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.jzy3d&lt;/groupId&gt;
            &lt;artifactId&gt;jzy3d-api&lt;/artifactId&gt;
            &lt;version&gt;${project.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.miglayout&lt;/groupId&gt;
            &lt;artifactId&gt;miglayout&lt;/artifactId&gt;
            &lt;version&gt;3.7.4&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.opencsv&lt;/groupId&gt;
            &lt;artifactId&gt;opencsv&lt;/artifactId&gt;
            &lt;version&gt;3.7&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${version.java.source}&lt;/source&gt;
                    &lt;target&gt;${version.java.target}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;
                &lt;version&gt;${version.mvn.deploy}&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;skip&gt;true&lt;/skip&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;!--&lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;--&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;attach-sources&lt;/id&gt;
                        &lt;phase&gt;deploy&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;jar&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;attach-javadocs&lt;/id&gt;
                        &lt;phase&gt;deploy&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;jar&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>

<pre><code>log4j:WARN No appenders could be found for logger (org.jzy3d.chart.factories.ChartComponentFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
</code></pre>
",<java><maven><intellij-idea><jzy3d>
28850182,Logging - ini-defined log path not appending date,"<p>My application requires logging where the application outputs messages to a file called ""profile_admin_ddmmyyyy(where ddmmyyyy is the current date). The path is pulled from the current directory using the following code:</p>

<pre><code>FileInputStream propFile = new FileInputStream(""config.ini"");
config.load(propFile);
path = config.getProperty(""path"");
</code></pre>

<p>In my ini, I have the ""path"" as:</p>

<pre><code>path=C:\app27\bin\profile_admin_
</code></pre>

<p>I need to be able to append the date to the end of this file with the file type of "".log"". Can anyone help me achieve this?</p>

<p>I have included the Class I call to for writing the log file:</p>

<pre><code>private String path;
private boolean appendToFile = false;

public FunctionLogging(String file_path, boolean append_value)
{
    path = file_path;
    appendToFile = append_value;
}

public void writeToFile(String textLine)
{
    Date date = new Date();
    SimpleDateFormat format = new SimpleDateFormat();
    format = new SimpleDateFormat(""dd-MM-yyyy|HH:mm:ss:ms|"");
    String timeStamp = format.format(date);

    try
    {
        FileInputStream propFile = new FileInputStream(""config.ini"");
        Properties config = new Properties(System.getProperties());
        config.load(propFile);
        path = config.getProperty(""path"");
        FileWriter write = new FileWriter(path, appendToFile);
        PrintWriter printlines = new PrintWriter(write);
        printlines.printf(""%s"" + ""%n""+ timeStamp, textLine);
        printlines.close();

    }
    catch(IOException e)
    {
        e.printStackTrace();
    }
</code></pre>
",<java>
32483899,How to enable Hibernate's SQL logging via logging.properties?,"<p>I have removed the property <code>hibernate.show_sql</code> from my EntityManager creation and want to replace it with a <a href=""https://stackoverflow.com/a/2078461/390177"">logging level</a>. I am using java's logging facility.</p>

<p>As explained in this answer I should set the log level of <strong>org.hibernate.SQL</strong>.</p>

<p>I have tried it with my logging.properties, but it doesn't work:</p>

<pre><code>handlers=java.util.logging.ConsoleHandler
org.hibernate.level=FINE
org.hibernate.SQL.level=FINEST
org.hibernate.type.level=FINER
</code></pre>

<p>I had also tried ALL, but it makes no difference.</p>

<p>What is wrong?</p>
",<hibernate><logging><java.util.logging>
576456,log4net versus TraceSource,"<p>In <a href=""https://stackoverflow.com/questions/576185/logging-best-practices"">this thread</a> many people have indicated that they use log4net. I am a fan of TraceSources and would like to know why log4net is used. </p>

<p>Here is why I like trace sources:</p>

<ul>
<li>Pluggable listeners - XML, TextFile, Console, EventLog, roll your own</li>
<li>Customisable trace switches (error, warning, info, verbose, start, end, custom)</li>
<li>Customisable configuration </li>
<li>The Logging Application Block is just a big set of TraceListeners</li>
<li>Correlation of activities/scopes (e.g., associate all logs within an ASP.NET request with a given customer</li>
<li>The Service Trace Viewer allows you to visualize events against these activities individually</li>
<li>All of it is configurable in app.config/web.config.</li>
</ul>

<p>Since the .NET framework internally uses TraceSources, it also gives me a consistent way of configuring tracing - with log4net, I have to configure log4net as well as TraceSources. </p>

<p>What does log4net give me that TraceSources don't (or that couldn't be done by writing a couple of custom TraceListeners)?</p>
",<.net><logging><log4net><trace><diagnostics>
26111312,Avoid infinity in logistical squashing function,"<p>I'm implementing part of a logistic regression function but can't seem to get anything other than -inf. Not sure how you can get anything else since if there is a 1 output, then the log(1-1) turns it into -inf.    </p>

<p>Any thoughts?    </p>

<pre><code>% Calculates error based on X, Y, theta
function error = empRisk(X,Y, theta)
    n = length(X);
    error = 0;
    for i=1: n
        y = Y(i,:);
        x = X(i,:);
        binLoss = classify(theta,x);

        part1 = y-1;
        part2 = log(1-binLoss);% -Inf if 1-1??
        part3 = y*(log(binLoss));

        error = error + ((part1*part2)-part3);
    end

    error = error*(1/n);
end

% Implements the classification function
function value = classify(theta, x)
    z = dot(theta,x);

    result = (1/(1+exp(-z)));

    % Output 0,1 based on result
    if result &gt;= 0.5
        value = 1;
    else
        value = 0;
    end
end
</code></pre>

<p>Here is the formula empRisk is supposed to be doing: <img src=""https://i.stack.imgur.com/1GEXj.png"" alt=""enter image description here""></p>
",<matlab><machine-learning>
4106524,How to override log4j.properties during testing?,"<p>I'm trying to log all <code>DEBUG</code> messages to console during testing in maven. For this purpose I created a file <code>src/test/resources/log4j.properties</code>, which is going to override the configuration I already have in <code>src/main/resources/log4j.properties</code>. Unfortunately such an overriding is not happening. Why and how to fix it?</p>
",<java><logging><log4j><maven-2><maven-surefire-plugin>
12939425,"Prolog, access specific member of list?","<p>Can anyone tell me how to access a specific member of a list in prolog? Say for example I need to access the 3rd or 4th element of a list passed into a rule?</p>
",<list><prolog><unification>
19489306,addExpressionAttributeToSelect add to Magento CatalogSearch,"<p>I will try to add <code>addExpressionAttributeToSelect</code> to a magento collection.
When I try this line, it works perfectly:</p>

<pre><code>// lat lng of Mallorca, Balearen, Spain
$lat = 39.695263;
$lng = 3.017571;
$dst = 250;
$mile2km = 1.609344;

echo ""&lt;pre&gt;"";
$col = Mage::getModel('catalog/product')-&gt;getCollection()-&gt;$this-&gt;addExpressionAttributeToSelect('latlngdistance', ""ROUND(
    DEGREES(
        ACOS(
            SIN(RADIANS( $lat )) * SIN(RADIANS( {{lat}} ))
            +  COS(RADIANS( $lat )) * COS(RADIANS( {{lat}} ))
            * COS(RADIANS( $lng - {{lng}} ))
        ) * 60 * 1.1515
    ) * $mile2km
, 1)"", array('lat', 'lng'));
        $this-&gt;getSelect()-&gt;having('latlngdistance &lt;= ?', $dst);
$col-&gt;getSelect()-&gt;limit(10);
$col-&gt;load();
</code></pre>

<p>But when I add these methods to my collection within a Block, Magento removes my <code>addExpressionAttributeToSelect</code> completely</p>

<p>Error Result:</p>

<pre><code>SQLSTATE[42S22]: Column not found: 1054 Unknown column 'latlngdistance' in 'having clause'
</code></pre>

<p>(I've added this method in the Block_Layer, Method: Mage_Catalog_Model_Layer::prepareProductCollection)</p>

<p>Edit:
You have to Edit the ""getSelectCountSql"" Method</p>

<p>Edit2:
My Final Solution in the rewirte-Collection Class (in My Modul)
So it works with Flat and EAV Tables. so i got the correct number of items.</p>

<pre><code>/**
 * Get SQL for get record count
 *
 * @param bool $resetLeftJoins
 * @return Varien_Db_Select
 */
protected function _getSelectCountSql($select = null, $resetLeftJoins = true)
{
    $countSelect = parent::_getSelectCountSql($select, $resetLeftJoins);
    if($this-&gt;getDirectCurPage() == 1)
    {
        $mile2km = $this-&gt;mile2km;

        $lat = $this-&gt;lat;
        $lng = $this-&gt;lng;

        $_col_lat = 'e.lat';
        $_col_lng = 'e.lng';
        if(!$this-&gt;isEnabledFlat()) // if flat tables did work
        {
            $attributes = Mage::getResourceModel('eav/entity_attribute_collection')
            -&gt;setEntityTypeFilter(Mage::getModel('catalog/product')-&gt;getResource()-&gt;getTypeId())
            -&gt;addFieldToFilter('attribute_code', array('in', array('lat', 'lng')));

            $tables = array();
            $attribute_ids = array();
            foreach ($attributes as $attribute)
            {
                $attribute_ids[$attribute-&gt;getAttributeCode()] = $attribute-&gt;getId();
                $tables[$attribute-&gt;getAttributeCode()] = $attribute-&gt;getBackendTable();
            }
            $_col_lat = 'pd_lat.value';
            $_col_lng = 'pd_lng.value';
            $countSelect-&gt;join(array('pd_lat' =&gt; $tables['lat']),
                    ""e.entity_id = pd_lat.entity_id AND pd_lat.attribute_id = {$attribute_ids['lat']}"", array());
            $countSelect-&gt;join(array('pd_lng' =&gt; $tables['lng']),
                    ""e.entity_id = pd_lng.entity_id AND pd_lng.attribute_id = {$attribute_ids['lng']}"", array());
        }

        $countSelect-&gt;columns('COUNT(DISTINCT e.entity_id) as count');
        $countSelect-&gt;columns(array('latlngdistance' =&gt; new Zend_Db_Expr(""ROUND(
            DEGREES(
                ACOS(
                    SIN(RADIANS( $lat )) * SIN(RADIANS( {$_col_lat} ))
                    +  COS(RADIANS( $lat )) * COS(RADIANS( {$_col_lat} ))
                    * COS(RADIANS( $lng - {$_col_lng} ))
                ) * 60 * 1.1515
            ) * $mile2km
        , 1)"")));
        $countSelect-&gt;group('latlngdistance');
        $OldcountSelect = $countSelect;
        $countSelect = $this-&gt;getConnection()-&gt;select();
        $countSelect-&gt;from(array('a' =&gt; $OldcountSelect), array('SUM(a.count)'));
        unset($OldcountSelect);
    }
    return $countSelect;
}
</code></pre>
",<magento><magento-1.7>
71281731,How can I get a specialized log() to accept many arguments?,"<p>I have been using this logger in node:</p>
<pre><code>// https://stackoverflow.com/questions/9781218/how-to-change-node-jss-console-font-color
function logC(text) {
  console.log('\x1b[36m%s\x1b[0m', text);
}
</code></pre>
<p>However it does not work for multiple arguments.  I want to be able to use it like:</p>
<pre><code>logC(text1, text2)
</code></pre>
<p>Obviously, I could write out the arguments in the function signature but I was hoping there was a way to do it with the built in arguments.</p>
",<javascript><node.js><debugging><console.log>
26655114,java.lang.ClassCastException with org.apache.logging.log4j.Logger,"<p>I have a cast issue whose generates a <code>java.lang.ClassCastException</code> exception:</p>

<pre><code>import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.apache.logging.log4j.core.LoggerContext;
import org.apache.logging.log4j.message.MessageFactory;

public class MyLogger extends org.apache.logging.log4j.core.Logger {

    MyLogger(LoggerContext context, String name, MessageFactory messageFactory) {
        super(context, name, messageFactory);
        // TODO Auto-generated constructor stub
    }

    public static MyLogger getLogger(String name) {
        org.apache.logging.log4j.core.Logger logger_ = (org.apache.logging.log4j.core.Logger) LogManager
            .getLogger(name);
        return (MyLogger) logger_;
    }
}
</code></pre>

<p>While this is the same principle as this one:</p>

<pre><code>public class test {

    private static class A {

    }

    private static class B extends A {

    }

    public static void main(String [] args) {
        A a = new A();
        B b = new B();
        a = (A) b;
    }
}
</code></pre>

<p>Can someone give an explaination?</p>
",<java>
11126094,Calling log4net from a singleton that is in a separate project stops all logging,"<p>The application is a WinForms .net 3.5 app with multiple projects, one main project and multiple library projects. If I call log4net from a singleton that exists in one of the sub-projects it causes all logging to stop.   </p>

<p><strong>Update</strong></p>

<p>Based on some of the comments I changed the TestSingletonLog4net class in the following ways. The problem still exists with these changes.</p>

<ul>
<li>Made the test class thread safe as Jon Skeet pointed this out.</li>
<li>Changed the member declaration and added the  log4net.Config.XmlConfigurator.Configure(); config call as per Norla's example with the same results, still whenever it is called all logging stops.</li>
</ul>

<p>Here is the updated class to reproduce the problem.</p>

<pre><code>    public class TestSingletonLog4Net
{
    private static volatile TestSingletonLog4Net instance;
    private static object syncRoot = new Object();

    public static readonly log4net.ILog log = log4net.LogManager.GetLogger(typeof(TestSingletonLog4Net));

    private  TestSingletonLog4Net()
    {
        log4net.Config.XmlConfigurator.Configure();

        log.Info(""Test write from singleton"");
    }
    public static TestSingletonLog4Net Instance
    {
        get
        {
            if (instance == null)
            {
                lock (syncRoot)
                {
                    if (instance == null)
                        instance = new TestSingletonLog4Net();
                }
            }

            return instance;
        }
    }
}
</code></pre>

<p>I setup a small project to duplicate the problem, and here is what is happening.</p>

<ul>
<li>if I use log4net from the main UI project with either singleton or normal class logging works.</li>
<li>If I use log4net from sub-project libraries that are not a singleton logging works. </li>
<li>If I attempt to use log4net from a singleton that is in one of the sub-project libraries all logging stops, not only does it not log but also logging done from main project no longer work either.</li>
</ul>

<p>I originally had the log4net configuration as part of the app.config but I suspected it may be a problem so I moved log4net configuration into it's own config file.</p>

<p>Using log4net version 1.2.11 </p>

<p>I have also tried calling log from outside the constructor with the same results.</p>

<p>The reset of my setup is below.</p>

<p>The following line is just below the using statements in my Program.cs</p>

<pre><code>[assembly: log4net.Config.XmlConfigurator(ConfigFile = ""log4net.config"", Watch = true)]
</code></pre>

<p>In each class I am calling log4net with:</p>

<pre><code>private static readonly log4net.ILog log = log4net.LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType);
</code></pre>

<p>Any advice for a resolution is greatly appreciated.</p>
",<c#><singleton><log4net>
57867613,Duplicated logs when using Serilog.Sink.Elasticsearch 8 with buffer,"<p>I am using <strong>.NET 4.6.2</strong> Application with <strong>Serilog</strong> with <strong>Elasticsearch sink 8</strong> to send logs to our Elasticsearch cluster. We also added the buffer settings to avoid losing any data.</p>

<p>Everything was working fine with Elasticsearch Sink 7.x until we upgrade to the latest version to make it compatible with with Elasticsearch 7 (cluster).</p>

<p>With the newer version, logs are duplicated (triplicated or more) and sometimes they are not even saved in Elasticsearch. </p>

<p>I believe must be something wrong with my buffer settings.</p>

<p>This is my test code:</p>

<pre><code>private static ILogger GetLogger()
{
    string indexName = ""buffertest"";

    var loggerConfig = new LoggerConfiguration()
        .MinimumLevel.Debug()
        .WriteTo.Console();

    var esSink = new ElasticsearchSinkOptions(new Uri(""https://myelasticdomain.com:9200""))
    {
        AutoRegisterTemplate = true,
        AutoRegisterTemplateVersion = AutoRegisterTemplateVersion.ESv7,
        TemplateName = indexName,
        IndexFormat = indexName + ""-{0:yyyy.MM.dd}"",
        ModifyConnectionSettings = c =&gt; c.BasicAuthentication(""myuser"", ""****""),
        CustomFormatter = new ExceptionAsObjectJsonFormatter(renderMessage: true)
    };

    // buffer
    esSink.BufferBaseFilename = $@""C:\logs\ElasticSeriLog\buffer-{indexName}"";
    esSink.SingleEventSizePostingLimit = null;
    esSink.BufferFileSizeLimitBytes = 1000 * 1000 * 100; // 100 MB
    esSink.BufferFileCountLimit = 50;

    loggerConfig.WriteTo.Elasticsearch(esSink);

    return loggerConfig.CreateLogger();
}

static void Main(string[] args)
{
    Log.Logger = GetLogger();

    for (int i = 0; i &lt; 500; i++)
    {
        var lineNumer = i + 1;
        var msgToLog = GetTextToLog();
        Log.Information(""{Line}{Message}"", lineNumer, msgToLog);
    }

    Console.WriteLine(""Press any key to continue..."");
    Console.ReadKey();

    Console.WriteLine(""Flushing..."");
    Log.CloseAndFlush();
}
</code></pre>

<p>Any idea? Thanks</p>
",<.net><elasticsearch><logging><kibana><serilog>
61512718,"Why does terraform fail with ""An argument named ""flow_log_destination_type"" is not expected here""?","<p>While I am using terraform to create vpc flow log module to s3 bucket then its throwing errors like:</p>
<pre><code>  An argument named &quot;flow_log_destination_type&quot; is not expected here.
  An argument named &quot;flow_log_destination_arn&quot; is not expected here.
</code></pre>
<p>In the Terraform docs, I can see the details to be filled like <code>log_destination_type &amp; log_destination_arn</code>,
and I found some docs on GitHub that exactly says the same code but while trying it's not working for me</p>
<p>The following error produced:</p>
<pre><code>Error: Unsupported argument

  on main.tf line 52, in module &quot;vpc_with_flow_logs_s3_bucket&quot;:
  52:   flow_log_destination_type = &quot;s3&quot;

An argument named &quot;flow_log_destination_type&quot; is not expected here.


Error: Unsupported argument

  on main.tf line 53, in module &quot;vpc_with_flow_logs_s3_bucket&quot;:
  53:   flow_log_destination_arn  = &quot;${aws_s3_bucket.terra-test2-lifecycle.arn}&quot;

An argument named &quot;flow_log_destination_arn&quot; is not expected here.


Error: Unsupported argument

  on main.tf line 55, in module &quot;vpc_with_flow_logs_s3_bucket&quot;:
  55:   vpc_flow_log_tags = {

An argument named &quot;vpc_flow_log_tags&quot; is not expected here.
</code></pre>
<p>Where I am doing wrong?</p>
<pre><code>module &quot;vpc&quot; {
  source  = &quot;terraform-aws-modules/vpc/aws&quot;
  version = &quot;2.33.0&quot;
  # Interpolated from the workspace
  name = &quot;${terraform.workspace}&quot;
  cidr = var.vpc_cidr

  azs             = var.vpc_azs
  private_subnets = var.vpc_private_subnets
  public_subnets  = var.vpc_public_subnets

  enable_nat_gateway = var.vpc_enable_nat_gw
  single_nat_gateway = var.vpc_single_nat_gw

  public_subnet_tags = {
    Name = &quot;${terraform.workspace}-public&quot;
  }

  private_subnet_tags = {
    Name = &quot;${terraform.workspace}-private&quot;
  }

  tags = {
    Name = &quot;${terraform.workspace}&quot;
  }

  vpc_tags = {
    owner       = &quot;PEDevOps&quot;
    environment = &quot;${terraform.workspace}&quot;
    version     = &quot;0.0.1&quot;
    managedby   = &quot;Terraform&quot;
  }
}

module &quot;vpc_with_flow_logs_s3_bucket&quot; {
  source = &quot;../../&quot;
  log_destination_type = &quot;s3&quot;
  log_destination_arn  = &quot;${aws_s3_bucket.terra-test2-lifecycle.arn}&quot;

  vpc_flow_log_tags = {
    Name = &quot;vpc-flow-logs-s3-bucket&quot;
  }
  
}

resource &quot;aws_s3_bucket&quot; &quot;terra-test-lifecycle&quot; {
  bucket = &quot;terra-test-lifecycle&quot;
  acl    = &quot;private&quot;

  lifecycle_rule {
    id      = &quot;log&quot;
    enabled = true

    prefix = &quot;log/&quot;

    tags = {
      &quot;rule&quot;      = &quot;log&quot;
      &quot;autoclean&quot; = &quot;true&quot;
    }

    transition {
      days          = 30
      storage_class = &quot;STANDARD_IA&quot; # or &quot;ONEZONE_IA&quot;
    }

    expiration {
      days = 60
    }
  }
  lifecycle_rule {
    id      = &quot;tmp&quot;
    prefix  = &quot;tmp/&quot;
    enabled = true

    expiration {
      date = &quot;2020-06-06&quot;
    }
  }
}
</code></pre>
<p>Why does terraform fail with <code>An argument named &quot;flow_log_destination_type&quot; is not expected here</code>?</p>
",<amazon-web-services><terraform>
3529576,.NET Trace log viewer,"<p>I have enabled trace logging in .NET to output the network data going back and forth so I can see the SOAP requests being sent to a web service. This seems to be the best way on a site that I can't debug or add a proxy between itself and the web service.</p>

<p>Here are the lines I've added to the web.config to enable it:</p>

<pre><code> &lt;system.diagnostics&gt;
  &lt;trace autoflush=""true""/&gt;
  &lt;sources&gt;
   &lt;source name=""System.Net"" maxdatasize=""1024""&gt;
    &lt;listeners&gt;
     &lt;add name=""TraceFile""/&gt;
    &lt;/listeners&gt;
   &lt;/source&gt;
   &lt;source name=""System.Net.Sockets"" maxdatasize=""1024""&gt;
    &lt;listeners&gt;
     &lt;add name=""TraceFile""/&gt;
    &lt;/listeners&gt;
   &lt;/source&gt;
  &lt;/sources&gt;
  &lt;sharedListeners&gt;
   &lt;add name=""TraceFile"" type=""System.Diagnostics.TextWriterTraceListener"" initializeData=""images/trace.log""/&gt;
  &lt;/sharedListeners&gt;
  &lt;switches&gt;
   &lt;add name=""System.Net"" value=""Verbose""/&gt;
   &lt;add name=""System.Net.Sockets"" value=""Verbose""/&gt;
  &lt;/switches&gt;
 &lt;/system.diagnostics&gt;
</code></pre>

<p>Does anyone know of a log viewer for this? My searching has come up fruitless.</p>
",<c#><.net><asp.net><windows><logging>
19364220,metrics plugin in logstash is not working,"<p>I failed in my attempts to use metrics in logstash, what I expect to see in debug output is logs with new tag and new field added. Nevertheless I get log unchanged, it looks like metrics is not working at all. My Logstash conf file is presented below. Can you please point me my mistake?</p>

<pre><code>input {
  generator {
    type =&gt; ""generated""
    count =&gt; 2
    lines =&gt; [""line 1"", ""line 2"", ""line 3""]
  }
}

filter {
  metrics {
    type =&gt; ""generated""
    meter =&gt; [""events""]
    add_tag =&gt; ""metric""
    add_field =&gt; [ ""status"", ""All is OK"" ]
  }
}

output {
  stdout {
    message =&gt; ""rate: %{events.rate_1m}""
    debug =&gt; true
  }
}
</code></pre>

<p>logstash: logstash-1.2.1-flatjar.jar
platform: Debian 3.2.46-1+deb7u1 x86_64</p>

<p>Best Regards</p>
",<debian><metrics><logstash>
62083041,Serilog Dynamically enrich a context,"<p>Is there any possibility to dynamically override or extend the log template in Serilog?</p>

<p>I have a parser class which parses XML line by line and I want to extend the log entry with the line number. I have already written an enricher that does that, but I have to globally override the default logger at the start of the function and reset it at the end, which is difficult to even look at (from a programming perspective) :D</p>

<p>What are the other options with Serilog or have I missed something?</p>
",<c#><logging><serilog>
57869511,TelemetryClient is not logging Session_Id and User_Id for CustomEvents,"<p>I am using MS BotFramework for NodeJS SDK where trying to log all applicationInsights data through ApplicationInsightsTelemetryClient and TelemetryLoggerMiddleware APIs.</p>

<p>My project is based on NodeJS Javascript version and the reference NodeJS project is in Typescript (<a href=""https://github.com/microsoft/botframework-solutions/tree/master/templates/Virtual-Assistant-Template/typescript/samples/sample-assistant"" rel=""nofollow noreferrer"">https://github.com/microsoft/botframework-solutions/tree/master/templates/Virtual-Assistant-Template/typescript/samples/sample-assistant</a>)</p>

<p>The Typescript project works fine. But my JavaScript project is not storing the Session_ID and User_ID for my customEvent.</p>

<p>Though I got the root cause as well. It's inside NPM Package not in my code. ;(</p>

<p>TelemetryClient.js’ runTelemetryProcessors method is not attaching the activity object to the contextObect.correlationContext property.</p>

<pre><code>TelemetryClient.prototype.runTelemetryProcessors = function (envelope, contextObjects) {
       var accepted = true;
       var telemetryProcessorsCount = this._telemetryProcessors.length;
       if (telemetryProcessorsCount === 0) {
           return accepted;
       }
       contextObjects = contextObjects || {};
       contextObjects['correlationContext'] = CorrelationContextManager_1.CorrelationContextManager.getCurrentContext();
       for (var i = 0; i &lt; telemetryProcessorsCount; ++i) {
           try {
               var processor = this._telemetryProcessors[i];
               if (processor) {
                   if (processor.apply(null, [envelope, contextObjects]) === false) {
                       accepted = false;
                       break;
                   }
               }
           }
           catch (error) {
               accepted = true;
               Logging.warn(""One of telemetry processors failed, telemetry item will be sent."", error, envelope);
           }
       }
       return accepted;
   };

</code></pre>

<p>If I make it working with activity object attachment to the contextOjbect than below processor method of ApplicationInsightsTelemetryClient will attach the userId and sessionId for all custom events.</p>

<pre><code>exports.ApplicationInsightsTelemetryClient = ApplicationInsightsTelemetryClient;
/* Define the telemetry initializer function which is responsible for setting the userId. sessionId and some other values
* so that application insights can correlate related events.
*/
function addBotIdentifiers(envelope, context) {
    if (context.correlationContext &amp;&amp; context.correlationContext.activity) {
        const activity = context.correlationContext.activity;
        // tslint:disable-next-line:no-string-literal
        const telemetryItem = envelope.data['baseData']; // TODO: update when envelope ts definition includes baseData
        const userId = activity.from ? activity.from.id : '';
        const channelId = activity.channelId || '';
        const conversationId = activity.conversation ? activity.conversation.id : '';
        // set user id and session id
        envelope.tags[appInsights.defaultClient.context.keys.userId] = channelId + userId;
        envelope.tags[appInsights.defaultClient.context.keys.sessionId] = conversationId;
        // Add additional properties
        telemetryItem.properties = telemetryItem.properties || {};
        telemetryItem.properties.activityId = activity.id;
        telemetryItem.properties.channelId = channelId;
        telemetryItem.properties.activityType = activity.type;
    }
    return true;
}
</code></pre>

<p>Any thought, what I am missing here?</p>
",<node.js><botframework><azure-application-insights>
41787875,"When I log typeof an IIFE to the console, it is an object instead of a function, why?","<p>I have an IIFE that returns an object. In my app.js file, which I add to a script tag in index.html, I log to the console typeof my IIFE and it is an object. Shouldn't it be a function? Why is typeof returning an object?</p>

<p>Here is my IIFE in app.js:</p>

<pre><code>var UIController = (function() {

  var DOMstrings = {
    inputType: '.add__type',
    description: '.add__description',
    value: '.add__value',
    addBtn: '.add__btn'
  };

  return {
    getInput: function() {
      // return an object containing all values from UI elements
      return {
        type: document.querySelector(DOMstrings.inputType).value, // will be either income or expense
        description: document.querySelector(DOMstrings.description).value, // description of transaction
        value: document.querySelector(DOMstrings.value).value // value of transaction
      };
    },
    getDOMStrings: function() {
      return DOMstrings;
    }
  };

})();

console.log(typeof UIController);
</code></pre>
",<javascript><iife>
62328441,Filter AuroraMysql slow query log file by specific queries,"<p>I downloaded the slow query log file from Aurora Mysql. I want to playback these queries but separate them to just writes and reads. So a tool to extract only selects, or Inserts+Updates would be nice</p>
",<mysql><amazon-web-services><percona><mysql-slow-query-log><amazon-aurora>
57502942,Extract timestamp from log message,"<p>I am trying to index log files to Elastic search. All the log entries are being indexed into a field named message. @timestamp field shows the time the entry was indexed and not the timestamp from log entry. </p>

<p>I created a ingest pipeline with grok processor to define the pattern of the log entry. I have tried several patterns and am unable to get this working, particularly because i am new to grok.</p>

<p><strong>Log sample</strong></p>

<pre><code>2019-08-05 00:04:06 info [index.js]: Request: HTTP GET /
2019-08-05 00:04:06 error [error.js]: No authorization token was found
</code></pre>

<p><strong>Ingest pipeline with grok &amp; date processor</strong></p>

<pre><code>""description"" : ""Extracting date from log line""
, ""processors"": [
{
""grok"": {
""field"": ""message"",
""patterns"": [""%{yyyy-mm-dd HH:mm:ss:logtime} %{LOGLEVEL:loglevel} %{GREEDYDATA:message}""]
},
""date"": {
""field"": ""logtime"",
""target_field"": ""@timestamp"",
""formats"": [""yyyy-mm-dd HH:mm:ss""]
}
}
]
}
</code></pre>

<p>All i want is the ability to extract the timestamp from the log message and everything else can be ignored or wildcarded or stored in just one variable like message. So essentially indexing the log file should index the timestamp from the log message and rest of the message can stay as text or string in one field, no need to parse rest of the message. </p>

<p>Any help would be appreciated.</p>
",<elasticsearch><logstash-grok><filebeat><grok>
4049621,"How do I get Sybase File Path, Transaction Log, & installation details?","<p>I need to Retirve the following Details using Sybase SQL Query.</p>

<p>1) Database Data File Path</p>

<p>2) Database Transaction Log File Path</p>

<p>3) Path where SybaseSoftware Installed</p>

<p>4) Patch Installed on Sybase</p>

<p>Thanks.</p>
",<sap-ase>
12553743,How to Log HTTP Request and Response using Jetty Http Client,"<p>I am using Jetty's HttpClient to send requests. Looking for a way to log the request and response in Trace - to be enabled for troubleshooting.</p>

<p>Any ideas how to do this?</p>
",<http><jetty-8>
23742242,log4net configuration: Can I refer to the same layout in several appenders?,"<p>I want to send log messages to several files (i.e. different appenders) based upon some property of the message.</p>

<p>The problem is that each <code>appender</code> needs to specify quite a verbose <code>layout</code> (that contains a compication conversionPattern and a couple of converters).  I have ended up duplicating this configuration in each <code>appender</code>.  This works but is not ideal as it makes the config much longer than I would like as well as the pain of having to update 3 complicated bit of configuration when the layout changes.</p>

<p>I want to be able to define the layout once and have all my appenders refer back to that one definition (in the same way that several loggers can refer to the same appender).  But perhaps there is a better way to achieve my goal of reducing duplication in the configuration?</p>

<p>My google-foo is weak and I could not find an answer.   Can anyone here help?</p>

<p>TIA.</p>
",<log4net>
26632168,How to display the value of a variable used in a PL/SQL block in the log file of a batch file? And Arrays?,"<p>Basically I'm using a batch file to run a .sql file on Windows Task Scheduler. The batch file generates a log file that displays all the put_lines. I now want to also see the value assigned to the variable: <strong>v_chks_dm</strong>, but couldn't figure out a way to do it. Tried the get_line statement but failed... Does anyone know how to do it?
thanks!</p>

<p>This is what's in the batch file:</p>

<pre><code>echo off
echo ****************************&gt;&gt;C:\output.log

sqlplus userid/password@csdpro @V:\CONDITION_TEST.sql&gt;&gt;C:\output.log
</code></pre>

<p>Here's the .sql file</p>

<pre><code>declare 
  v_chks_dm  number;
  begin
  Select /*+parallel (a,4)*/ count(distinct a.src_table) into v_chks_dm
    from hcr_dm.hcr_dm_fact a;
    dbms_output.put_line('v_chkt_dm value assigned');
--  dbms_output.get_line(v_chks_dm);
  if.... then... else.... end if;
  end; 
</code></pre>

<p>One more question... what if the variable is an array? I have something like this, but got an error says ORA-06533: Subscript beyond count. The number of values in the array usually varies from 0 to 10, but could be more. Thanks!</p>

<pre><code>  declare 
  type v_chks_array is varray(10) of varchar2(50);
  arrSRCs v_chks_array;
  begin
  arrSRCs :=v_chks_array();
  arrSRCs.EXTEND(10);
  Select /*+parallel (a,4)*/ distinct a.src_table BULK collect into arrSRCs
    from hcr_dm.hcr_dm_fact a;
  dbms_output.put_line(arrSRCs(10));
  end; 
</code></pre>
",<variables><batch-file><plsql><getline>
22009161,creating a menu in prolog?,"<pre><code>menu :-
    repeat,
    write('                          '),nl,
    write('   1.the number of hello  '),nl,
    write('                          '),nl,
    write('enter your choice:'),nl,
    read(Choice), Choice&gt;0, Choice =&lt;6,
    doit(Choice),Choice=6.


doit(1):- numberofhello(N).
doit(6):- abort.

my_list([hello,hello,hello]).


counthowmany(_, [], 0) :- !.
counthowmany(X, [X|Q], N) :- !, counthowmany(X, Q, N1), N is N1+1.
counthowmany(X, [_|Q], N) :- counthowmany(X, Q, N).


numberofhello(N) :- my_list(L),counthowmany(hello,L,N).
</code></pre>

<p>now in the code above after compile buffer when I ask Prolog for a menu the menu appears
with one choice and when i enter 1 for number of hello in the list(my_list) i don't get any answer and i get a singleton variable warning while compiling .....</p>

<p>can anyone help me please........</p>
",<prolog>
27924474,Display view name or defined identifier in Xcode6 debug log,"<p>Here is the array of auto-layout errors I get in the log:</p>

<pre><code>(
    ""&lt;NSLayoutConstraint:0x7b7f9060 H:[UIView:0x7b7f8f30(175)]&gt;"",
    ""&lt;NSLayoutConstraint:0x7b7f9090 UIView:0x7b7f8f30.width == UIView:0x7b7f8f30.height&gt;"",
    ""&lt;NSLayoutConstraint:0x7b7f90c0 V:[UIView:0x7b7f8f30(50)]&gt;""
)
</code></pre>

<p>On older Xcode I could set an identifier so that ""UIView"" would be replaced by the identifier. In Xcode6, I can't find how to do this, so i'm stuck with this hard to understand code where I don't know which views this is about.
Do you know how what I could do in  Xcode6 so I have a way to replace UIView by some text I can understand ?</p>
",<ios><xcode>
67592863,Filter log fle by database name including traceback messages,"<p>I'm trying to filter the log file by database name but when i use grep command i lose the Traceback message</p>
<p>tail -f log.txt</p>
<pre><code>2021-05-18 19:05:21,866 1066171 ERROR database1 (...)
Traceback (most recent call last):(...)
  File(...)
2021-05-18 19:05:21,879 1066171 INFO database1 (...)
2021-05-18 19:05:21,866 1066171 ERROR database2 (...)
Traceback (most recent call last):(...)
  File(...)
</code></pre>
<p>tail -f log.txt | grep database1</p>
<pre><code>2021-05-18 19:05:21,866 1066171 ERROR database1 (...)
2021-05-18 19:05:21,879 1066171 INFO database1 (...)
</code></pre>
<p>How can i filter all messeges from database1 including Treceback lines</p>
",<linux><bash><logging>
264815,Logging for JBoss 3.2.5 Java EE Client,"<p>I am trying to find out why a Java EE client (stand alone Java program that uses jbossall-client.jar) is failing to connect to a Java EE Server so it would be good to enable logging that occurs from within JBoss AS classes such as <code>org.jnp.interfaces.NamingContext</code> - presume there is a config file I can set up?</p>

<p>Just for info this is the actual exception that I am getting - hopefully logging would give a bit more info.</p>

<p><strong>Error</strong></p>

<pre class=""lang-java prettyprint-override""><code>javax.naming.CommunicationException: 
    Receive timed out [Root exception is java.net.SocketTimeoutException: 
        Receive timed out]
        at org.jnp.interfaces.NamingContext.discoverServer
            (NamingContext.java:1119)
</code></pre>
",<logging><jakarta-ee><jboss><client>
67635140,servlet 4.0 version log4j2 auto-initialization disable is not working with context-parm isLog4jAutoInitializationDisabled,"<p>My Current web-application is using Servlet 4.0 version and
I am trying disable auto-initialization for log4j2 and below is my web.xml
I have followed <a href=""https://logging.apache.org/log4j/2.x/manual/webapp.html#Servlet-3.0"" rel=""nofollow noreferrer"">Official</a> document</p>
<pre><code>&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; 
    xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; 
    xmlns:web=&quot;http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; 
    xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; 
    id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt;
    
    &lt;display-name&gt;CentricityPracticeWS&lt;/display-name&gt;
    
     &lt;listener&gt;
        &lt;listener-class&gt;org.apache.logging.log4j.web.Log4jServletContextListener&lt;/listener-class&gt;
    &lt;/listener&gt;
 
    &lt;filter&gt;
        &lt;filter-name&gt;CentricityPracticeWS&lt;/filter-name&gt;
        &lt;filter-class&gt;org.apache.logging.log4j.web.Log4jServletFilter&lt;/filter-class&gt;
    &lt;/filter&gt;
    &lt;filter-mapping&gt;
        &lt;filter-name&gt;CentricityPracticeWS&lt;/filter-name&gt;
        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;
        &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt;
        &lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt;
        &lt;dispatcher&gt;INCLUDE&lt;/dispatcher&gt;
        &lt;dispatcher&gt;ERROR&lt;/dispatcher&gt;
    &lt;/filter-mapping&gt;
    
     &lt;context-param&gt;
        &lt;param-name&gt;isLog4jContextSelectorNamed&lt;/param-name&gt;
        &lt;param-value&gt;true&lt;/param-value&gt;
    &lt;/context-param&gt;

    &lt;context-param&gt;
        &lt;param-name&gt;log4jConfiguration&lt;/param-name&gt;
        &lt;param-value&gt;file://C://jboss//standalone//deployments//CentricityPracticeEAR.ear//init//log4j2.xml&lt;/param-value&gt;
    &lt;/context-param&gt;
    
        &lt;context-param&gt;
        &lt;param-name&gt;log4jContextName&lt;/param-name&gt;
        &lt;param-value&gt;CentricityPracticeWS&lt;/param-value&gt;
    &lt;/context-param&gt;

    
    &lt;context-param&gt;
      &lt;param-name&gt;isLog4jAutoInitializationDisabled&lt;/param-name&gt;
      &lt;param-value&gt;true&lt;/param-value&gt;
    &lt;/context-param&gt;

    &lt;!-- init properties shared by entire application --&gt;
    &lt;context-param&gt;
        &lt;param-name&gt;earDeploymentDescriptorPath&lt;/param-name&gt;
        &lt;param-value&gt;application.xml&lt;/param-value&gt;
    &lt;/context-param&gt;
    &lt;listener&gt;
        &lt;listener-class&gt;com.CustomListener&lt;/listener-class&gt;
    &lt;/listener&gt;
    
    &lt;!-- bootstrap Log4j --&gt;
    &lt;!-- Log4j refresh interval --&gt;
    &lt;context-param&gt;
        &lt;param-name&gt;log4jRefreshInterval&lt;/param-name&gt;
        &lt;param-value&gt;60000&lt;/param-value&gt;
    &lt;/context-param&gt;
    &lt;context-param&gt;
        &lt;param-name&gt;log4jExposeWebAppRoot&lt;/param-name&gt;
        &lt;param-value&gt;false&lt;/param-value&gt;
    &lt;/context-param&gt;
    &lt;listener&gt;
        &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt;
    &lt;/listener&gt;
    
    &lt;!-- bootstrap Spring --&gt;
    &lt;context-param&gt;
        &lt;param-name&gt;parentContextKey&lt;/param-name&gt;
        &lt;param-value&gt;centricity.practice&lt;/param-value&gt;
    &lt;/context-param&gt;
    &lt;context-param&gt;
        &lt;param-name&gt;locatorFactorySelector&lt;/param-name&gt;
        &lt;param-value&gt;/beanRefFactory.xml&lt;/param-value&gt;
    &lt;/context-param&gt; 
    &lt;context-param&gt;
        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
        &lt;param-value&gt;/WEB-INF/context-web.xml&lt;/param-value&gt;
    &lt;/context-param&gt;
    &lt;listener&gt;
        &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;
    &lt;/listener&gt;
    &lt;!-- welcome file list--&gt;
    &lt;welcome-file-list&gt;
        &lt;welcome-file&gt;index.html&lt;/welcome-file&gt;
    &lt;/welcome-file-list&gt;
    
&lt;/web-app&gt;
</code></pre>
<p>disable auto-initialization is not working with above web.xml</p>
<p>I have also tried keeping only below  but no luck</p>
<pre><code>&lt;context-param&gt;
    &lt;param-name&gt;isLog4jAutoInitializationDisabled&lt;/param-name&gt;
    &lt;param-value&gt;true&lt;/param-value&gt;
&lt;/context-param&gt;
</code></pre>
<p>please correct me if there is anything wrong with above web.xml configuration
your help is apricated !!</p>
",<log4j><java-11><servlet-4>
71341106,"how make output ""Negative!"" at console.log(question4([-1, 4, 7, 11]))","<pre><code>function question4(angka){
var w=0 , jml=0, rtt=0;
var nilai;
nilai=angka;


for(w=0;w &lt; nilai.length;w++)
{
jml=jml+nilai[w];
}
rtt=jml/nilai.length;
console.log(rtt);
}

console.log(question4([4, 5, 6, 7, 8]));
console.log(question4([100, 200, 300, 400, 500]));
console.log(question4([-1, 4, 7, 11]));
</code></pre>
<p>If there is one or more array elements with negative values, then the function is direct
outputs the text 'Negative!'.</p>
",<javascript><arrays>
71266131,Linear regression plot on log scale in Python,"<p>I want to do linear regression to the data given by x and y. Everything seems to be fine when I use a linear plot, but when I want to plot it on a log scale the line does not look straight. I think I should divide the interval into finer grids rather than only six points. But I couldn't do that.</p>
<p>How can I do line fitting on a log scale for the below script?</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

x = np.array([1560., 526., 408., 226., 448., 288.])
y = np.array([0.118, 0.124, 0.131, 0.160, 0.129, 0.138])

f = np.multiply(x,y**2)

coefs = np.polyfit(x, f, 1)

pred_f = coefs[1] + np.multiply(sorted(x), coefs[0])

fig, ax1 = plt.subplots(1, 1, figsize=(8,6))

ax1.scatter(x, f)
ax1.plot(sorted(x), pred_f, 'k--')
ax1.set_xscale('log')
ax1.set_yscale('log')

plt.show()
</code></pre>
",<python><numpy><matplotlib>
13065500,How to log ADO connection's execute statements,"<p>I am using ado connection to <a href=""https://stackoverflow.com/questions/12260493/connect-to-sql-2008-using-inno-setup"">connect to sql 2008</a> from inno, and i would like to know if we can log the details into a file so that can capture the errors thrown by sql. </p>

<p>Note: Thru ado connection I am not just executing select querys, i am using ado connection to execute set of statements to create database, procedure, tables etc. </p>
",<ado><inno-setup>
11986247,Can I catch LogCat messages when using the phone normally (not connected to the pc)?,"<p>I want to know if there's any way of recording logcat's messages when I'm testing my app with a real phone in a real environment. What I'm trying to achieve is to take my phone elsewhere and if anything goes wrong with my app, trace back why it went wrong. Especially if I give my app to a friend (or a boss) to try it out, they can't give me a lot of feedback on problems.</p>

<p>I could just print all the output to a .txt and then read it, but I'd like something a bit nicer</p>

<p>Any Ideas?</p>
",<android><logcat>
42349527,Logstash wont start on windows,"<p>I'm trying to use logstash on windows 10.
So far I am stuck on this matter:</p>

<pre><code>$ bin/logstash -f conf.conf 
NoMethodError: undefined method `each_pair' for ""C:/Sources/logstash-5.2.1/vendor/bundle/jruby/2.3.0"":String
Did you mean?  each_char
  paths= at C:/jruby-9.1.7.0/lib/ruby/stdlib/rubygems.rb:388
  setup! at C:/Sources/logstash-5.2.1/lib/bootstrap/bundler.rb:49
  &lt;main&gt; at C:/Sources/logstash-5.2.1/lib/bootstrap/environment.rb:67
</code></pre>

<p>It seems that a string is passed instead of an array.
I cant find any clue on this problem.
Could anyone be kind enough to help me ?</p>

<p>Théo</p>
",<logstash>
22415347,Optional indented newline in git log format,"<p>I have been tinkering with <code>git</code> aliases for some <code>log</code> commands. I have most of what I'd like (<a href=""https://stackoverflow.com/a/9074343/241211"">credit here</a>), but I'm having trouble with one piece. When I call…</p>
<pre class=""lang-bash prettyprint-override""><code>git log --graph --format=format:'%h - [%ar] %s%+d'
</code></pre>
<p>…I get…</p>
<pre class=""lang-none prettyprint-override""><code>* ab123f - [6 hours ago] Fix the references
|  (HEAD, origin/master, master)
* bc123f - [8 hours ago] New build syntax
* cd123f - [10 hours ago] Initial import
</code></pre>
<p>…where <code>%+d</code> adds a new line and puts the <code>--decorate</code> tags on it if they exist. I would rather have the tags to be in line with the <em>time stamp</em> instead, like so:</p>
<pre class=""lang-none prettyprint-override""><code>* ab123f - [6 hours ago] Fix the references
|          (HEAD, origin/master, master)
* bc123f - [8 hours ago] New build syntax
* cd123f - [10 hours ago] Initial import
</code></pre>
<p>How do I accomplish this? I do not want a bonus newline if there are no <code>--decorate</code> tags. I've been experimenting with various <a href=""https://git-scm.com/docs/pretty-formats"" rel=""nofollow noreferrer"">format placeholders:</a> <code>%+d</code>, <code>%-d</code>, <code>%+    d</code> (which doesn't work); permutations of <code>%&gt;(&lt;N&gt;)</code>, <code>%&gt;&gt;(&lt;N&gt;)</code>; and so on, but I can't get it to do what I want.</p>
<p>Colors and further commit info had been removed for simplicity, but they seem to interfere with <a href=""https://stackoverflow.com/a/22416145/241211"">torek's answer</a>. The full command is below:</p>
<pre class=""lang-bash prettyprint-override""><code>git log --graph --format=format:'%C(bold yellow)%h%C(reset) - %C(green)(%ar)%C(reset) %s %C(white)&lt;%an&gt;%C(reset)%C(auto)%+d%C(reset)'
</code></pre>
",<git><formatting><git-log>
67645585,"Prolog: Why do I keep getting a operator expected error, how can I fix this?","<p><a href=""https://i.stack.imgur.com/JpiAH.png"" rel=""nofollow noreferrer"">Operator Expected error</a></p>
<p>I am new to prolog and trying to understand how to fix this error. This code is where the issue occurs:</p>
<pre><code>
% Checks if the sum constraint of a cage is met.
sum(S, S, [], _).
sum(SumOfCells, S, [RowIndex-ColIndex|Lt], T) :-
    nth(RowIndex, T, Row), nth(ColIndex, Row, CellVal),
    NewSum #= SumOfCells + CellVal, sum(NewSum, S, Lt, T).

</code></pre>
<p>&quot;Syntax error: Operator expected&quot;.</p>
<p>It is my understanding that I have declared a variable NewSum and am trying to set it equal to the sum of SumOfCells and CellVal. Can you help me identify what I did wrong and how I can fix it?</p>
",<prolog><syntax-error><clpfd>
51506738,Microsoft.Extensions.Logging.Console not working in Console App,"<p>Im trying to log to the console, but when I do this:</p>

<pre><code>//setup our DI
var serviceProvider = new ServiceCollection()
         .AddSingleton(new LoggerFactory()
         .AddConsole(LogLevel.Debug))
         .BuildServiceProvider();

var logger = serviceProvider.GetService&lt;ILoggerFactory&gt;()
        .CreateLogger&lt;Program&gt;();

var enabled = logger.IsEnabled(LogLevel.Debug); // This is true
logger.LogDebug(""Starting application""); // does not show up in console
</code></pre>

<p>Nothing shows up in my console!  What am I missing?!?</p>
",<c#><.net-core-2.1>
6751728,How to create a PDF catalog object to embed XML using Ghostscript,"<p>Does anyone know how to create a PDF catalog object to embed XML in the PDF file using Ghostscript?</p>
",<pdf><object><ghostscript><catalog>
62570091,git log - display only the first x characters of commit's message,"<p>I want to display only a limited number of characters (say the first 100 characters) of the commit message in <code>git log</code></p>
<p>Currently, I used <code>git log --oneline</code> but this displays the first line of the message. This can be a very long line if there is no new-line-characters between lines in the message. This makes my git log ugly and not easily readable.</p>
<p>How can I do this?</p>
<p>If this is not possible to display a limited number of characters, can I display the real first line of the message, I mean if there is no break between it and the second line in the message?</p>
",<git><git-log>
41812805,logstash 5.0.1: setup elasticsearch multiple indexes ouput for multiple kafka input topics,"<p>I have a logstash input setup as </p>

<pre><code>input {
  kafka {
  bootstrap_servers =&gt; ""zookeper_address""
  topics =&gt; [""topic1"",""topic2""]
  }
}
</code></pre>

<p>I need to feed the topics into two different indexes in elasticsearch. Can anyone help me with how the ouput should be setup for such a task. At this time I am only able to setup</p>

<pre><code>output {
  elasticsearch {
    hosts =&gt; [""localhost:9200""]
    index =&gt; ""my_index""
    codec =&gt; ""json""
    document_id =&gt; ""%{id}""
  }
}
</code></pre>

<p>I need two indexes on the same elasticsearch instance say <code>index1</code> and <code>index2</code> which will be fed by messages coming in on <code>topic1</code> and <code>topic2</code></p>
",<elasticsearch><logstash-configuration>
57529281,Serverless first deploy error occured: HelloLogGroup - User,"<p>I want to test deploy serverless project using default serverless template, but i got this error </p>

<pre><code> An error occurred: HelloLogGroup - User: arn:aws:iam::346468483688:user/crm_development is not authorized to perform: logs:DescribeLogGroups on resource: arn:aws:logs:us-east-1:346468483688:log-group::log-stream: (Service: AWSLogs; Status Code: 400; Error Code: AccessDeniedException; Request ID: cb3894c8-aaca-400b-9862-a610e0cbffc2).
</code></pre>
",<amazon-web-services><serverless-framework><serverless>
